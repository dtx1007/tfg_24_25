{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715e37f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocessing_utils import preprocess_data_for_nn\n",
    "\n",
    "from torch_nn_model_2 import (\n",
    "    get_best_available_device,\n",
    "    train_nn_model,\n",
    "    NNHyperparams,\n",
    ")\n",
    "\n",
    "torchtext.disable_torchtext_deprecation_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580645a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    sequence_cols: list[str],\n",
    "    char_cols: list[str],\n",
    "    vector_cols: list[str],\n",
    "    scalar_cols: list[str],\n",
    "    vector_dims: dict[str, int],\n",
    "    load_fresh: bool = False,\n",
    "    sample_size: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load the dataset, optionally reloading it fresh.\n",
    "    \"\"\"\n",
    "    if load_fresh:\n",
    "        print(\"Loading dataset fresh...\")\n",
    "        df = pd.read_csv(\"dataset/apk_analysis_dataset.csv\")\n",
    "\n",
    "        if sample_size is not None:\n",
    "            print(f\"Sampling {sample_size} rows from the dataset...\")\n",
    "            df = df.sample(sample_size, random_state=42)\n",
    "\n",
    "        df, vocab_dict = preprocess_data_for_nn(\n",
    "            df,\n",
    "            sequence_cols=sequence_cols,\n",
    "            char_cols=char_cols,\n",
    "            vector_cols=vector_cols,\n",
    "            scalar_cols=scalar_cols,\n",
    "            vector_dims=vector_dims,\n",
    "        )\n",
    "\n",
    "        print(\"Saving preprocessed dataset and vocab_dict...\")\n",
    "\n",
    "        df.to_pickle(\"dataset/processed_apk_analysis_dataset.pkl\")\n",
    "        torch.save(vocab_dict, \"dataset/processed_vocab_dict.pth\")\n",
    "\n",
    "        print(\"Preprocessing complete and saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Loading last preprocessed dataset...\")\n",
    "        df = pd.read_pickle(\"dataset/processed_apk_analysis_dataset.pkl\")\n",
    "        vocab_dict = torch.load(\"dataset/processed_vocab_dict.pth\")\n",
    "\n",
    "    return df, vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6127393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading last preprocessed dataset...\n",
      "Using CUDA device: NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3100, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3155, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3367, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3612, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\david\\miniconda3\\envs\\python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3672, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_21648\\1702589239.py\", line 29, in <module>\n",
      "    device = get_best_available_device()\n",
      "  File \"c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\prototypes\\torch_nn_model_2.py\", line 637, in get_best_available_device\n",
      "    device = torch.device(\"cuda\")\n",
      "c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\prototypes\\torch_nn_model_2.py:637: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device = torch.device(\"cuda\")\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_COLS = [\n",
    "    \"activities_list\",\n",
    "    \"services_list\",\n",
    "    \"receivers_list\",\n",
    "    \"permissions_list\",\n",
    "    \"api_calls_list\",\n",
    "]\n",
    "\n",
    "CHAR_COLS = [\"fuzzy_hash\"]\n",
    "VECTOR_COLS = [\"opcode_counts\"]\n",
    "SCALAR_COLS = [\"file_size\"]\n",
    "VECTOR_DIMS = {\"opcode_counts\": 768}\n",
    "\n",
    "# Load dataset\n",
    "df, vocab_dict = load_dataset(\n",
    "    SEQUENCE_COLS,\n",
    "    CHAR_COLS,\n",
    "    VECTOR_COLS,\n",
    "    SCALAR_COLS,\n",
    "    VECTOR_DIMS,\n",
    "    load_fresh=False,\n",
    "    sample_size=None,\n",
    ")\n",
    "\n",
    "df, df_sample = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"is_malware\"]\n",
    ")\n",
    "\n",
    "device = get_best_available_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26973f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15977 entries, 19862 to 3961\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   file_size         15977 non-null  float64\n",
      " 1   fuzzy_hash        15977 non-null  object \n",
      " 2   activities_list   15977 non-null  object \n",
      " 3   services_list     15977 non-null  object \n",
      " 4   receivers_list    15977 non-null  object \n",
      " 5   permissions_list  15977 non-null  object \n",
      " 6   api_calls_list    15977 non-null  object \n",
      " 7   opcode_counts     15977 non-null  object \n",
      " 8   is_malware        15977 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_size</th>\n",
       "      <th>fuzzy_hash</th>\n",
       "      <th>activities_list</th>\n",
       "      <th>services_list</th>\n",
       "      <th>receivers_list</th>\n",
       "      <th>permissions_list</th>\n",
       "      <th>api_calls_list</th>\n",
       "      <th>opcode_counts</th>\n",
       "      <th>is_malware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19862</th>\n",
       "      <td>4939479.0</td>\n",
       "      <td>[47, 64, 18, 17, 62, 19, 63, 63, 29, 34, 31, 4...</td>\n",
       "      <td>[238986, 10, 238988, 238983, 3, 238985, 4, 22,...</td>\n",
       "      <td>[9, 4, 13, 5, 6, 8, 11, 3, 12, 10, 20857, 0, 0...</td>\n",
       "      <td>[4, 8, 13, 16, 11, 7, 12, 6, 10, 5, 9, 0, 0, 0...</td>\n",
       "      <td>[20, 3, 23, 17, 4, 5, 11, 41, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[175378, 2972, 4510, 6430, 5098, 16823, 16449,...</td>\n",
       "      <td>[268.0, 2926.0, 3840.0, 0.0, 700.0, 619.0, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>4560508.0</td>\n",
       "      <td>[36, 17, 10, 59, 6, 65, 21, 62, 17, 39, 62, 14...</td>\n",
       "      <td>[179512, 179513, 179511, 18, 179509, 179510, 1...</td>\n",
       "      <td>[20, 25, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[18, 17, 11402, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[13, 9, 7, 24, 46, 21, 19, 4, 12, 8, 6, 22, 5,...</td>\n",
       "      <td>[1012942, 1012943, 1012944, 1012945, 1013007, ...</td>\n",
       "      <td>[164.0, 2642.0, 44.0, 0.0, 49.0, 10.0, 0.0, 32...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18535</th>\n",
       "      <td>4335600.0</td>\n",
       "      <td>[53, 46, 15, 50, 10, 22, 23, 21, 21, 34, 50, 3...</td>\n",
       "      <td>[97608, 44202, 97613, 4, 97614, 22, 97609, 3, ...</td>\n",
       "      <td>[13, 10, 12, 11, 4, 5, 9, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[6, 13, 16, 12, 4, 9, 7, 10, 8, 11, 0, 0, 0, 0...</td>\n",
       "      <td>[14, 7, 18, 17, 5, 3, 4, 41, 12, 13, 23, 10, 3...</td>\n",
       "      <td>[83888, 197158, 2972, 16823, 16449, 16835, 167...</td>\n",
       "      <td>[389.0, 2931.0, 5771.0, 0.0, 532.0, 537.0, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>2120068.0</td>\n",
       "      <td>[56, 12, 11, 7, 57, 50, 12, 51, 34, 17, 45, 16...</td>\n",
       "      <td>[194481, 12198, 12199, 23835, 23836, 0, 0, 0, ...</td>\n",
       "      <td>[2126, 2127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[22, 163, 11, 4, 182, 7, 21, 8, 3, 9, 15, 6, 2...</td>\n",
       "      <td>[302565, 121966, 302566, 418308, 302567, 41845...</td>\n",
       "      <td>[139.0, 3710.0, 541.0, 0.0, 113.0, 53.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>269692.0</td>\n",
       "      <td>[3, 30, 28, 62, 49, 62, 38, 33, 17, 45, 36, 62...</td>\n",
       "      <td>[721, 931, 707, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[212, 214, 213, 211, 284, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[153, 126, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[6, 9, 15, 3, 4, 19, 31, 10, 28, 62, 0, 0, 0, ...</td>\n",
       "      <td>[18370, 58927, 73, 84, 685, 731, 277, 592, 223...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_size                                         fuzzy_hash  \\\n",
       "19862  4939479.0  [47, 64, 18, 17, 62, 19, 63, 63, 29, 34, 31, 4...   \n",
       "7826   4560508.0  [36, 17, 10, 59, 6, 65, 21, 62, 17, 39, 62, 14...   \n",
       "18535  4335600.0  [53, 46, 15, 50, 10, 22, 23, 21, 21, 34, 50, 3...   \n",
       "7789   2120068.0  [56, 12, 11, 7, 57, 50, 12, 51, 34, 17, 45, 16...   \n",
       "2356    269692.0  [3, 30, 28, 62, 49, 62, 38, 33, 17, 45, 36, 62...   \n",
       "\n",
       "                                         activities_list  \\\n",
       "19862  [238986, 10, 238988, 238983, 3, 238985, 4, 22,...   \n",
       "7826   [179512, 179513, 179511, 18, 179509, 179510, 1...   \n",
       "18535  [97608, 44202, 97613, 4, 97614, 22, 97609, 3, ...   \n",
       "7789   [194481, 12198, 12199, 23835, 23836, 0, 0, 0, ...   \n",
       "2356   [721, 931, 707, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           services_list  \\\n",
       "19862  [9, 4, 13, 5, 6, 8, 11, 3, 12, 10, 20857, 0, 0...   \n",
       "7826   [20, 25, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "18535  [13, 10, 12, 11, 4, 5, 9, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "7789   [2126, 2127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2356   [212, 214, 213, 211, 284, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                          receivers_list  \\\n",
       "19862  [4, 8, 13, 16, 11, 7, 12, 6, 10, 5, 9, 0, 0, 0...   \n",
       "7826   [18, 17, 11402, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "18535  [6, 13, 16, 12, 4, 9, 7, 10, 8, 11, 0, 0, 0, 0...   \n",
       "7789   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2356   [153, 126, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                        permissions_list  \\\n",
       "19862  [20, 3, 23, 17, 4, 5, 11, 41, 0, 0, 0, 0, 0, 0...   \n",
       "7826   [13, 9, 7, 24, 46, 21, 19, 4, 12, 8, 6, 22, 5,...   \n",
       "18535  [14, 7, 18, 17, 5, 3, 4, 41, 12, 13, 23, 10, 3...   \n",
       "7789   [22, 163, 11, 4, 182, 7, 21, 8, 3, 9, 15, 6, 2...   \n",
       "2356   [6, 9, 15, 3, 4, 19, 31, 10, 28, 62, 0, 0, 0, ...   \n",
       "\n",
       "                                          api_calls_list  \\\n",
       "19862  [175378, 2972, 4510, 6430, 5098, 16823, 16449,...   \n",
       "7826   [1012942, 1012943, 1012944, 1012945, 1013007, ...   \n",
       "18535  [83888, 197158, 2972, 16823, 16449, 16835, 167...   \n",
       "7789   [302565, 121966, 302566, 418308, 302567, 41845...   \n",
       "2356   [18370, 58927, 73, 84, 685, 731, 277, 592, 223...   \n",
       "\n",
       "                                           opcode_counts  is_malware  \n",
       "19862  [268.0, 2926.0, 3840.0, 0.0, 700.0, 619.0, 0.0...           0  \n",
       "7826   [164.0, 2642.0, 44.0, 0.0, 49.0, 10.0, 0.0, 32...           1  \n",
       "18535  [389.0, 2931.0, 5771.0, 0.0, 532.0, 537.0, 0.0...           0  \n",
       "7789   [139.0, 3710.0, 541.0, 0.0, 113.0, 53.0, 0.0, ...           1  \n",
       "2356   [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, ...           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "752f2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure df_processed, vocab_dict, SEQUENCE_COLS, etc. are defined in your notebook scope\n",
    "# df_processed = df # Or however you get your fully preprocessed DataFrame for the NN\n",
    "# device = get_best_available_device() # Already defined\n",
    "\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Objective function for Optuna to optimize.\n",
    "    A trial will suggest a set of hyperparameters, train the model, and return a score.\n",
    "    \"\"\"\n",
    "    # Define the search space for hyperparameters\n",
    "    # These are examples, adjust ranges and types based on your intuition/needs\n",
    "    lr = trial.suggest_float(\"max_learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
    "\n",
    "    hidden_dims_one_layer = [(16,), (32,), (64,), (128,), (256,)]\n",
    "    hidden_dims_two_layers = [\n",
    "        (256, 128),\n",
    "        (256, 64),\n",
    "        (256, 32),\n",
    "        (256, 16),\n",
    "        (128, 64),\n",
    "        (128, 32),\n",
    "        (128, 16),\n",
    "        (64, 32),\n",
    "        (64, 16),\n",
    "        (32, 16),\n",
    "    ]\n",
    "    hiddem_dims_possible = hidden_dims_one_layer + hidden_dims_two_layers\n",
    "    \n",
    "    hidden_dims_idx = trial.suggest_int(\"hidden_dims_idx\", 0, len(hiddem_dims_possible) - 1)\n",
    "    hidden_dims = list(hiddem_dims_possible[hidden_dims_idx])\n",
    "    print(f\"Selected hidden_dims: {hidden_dims} (index {hidden_dims_idx})\")\n",
    "\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5, step=0.1)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    # Create NNHyperparams instance with suggested values\n",
    "    # Keep other hyperparams fixed or include them in the trial if you want to tune them\n",
    "    current_hyperparams = NNHyperparams(\n",
    "        batch_size=batch_size,\n",
    "        max_learning_rate=lr,\n",
    "        epochs=5,\n",
    "        early_stopping=True,\n",
    "        patience=2,\n",
    "        optimizer=\"adamw\",  # Consider fixing or tuning\n",
    "        weight_decay=weight_decay,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout=dropout,\n",
    "        seq_pooling=\"mean\",\n",
    "        n_classes=2,\n",
    "        label_col=\"is_malware\",\n",
    "        dataloader_num_workers=2,\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_persistent_workers=True,\n",
    "        grad_scaler_max_norm=1.0,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Optuna Trial ---\")\n",
    "    print(f\"Suggested Hyperparams: {current_hyperparams}\")\n",
    "\n",
    "    trained_model, results, fitted_scalers = train_nn_model(\n",
    "        df=df_sample,  # Use your full preprocessed DataFrame or a sample\n",
    "        vocab_dict=vocab_dict,\n",
    "        sequence_cols=SEQUENCE_COLS,\n",
    "        scalar_cols=SCALAR_COLS,\n",
    "        char_cols=CHAR_COLS,\n",
    "        vector_cols=VECTOR_COLS,\n",
    "        vector_dims=VECTOR_DIMS,\n",
    "        hyperparams=current_hyperparams,\n",
    "        device=device,\n",
    "        train_split_ratio=0.5,\n",
    "        scoring_metric=\"f1\",\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    # unload the model to free memory\n",
    "    del trained_model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    import gc\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # Get the metric to optimize from the results\n",
    "    # Ensure this matches the 'scoring_metric' used in train_nn_model\n",
    "    # and the direction of optimization in optuna.create_study\n",
    "    metric_to_optimize = results[\"final_metrics_best_model\"].get(\"f1\", 0.0)\n",
    "\n",
    "    print(f\"Trial finished. Validation Recall: {metric_to_optimize:.4f}\")\n",
    "\n",
    "    # Optuna tries to maximize the returned value by default if direction='maximize'\n",
    "    return metric_to_optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06ccbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:21:52,274] A new study created in memory with name: debrim_nn_hyperopt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hidden_dims: [128, 32] (index 10)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0023856730313390243, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.6634066787303807e-05, embedding_dim=128, hidden_dims=[128, 32], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.7262, LR: 9.56e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6629, LR: 2.12e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.5130, LR: 5.22e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.1387, LR: 9.68e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.3508, LR: 1.47e-03\n",
      "Epoch 1/5 — Train Loss: 0.4194\n",
      "Epoch 1 — Val Loss: 0.1758, Val F1: 0.9366 (Acc: 0.9354, P: 0.9190, R: 0.9549, F1: 0.9366, ROC: 0.9845, PR: 0.9853)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.0495, LR: 1.84e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0499, LR: 2.20e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0369, LR: 2.37e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.0365, LR: 2.38e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.5619, LR: 2.33e-03\n",
      "Epoch 2/5 — Train Loss: 0.1148\n",
      "Epoch 2 — Val Loss: 0.0981, Val F1: 0.9674 (Acc: 0.9680, P: 0.9824, R: 0.9529, F1: 0.9674, ROC: 0.9946, PR: 0.9953)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0208, LR: 2.26e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0327, LR: 2.14e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0302, LR: 1.99e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.1580, LR: 1.81e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0217, LR: 1.61e-03\n",
      "Epoch 3/5 — Train Loss: 0.0310\n",
      "Epoch 3 — Val Loss: 0.1045, Val F1: 0.9695 (Acc: 0.9695, P: 0.9690, R: 0.9699, F1: 0.9695, ROC: 0.9951, PR: 0.9956)\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0309, LR: 1.44e-03\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0065, LR: 1.22e-03\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0238, LR: 9.99e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0007, LR: 7.84e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0392, LR: 5.83e-04\n",
      "Epoch 4/5 — Train Loss: 0.0083\n",
      "Epoch 4 — Val Loss: 0.1334, Val F1: 0.9723 (Acc: 0.9725, P: 0.9787, R: 0.9659, F1: 0.9723, ROC: 0.9956, PR: 0.9962)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0981\n",
      "\n",
      "Training finished. Total time: 85.93s. Model size: 2069997.49 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9680\n",
      "  - Precision: 0.9824\n",
      "  - Recall: 0.9529\n",
      "  - F1: 0.9674\n",
      "  - Roc_auc: 0.9946\n",
      "  - Pr_auc: 0.9953\n",
      "  - Val_loss: 0.0981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:23:35,920] Trial 0 finished with value: 0.9674465920651069 and parameters: {'max_learning_rate': 0.0023856730313390243, 'batch_size': 16, 'embedding_dim': 128, 'hidden_dims_idx': 10, 'dropout': 0.4, 'weight_decay': 1.6634066787303807e-05}. Best is trial 0 with value: 0.9674465920651069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9674\n",
      "Selected hidden_dims: [32, 16] (index 14)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=3.0173055455242765e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0003004062167267393, embedding_dim=64, hidden_dims=[32, 16], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7047, LR: 1.22e-06\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6871, LR: 2.78e-06\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6818, LR: 6.77e-06\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.7008, LR: 1.24e-05\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.6911, LR: 1.87e-05\n",
      "Epoch 1/5 — Train Loss: 0.6906\n",
      "Epoch 1 — Val Loss: 0.6880, Val F1: 0.5325 (Acc: 0.6046, P: 0.6503, R: 0.4509, F1: 0.5325, ROC: 0.6492, PR: 0.6472)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.6914, LR: 2.36e-05\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.6796, LR: 2.80e-05\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.6966, LR: 3.01e-05\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.6801, LR: 3.00e-05\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.6730, LR: 2.94e-05\n",
      "Epoch 2/5 — Train Loss: 0.6820\n",
      "Epoch 2 — Val Loss: 0.6768, Val F1: 0.7301 (Acc: 0.7528, P: 0.8029, R: 0.6693, F1: 0.7301, ROC: 0.8458, PR: 0.8026)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.6734, LR: 2.85e-05\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.6764, LR: 2.70e-05\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.6626, LR: 2.51e-05\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.6599, LR: 2.28e-05\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.6575, LR: 2.03e-05\n",
      "Epoch 3/5 — Train Loss: 0.6696\n",
      "Epoch 3 — Val Loss: 0.6636, Val F1: 0.8146 (Acc: 0.8148, P: 0.8146, R: 0.8146, F1: 0.8146, ROC: 0.8971, PR: 0.8638)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.6592, LR: 1.80e-05\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.6709, LR: 1.52e-05\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.6718, LR: 1.25e-05\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.6709, LR: 9.78e-06\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.6494, LR: 7.27e-06\n",
      "Epoch 4/5 — Train Loss: 0.6569\n",
      "Epoch 4 — Val Loss: 0.6559, Val F1: 0.8270 (Acc: 0.8243, P: 0.8138, R: 0.8407, F1: 0.8270, ROC: 0.9070, PR: 0.8798)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.6576, LR: 5.35e-06\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.6553, LR: 3.39e-06\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.6546, LR: 1.84e-06\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.6656, LR: 7.35e-07\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.6450, LR: 1.24e-07\n",
      "Epoch 5/5 — Train Loss: 0.6532\n",
      "Epoch 5 — Val Loss: 0.6546, Val F1: 0.8289 (Acc: 0.8258, P: 0.8137, R: 0.8447, F1: 0.8289, ROC: 0.9081, PR: 0.8818)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.6546\n",
      "\n",
      "Training finished. Total time: 42.09s. Model size: 1034724.18 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.8258\n",
      "  - Precision: 0.8137\n",
      "  - Recall: 0.8447\n",
      "  - F1: 0.8289\n",
      "  - Roc_auc: 0.9081\n",
      "  - Pr_auc: 0.8818\n",
      "  - Val_loss: 0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:24:30,653] Trial 1 finished with value: 0.8289085545722714 and parameters: {'max_learning_rate': 3.0173055455242765e-05, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 14, 'dropout': 0.30000000000000004, 'weight_decay': 0.0003004062167267393}. Best is trial 0 with value: 0.9674465920651069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.8289\n",
      "Selected hidden_dims: [32, 16] (index 14)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.00047686427118995696, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0007098155083968054, embedding_dim=256, hidden_dims=[32, 16], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6932, LR: 1.91e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6870, LR: 4.23e-05\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.6579, LR: 1.04e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.5502, LR: 1.94e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.3971, LR: 2.93e-04\n",
      "Epoch 1/5 — Train Loss: 0.5539\n",
      "Epoch 1 — Val Loss: 0.2149, Val F1: 0.9293 (Acc: 0.9264, P: 0.8936, R: 0.9679, F1: 0.9293, ROC: 0.9786, PR: 0.9728)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.2380, LR: 3.68e-04\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.2517, LR: 4.39e-04\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0153, LR: 4.75e-04\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.0569, LR: 4.75e-04\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.1014, LR: 4.65e-04\n",
      "Epoch 2/5 — Train Loss: 0.1473\n",
      "Epoch 2 — Val Loss: 0.1789, Val F1: 0.9645 (Acc: 0.9640, P: 0.9495, R: 0.9800, F1: 0.9645, ROC: 0.9890, PR: 0.9799)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0445, LR: 4.52e-04\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0973, LR: 4.28e-04\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0271, LR: 3.98e-04\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0894, LR: 3.63e-04\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0482, LR: 3.23e-04\n",
      "Epoch 3/5 — Train Loss: 0.0803\n",
      "Epoch 3 — Val Loss: 0.1216, Val F1: 0.9686 (Acc: 0.9685, P: 0.9643, R: 0.9729, F1: 0.9686, ROC: 0.9912, PR: 0.9884)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0654, LR: 2.88e-04\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0063, LR: 2.44e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0530, LR: 2.00e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.4301, LR: 1.57e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0149, LR: 1.17e-04\n",
      "Epoch 4/5 — Train Loss: 0.0392\n",
      "Epoch 4 — Val Loss: 0.1403, Val F1: 0.9705 (Acc: 0.9705, P: 0.9681, R: 0.9729, F1: 0.9705, ROC: 0.9915, PR: 0.9882)\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0174, LR: 8.71e-05\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0261, LR: 5.55e-05\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0201, LR: 3.03e-05\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.0157, LR: 1.23e-05\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0054, LR: 2.22e-06\n",
      "Epoch 5/5 — Train Loss: 0.0318\n",
      "Epoch 5 — Val Loss: 0.1409, Val F1: 0.9724 (Acc: 0.9725, P: 0.9729, R: 0.9719, F1: 0.9724, ROC: 0.9914, PR: 0.9880)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1216\n",
      "\n",
      "Training finished. Total time: 936.49s. Model size: 4140115.30 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9685\n",
      "  - Precision: 0.9643\n",
      "  - Recall: 0.9729\n",
      "  - F1: 0.9686\n",
      "  - Roc_auc: 0.9912\n",
      "  - Pr_auc: 0.9884\n",
      "  - Val_loss: 0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:40:31,918] Trial 2 finished with value: 0.9685785536159601 and parameters: {'max_learning_rate': 0.00047686427118995696, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 14, 'dropout': 0.1, 'weight_decay': 0.0007098155083968054}. Best is trial 2 with value: 0.9685785536159601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9686\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=8.640717728312954e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.8868621856571994e-05, embedding_dim=128, hidden_dims=[64], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.6506, LR: 3.48e-06\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6883, LR: 7.96e-06\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6648, LR: 1.94e-05\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.6370, LR: 3.56e-05\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.5803, LR: 5.36e-05\n",
      "Epoch 1/5 — Train Loss: 0.6565\n",
      "Epoch 1 — Val Loss: 0.6150, Val F1: 0.5399 (Acc: 0.6707, P: 0.8935, R: 0.3868, F1: 0.5399, ROC: 0.9163, PR: 0.8856)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.6360, LR: 6.76e-05\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.5597, LR: 8.02e-05\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.5304, LR: 8.61e-05\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.4781, LR: 8.60e-05\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.3286, LR: 8.42e-05\n",
      "Epoch 2/5 — Train Loss: 0.4652\n",
      "Epoch 2 — Val Loss: 0.3485, Val F1: 0.8765 (Acc: 0.8704, P: 0.8362, R: 0.9208, F1: 0.8765, ROC: 0.9328, PR: 0.9266)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.2682, LR: 8.16e-05\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.3744, LR: 7.73e-05\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.2876, LR: 7.18e-05\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.3173, LR: 6.53e-05\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.3043, LR: 5.81e-05\n",
      "Epoch 3/5 — Train Loss: 0.2739\n",
      "Epoch 3 — Val Loss: 0.2523, Val F1: 0.9183 (Acc: 0.9144, P: 0.8776, R: 0.9629, F1: 0.9183, ROC: 0.9709, PR: 0.9638)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.2615, LR: 5.16e-05\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.1603, LR: 4.37e-05\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.2356, LR: 3.57e-05\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.1866, LR: 2.80e-05\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.2048, LR: 2.08e-05\n",
      "Epoch 4/5 — Train Loss: 0.2154\n",
      "Epoch 4 — Val Loss: 0.2240, Val F1: 0.9257 (Acc: 0.9224, P: 0.8871, R: 0.9679, F1: 0.9257, ROC: 0.9772, PR: 0.9713)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.1827, LR: 1.53e-05\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.2162, LR: 9.72e-06\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.1678, LR: 5.26e-06\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.1434, LR: 2.11e-06\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.3271, LR: 3.55e-07\n",
      "Epoch 5/5 — Train Loss: 0.1999\n",
      "Epoch 5 — Val Loss: 0.2198, Val F1: 0.9277 (Acc: 0.9244, P: 0.8882, R: 0.9709, F1: 0.9277, ROC: 0.9783, PR: 0.9725)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.2198\n",
      "\n",
      "Training finished. Total time: 63.86s. Model size: 2069756.43 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9244\n",
      "  - Precision: 0.8882\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9277\n",
      "  - Roc_auc: 0.9783\n",
      "  - Pr_auc: 0.9725\n",
      "  - Val_loss: 0.2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:41:50,317] Trial 3 finished with value: 0.9277166108185735 and parameters: {'max_learning_rate': 8.640717728312954e-05, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 2, 'dropout': 0.4, 'weight_decay': 4.8868621856571994e-05}. Best is trial 2 with value: 0.9685785536159601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9277\n",
      "Selected hidden_dims: [32, 16] (index 14)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0005493676823427794, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.054951462634546e-05, embedding_dim=256, hidden_dims=[32, 16], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6958, LR: 2.26e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6919, LR: 5.88e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6851, LR: 1.44e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6766, LR: 2.59e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6333, LR: 3.80e-04\n",
      "Epoch 1/5 — Train Loss: 0.6711\n",
      "Epoch 1 — Val Loss: 0.5604, Val F1: 0.8715 (Acc: 0.8604, P: 0.8065, R: 0.9479, F1: 0.8715, ROC: 0.9208, PR: 0.9113)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.5570, LR: 4.42e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.3986, LR: 5.21e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.3480, LR: 5.49e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2158, LR: 5.44e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1632, LR: 5.28e-04\n",
      "Epoch 2/5 — Train Loss: 0.3129\n",
      "Epoch 2 — Val Loss: 0.1799, Val F1: 0.9433 (Acc: 0.9414, P: 0.9136, R: 0.9749, F1: 0.9433, ROC: 0.9849, PR: 0.9791)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1381, LR: 5.15e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0861, LR: 4.85e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0562, LR: 4.46e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1803, LR: 4.01e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1003, LR: 3.51e-04\n",
      "Epoch 3/5 — Train Loss: 0.1472\n",
      "Epoch 3 — Val Loss: 0.1523, Val F1: 0.9585 (Acc: 0.9580, P: 0.9446, R: 0.9729, F1: 0.9585, ROC: 0.9881, PR: 0.9799)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.1492, LR: 3.21e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0789, LR: 2.67e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.1190, LR: 2.14e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0931, LR: 1.62e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0805, LR: 1.16e-04\n",
      "Epoch 4/5 — Train Loss: 0.1006\n",
      "Epoch 4 — Val Loss: 0.1463, Val F1: 0.9620 (Acc: 0.9620, P: 0.9592, R: 0.9649, F1: 0.9620, ROC: 0.9888, PR: 0.9823)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1052, LR: 9.17e-05\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0600, LR: 5.52e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0788, LR: 2.72e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0970, LR: 8.71e-06\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0702, LR: 4.34e-07\n",
      "Epoch 5/5 — Train Loss: 0.0966\n",
      "Epoch 5 — Val Loss: 0.1519, Val F1: 0.9607 (Acc: 0.9605, P: 0.9536, R: 0.9679, F1: 0.9607, ROC: 0.9887, PR: 0.9809)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1463\n",
      "\n",
      "Training finished. Total time: 401.78s. Model size: 4140115.30 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9620\n",
      "  - Precision: 0.9592\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9620\n",
      "  - Roc_auc: 0.9888\n",
      "  - Pr_auc: 0.9823\n",
      "  - Val_loss: 0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:48:57,538] Trial 4 finished with value: 0.962037962037962 and parameters: {'max_learning_rate': 0.0005493676823427794, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 14, 'dropout': 0.2, 'weight_decay': 3.054951462634546e-05}. Best is trial 2 with value: 0.9685785536159601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9620\n",
      "Selected hidden_dims: [16] (index 0)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=3.72307572305381e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=9.980271361663464e-06, embedding_dim=64, hidden_dims=[16], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7324, LR: 1.50e-06\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6952, LR: 3.43e-06\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6869, LR: 8.35e-06\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.6864, LR: 1.53e-05\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.6730, LR: 2.31e-05\n",
      "Epoch 1/5 — Train Loss: 0.7022\n",
      "Epoch 1 — Val Loss: 0.6945, Val F1: 0.1276 (Acc: 0.5210, P: 0.7071, R: 0.0701, F1: 0.1276, ROC: 0.5608, PR: 0.5784)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.6538, LR: 2.91e-05\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.7157, LR: 3.46e-05\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.6791, LR: 3.71e-05\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.6516, LR: 3.71e-05\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.6756, LR: 3.63e-05\n",
      "Epoch 2/5 — Train Loss: 0.6738\n",
      "Epoch 2 — Val Loss: 0.6487, Val F1: 0.5466 (Acc: 0.6687, P: 0.8636, R: 0.3998, F1: 0.5466, ROC: 0.8513, PR: 0.8273)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.6378, LR: 3.52e-05\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.6276, LR: 3.33e-05\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.6126, LR: 3.09e-05\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.6014, LR: 2.82e-05\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.5822, LR: 2.50e-05\n",
      "Epoch 3/5 — Train Loss: 0.6077\n",
      "Epoch 3 — Val Loss: 0.5811, Val F1: 0.7755 (Acc: 0.7928, P: 0.8452, R: 0.7164, F1: 0.7755, ROC: 0.8995, PR: 0.8829)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.5701, LR: 2.22e-05\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.5645, LR: 1.88e-05\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.6109, LR: 1.54e-05\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.5229, LR: 1.21e-05\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.5075, LR: 8.97e-06\n",
      "Epoch 4/5 — Train Loss: 0.5488\n",
      "Epoch 4 — Val Loss: 0.5441, Val F1: 0.7998 (Acc: 0.8063, P: 0.8267, R: 0.7745, F1: 0.7998, ROC: 0.9022, PR: 0.8908)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.5480, LR: 6.60e-06\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.6009, LR: 4.19e-06\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.5226, LR: 2.27e-06\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.5344, LR: 9.07e-07\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.5292, LR: 1.53e-07\n",
      "Epoch 5/5 — Train Loss: 0.5309\n",
      "Epoch 5 — Val Loss: 0.5385, Val F1: 0.8019 (Acc: 0.8073, P: 0.8243, R: 0.7806, F1: 0.8019, ROC: 0.9023, PR: 0.8916)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.5385\n",
      "\n",
      "Training finished. Total time: 42.74s. Model size: 1034693.30 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.8073\n",
      "  - Precision: 0.8243\n",
      "  - Recall: 0.7806\n",
      "  - F1: 0.8019\n",
      "  - Roc_auc: 0.9023\n",
      "  - Pr_auc: 0.8916\n",
      "  - Val_loss: 0.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 10:49:52,828] Trial 5 finished with value: 0.8018528049408131 and parameters: {'max_learning_rate': 3.72307572305381e-05, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.2, 'weight_decay': 9.980271361663464e-06}. Best is trial 2 with value: 0.9685785536159601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.8019\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.00024161654753634412, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=2.361905972968227e-06, embedding_dim=256, hidden_dims=[64], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.6813, LR: 9.73e-06\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6836, LR: 2.23e-05\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6542, LR: 5.42e-05\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.6245, LR: 9.96e-05\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.5437, LR: 1.50e-04\n",
      "Epoch 1/5 — Train Loss: 0.6064\n",
      "Epoch 1 — Val Loss: 0.3654, Val F1: 0.8713 (Acc: 0.8684, P: 0.8517, R: 0.8918, F1: 0.8713, ROC: 0.9360, PR: 0.9304)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.2764, LR: 1.89e-04\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.2503, LR: 2.24e-04\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.1815, LR: 2.41e-04\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.0928, LR: 2.41e-04\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.1290, LR: 2.35e-04\n",
      "Epoch 2/5 — Train Loss: 0.1928\n",
      "Epoch 2 — Val Loss: 0.1594, Val F1: 0.9500 (Acc: 0.9489, P: 0.9291, R: 0.9719, F1: 0.9500, ROC: 0.9886, PR: 0.9779)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.2221, LR: 2.28e-04\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0408, LR: 2.16e-04\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0571, LR: 2.01e-04\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.3398, LR: 1.83e-04\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0913, LR: 1.63e-04\n",
      "Epoch 3/5 — Train Loss: 0.0994\n",
      "Epoch 3 — Val Loss: 0.1461, Val F1: 0.9528 (Acc: 0.9520, P: 0.9345, R: 0.9719, F1: 0.9528, ROC: 0.9908, PR: 0.9878)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.1613, LR: 1.44e-04\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0615, LR: 1.22e-04\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0188, LR: 9.98e-05\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0904, LR: 7.83e-05\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0948, LR: 5.82e-05\n",
      "Epoch 4/5 — Train Loss: 0.0739\n",
      "Epoch 4 — Val Loss: 0.1247, Val F1: 0.9650 (Acc: 0.9650, P: 0.9631, R: 0.9669, F1: 0.9650, ROC: 0.9916, PR: 0.9880)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.0975, LR: 4.28e-05\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.0781, LR: 2.72e-05\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.0284, LR: 1.47e-05\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.2150, LR: 5.89e-06\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.0306, LR: 9.93e-07\n",
      "Epoch 5/5 — Train Loss: 0.0655\n",
      "Epoch 5 — Val Loss: 0.1316, Val F1: 0.9641 (Acc: 0.9640, P: 0.9584, R: 0.9699, F1: 0.9641, ROC: 0.9909, PR: 0.9856)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1247\n",
      "\n",
      "Training finished. Total time: 858.55s. Model size: 4140337.24 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9650\n",
      "  - Precision: 0.9631\n",
      "  - Recall: 0.9669\n",
      "  - F1: 0.9650\n",
      "  - Roc_auc: 0.9916\n",
      "  - Pr_auc: 0.9880\n",
      "  - Val_loss: 0.1247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:04:33,954] Trial 6 finished with value: 0.965 and parameters: {'max_learning_rate': 0.00024161654753634412, 'batch_size': 32, 'embedding_dim': 256, 'hidden_dims_idx': 2, 'dropout': 0.4, 'weight_decay': 2.361905972968227e-06}. Best is trial 2 with value: 0.9685785536159601.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9650\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.00463248659727382, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0002460523448470818, embedding_dim=128, hidden_dims=[256, 128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.6905, LR: 1.87e-04\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6624, LR: 4.27e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.3733, LR: 1.04e-03\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.1334, LR: 1.91e-03\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.0884, LR: 2.87e-03\n",
      "Epoch 1/5 — Train Loss: 0.3796\n",
      "Epoch 1 — Val Loss: 0.2238, Val F1: 0.9523 (Acc: 0.9510, P: 0.9253, R: 0.9810, F1: 0.9523, ROC: 0.9892, PR: 0.9840)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.1222, LR: 3.63e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.1839, LR: 4.30e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.1288, LR: 4.62e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.3243, LR: 4.61e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.0697, LR: 4.51e-03\n",
      "Epoch 2/5 — Train Loss: 0.1050\n",
      "Epoch 2 — Val Loss: 0.2099, Val F1: 0.9532 (Acc: 0.9550, P: 0.9903, R: 0.9188, F1: 0.9532, ROC: 0.9905, PR: 0.9924)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0083, LR: 4.37e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0504, LR: 4.14e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.1211, LR: 3.85e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0158, LR: 3.50e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0001, LR: 3.12e-03\n",
      "Epoch 3/5 — Train Loss: 0.0445\n",
      "Epoch 3 — Val Loss: 0.1193, Val F1: 0.9690 (Acc: 0.9690, P: 0.9680, R: 0.9699, F1: 0.9690, ROC: 0.9957, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0001, LR: 2.77e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0011, LR: 2.34e-03\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0612, LR: 1.91e-03\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.1494, LR: 1.50e-03\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0004, LR: 1.12e-03\n",
      "Epoch 4/5 — Train Loss: 0.0226\n",
      "Epoch 4 — Val Loss: 0.1745, Val F1: 0.9667 (Acc: 0.9670, P: 0.9745, R: 0.9589, F1: 0.9667, ROC: 0.9943, PR: 0.9950)\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.0000, LR: 8.21e-04\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.0001, LR: 5.21e-04\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.0006, LR: 2.82e-04\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.0130, LR: 1.13e-04\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.0165, LR: 1.90e-05\n",
      "Epoch 5/5 — Train Loss: 0.0052\n",
      "Epoch 5 — Val Loss: 0.1717, Val F1: 0.9688 (Acc: 0.9690, P: 0.9737, R: 0.9639, F1: 0.9688, ROC: 0.9943, PR: 0.9950)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1193\n",
      "\n",
      "Training finished. Total time: 83.37s. Model size: 2070559.62 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9690\n",
      "  - Precision: 0.9680\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9690\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9957\n",
      "  - Val_loss: 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:06:11,764] Trial 7 finished with value: 0.968968968968969 and parameters: {'max_learning_rate': 0.00463248659727382, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 0.0002460523448470818}. Best is trial 7 with value: 0.968968968968969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9690\n",
      "Selected hidden_dims: [32, 16] (index 14)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=3.597758807424261e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.5254536321490948e-05, embedding_dim=128, hidden_dims=[32, 16], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6944, LR: 1.44e-06\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.8098, LR: 3.19e-06\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.6756, LR: 7.88e-06\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.7159, LR: 1.46e-05\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.8232, LR: 2.21e-05\n",
      "Epoch 1/5 — Train Loss: 0.7191\n",
      "Epoch 1 — Val Loss: 0.7057, Val F1: 0.0000 (Acc: 0.5005, P: 0.0000, R: 0.0000, F1: 0.0000, ROC: 0.8520, PR: 0.8217)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.6850, LR: 2.78e-05\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.6878, LR: 3.31e-05\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.7271, LR: 3.58e-05\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.5866, LR: 3.58e-05\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.5725, LR: 3.51e-05\n",
      "Epoch 2/5 — Train Loss: 0.6718\n",
      "Epoch 2 — Val Loss: 0.6211, Val F1: 0.0000 (Acc: 0.5005, P: 0.0000, R: 0.0000, F1: 0.0000, ROC: 0.9337, PR: 0.9204)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.6077, LR: 3.41e-05\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.5536, LR: 3.23e-05\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.5931, LR: 3.00e-05\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.5406, LR: 2.74e-05\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.5018, LR: 2.43e-05\n",
      "Epoch 3/5 — Train Loss: 0.5579\n",
      "Epoch 3 — Val Loss: 0.5086, Val F1: 0.6717 (Acc: 0.7402, P: 0.9108, R: 0.5321, F1: 0.6717, ROC: 0.9247, PR: 0.9103)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.5162, LR: 2.17e-05\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.5474, LR: 1.84e-05\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.4904, LR: 1.51e-05\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.5975, LR: 1.18e-05\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.5246, LR: 8.79e-06\n",
      "Epoch 4/5 — Train Loss: 0.4709\n",
      "Epoch 4 — Val Loss: 0.4559, Val F1: 0.7635 (Acc: 0.7858, P: 0.8510, R: 0.6924, F1: 0.7635, ROC: 0.9212, PR: 0.9073)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.5129, LR: 6.57e-06\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.3826, LR: 4.19e-06\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.3706, LR: 2.29e-06\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.4662, LR: 9.31e-07\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.3141, LR: 1.67e-07\n",
      "Epoch 5/5 — Train Loss: 0.4459\n",
      "Epoch 5 — Val Loss: 0.4484, Val F1: 0.7702 (Acc: 0.7898, P: 0.8482, R: 0.7054, F1: 0.7702, ROC: 0.9214, PR: 0.9074)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.4484\n",
      "\n",
      "Training finished. Total time: 111.63s. Model size: 2069646.55 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.7898\n",
      "  - Precision: 0.8482\n",
      "  - Recall: 0.7054\n",
      "  - F1: 0.7702\n",
      "  - Roc_auc: 0.9214\n",
      "  - Pr_auc: 0.9074\n",
      "  - Val_loss: 0.4484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:08:17,447] Trial 8 finished with value: 0.7702407002188184 and parameters: {'max_learning_rate': 3.597758807424261e-05, 'batch_size': 16, 'embedding_dim': 128, 'hidden_dims_idx': 14, 'dropout': 0.2, 'weight_decay': 1.5254536321490948e-05}. Best is trial 7 with value: 0.968968968968969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.7702\n",
      "Selected hidden_dims: [64, 16] (index 13)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.00019903972619363417, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.2916797988710483e-06, embedding_dim=128, hidden_dims=[64, 16], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7201, LR: 8.17e-06\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6809, LR: 2.13e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6800, LR: 5.21e-05\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6817, LR: 9.39e-05\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6863, LR: 1.38e-04\n",
      "Epoch 1/5 — Train Loss: 0.6939\n",
      "Epoch 1 — Val Loss: 0.6869, Val F1: 0.0020 (Acc: 0.5010, P: 1.0000, R: 0.0010, F1: 0.0020, ROC: 0.8819, PR: 0.8434)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.6905, LR: 1.60e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.6659, LR: 1.89e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.6417, LR: 1.99e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.5649, LR: 1.97e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.4969, LR: 1.91e-04\n",
      "Epoch 2/5 — Train Loss: 0.6145\n",
      "Epoch 2 — Val Loss: 0.5277, Val F1: 0.8607 (Acc: 0.8438, P: 0.7762, R: 0.9659, F1: 0.8607, ROC: 0.9100, PR: 0.8986)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.4918, LR: 1.87e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.4994, LR: 1.76e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.4961, LR: 1.62e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.4491, LR: 1.45e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.4157, LR: 1.27e-04\n",
      "Epoch 3/5 — Train Loss: 0.4580\n",
      "Epoch 3 — Val Loss: 0.4310, Val F1: 0.8952 (Acc: 0.8854, P: 0.8239, R: 0.9800, F1: 0.8952, ROC: 0.9661, PR: 0.9595)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.4182, LR: 1.16e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.3977, LR: 9.67e-05\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.3993, LR: 7.74e-05\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.3474, LR: 5.89e-05\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.4106, LR: 4.19e-05\n",
      "Epoch 4/5 — Train Loss: 0.3842\n",
      "Epoch 4 — Val Loss: 0.3713, Val F1: 0.9199 (Acc: 0.9149, P: 0.8683, R: 0.9780, F1: 0.9199, ROC: 0.9828, PR: 0.9794)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.3927, LR: 3.32e-05\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.3642, LR: 2.00e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.3177, LR: 9.86e-06\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.3734, LR: 3.16e-06\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.3616, LR: 1.57e-07\n",
      "Epoch 5/5 — Train Loss: 0.3592\n",
      "Epoch 5 — Val Loss: 0.3631, Val F1: 0.9195 (Acc: 0.9144, P: 0.8676, R: 0.9780, F1: 0.9195, ROC: 0.9828, PR: 0.9795)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.3631\n",
      "\n",
      "Training finished. Total time: 91.96s. Model size: 2069760.80 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9144\n",
      "  - Precision: 0.8676\n",
      "  - Recall: 0.9780\n",
      "  - F1: 0.9195\n",
      "  - Roc_auc: 0.9828\n",
      "  - Pr_auc: 0.9795\n",
      "  - Val_loss: 0.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:10:04,329] Trial 9 finished with value: 0.9194536033914272 and parameters: {'max_learning_rate': 0.00019903972619363417, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 13, 'dropout': 0.2, 'weight_decay': 1.2916797988710483e-06}. Best is trial 7 with value: 0.968968968968969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9195\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.009474260570458054, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00014281990984921708, embedding_dim=128, hidden_dims=[256, 64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7025, LR: 3.82e-04\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.5231, LR: 8.73e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.3203, LR: 2.13e-03\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.3581, LR: 3.90e-03\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.0330, LR: 5.87e-03\n",
      "Epoch 1/5 — Train Loss: 0.3134\n",
      "Epoch 1 — Val Loss: 0.1097, Val F1: 0.9580 (Acc: 0.9575, P: 0.9454, R: 0.9709, F1: 0.9580, ROC: 0.9935, PR: 0.9936)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.0475, LR: 7.42e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.0762, LR: 8.79e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.0991, LR: 9.44e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.1628, LR: 9.43e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.1160, LR: 9.23e-03\n",
      "Epoch 2/5 — Train Loss: 0.1533\n",
      "Epoch 2 — Val Loss: 0.0962, Val F1: 0.9688 (Acc: 0.9690, P: 0.9737, R: 0.9639, F1: 0.9688, ROC: 0.9963, PR: 0.9964)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0019, LR: 8.94e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0041, LR: 8.47e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0023, LR: 7.87e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0001, LR: 7.16e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.1541, LR: 6.37e-03\n",
      "Epoch 3/5 — Train Loss: 0.0517\n",
      "Epoch 3 — Val Loss: 0.2380, Val F1: 0.9665 (Acc: 0.9665, P: 0.9650, R: 0.9679, F1: 0.9665, ROC: 0.9929, PR: 0.9926)\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0340, LR: 5.66e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0072, LR: 4.79e-03\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0002, LR: 3.91e-03\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0020, LR: 3.07e-03\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0019, LR: 2.28e-03\n",
      "Epoch 4/5 — Train Loss: 0.0184\n",
      "Epoch 4 — Val Loss: 0.1682, Val F1: 0.9697 (Acc: 0.9700, P: 0.9776, R: 0.9619, F1: 0.9697, ROC: 0.9948, PR: 0.9948)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0962\n",
      "\n",
      "Training finished. Total time: 63.43s. Model size: 2070494.87 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9690\n",
      "  - Precision: 0.9737\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9688\n",
      "  - Roc_auc: 0.9963\n",
      "  - Pr_auc: 0.9964\n",
      "  - Val_loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:11:22,458] Trial 10 finished with value: 0.9687814702920443 and parameters: {'max_learning_rate': 0.009474260570458054, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 0.00014281990984921708}. Best is trial 7 with value: 0.968968968968969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9688\n",
      "Selected hidden_dims: [256, 32] (index 7)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.009614878948685204, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00015674563930015588, embedding_dim=128, hidden_dims=[256, 32], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.6793, LR: 3.87e-04\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.4864, LR: 8.86e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.1454, LR: 2.16e-03\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.6601, LR: 3.96e-03\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.2033, LR: 5.96e-03\n",
      "Epoch 1/5 — Train Loss: 0.3763\n",
      "Epoch 1 — Val Loss: 0.1179, Val F1: 0.9613 (Acc: 0.9615, P: 0.9647, R: 0.9579, F1: 0.9613, ROC: 0.9928, PR: 0.9927)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.1832, LR: 7.53e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.0217, LR: 8.92e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.0062, LR: 9.58e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.0063, LR: 9.57e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.1171, LR: 9.37e-03\n",
      "Epoch 2/5 — Train Loss: 0.1015\n",
      "Epoch 2 — Val Loss: 0.1487, Val F1: 0.9664 (Acc: 0.9665, P: 0.9669, R: 0.9659, F1: 0.9664, ROC: 0.9945, PR: 0.9941)\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0316, LR: 9.08e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0001, LR: 8.60e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0014, LR: 7.99e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0176, LR: 7.27e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0020, LR: 6.47e-03\n",
      "Epoch 3/5 — Train Loss: 0.0463\n",
      "Epoch 3 — Val Loss: 0.5025, Val F1: 0.9170 (Acc: 0.9229, P: 0.9918, R: 0.8527, F1: 0.9170, ROC: 0.9880, PR: 0.9893)\n",
      "Early stopping triggered after 3 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 1 with Val Loss: 0.1179\n",
      "\n",
      "Training finished. Total time: 81.17s. Model size: 2070462.49 KB\n",
      "Best model (by val_loss) obtained at epoch 1:\n",
      "  - Accuracy: 0.9615\n",
      "  - Precision: 0.9647\n",
      "  - Recall: 0.9579\n",
      "  - F1: 0.9613\n",
      "  - Roc_auc: 0.9928\n",
      "  - Pr_auc: 0.9927\n",
      "  - Val_loss: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:12:58,381] Trial 11 finished with value: 0.9612870789341378 and parameters: {'max_learning_rate': 0.009614878948685204, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 7, 'dropout': 0.5, 'weight_decay': 0.00015674563930015588}. Best is trial 7 with value: 0.968968968968969.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9613\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.008975360627093466, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00011953356837977742, embedding_dim=128, hidden_dims=[256, 64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7025, LR: 3.61e-04\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.5371, LR: 8.27e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.3314, LR: 2.01e-03\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.3630, LR: 3.70e-03\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.0338, LR: 5.57e-03\n",
      "Epoch 1/5 — Train Loss: 0.3142\n",
      "Epoch 1 — Val Loss: 0.1284, Val F1: 0.9515 (Acc: 0.9505, P: 0.9310, R: 0.9729, F1: 0.9515, ROC: 0.9917, PR: 0.9925)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.0699, LR: 7.03e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.0799, LR: 8.33e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.4954, LR: 8.95e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.1250, LR: 8.93e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.0783, LR: 8.75e-03\n",
      "Epoch 2/5 — Train Loss: 0.1118\n",
      "Epoch 2 — Val Loss: 0.1002, Val F1: 0.9696 (Acc: 0.9700, P: 0.9815, R: 0.9579, F1: 0.9696, ROC: 0.9961, PR: 0.9960)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0097, LR: 8.47e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0001, LR: 8.03e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0095, LR: 7.46e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0028, LR: 6.79e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0221, LR: 6.04e-03\n",
      "Epoch 3/5 — Train Loss: 0.0619\n",
      "Epoch 3 — Val Loss: 0.1082, Val F1: 0.9733 (Acc: 0.9735, P: 0.9778, R: 0.9689, F1: 0.9733, ROC: 0.9959, PR: 0.9959)\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0026, LR: 5.36e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0009, LR: 4.54e-03\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0001, LR: 3.71e-03\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0000, LR: 2.91e-03\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0004, LR: 2.16e-03\n",
      "Epoch 4/5 — Train Loss: 0.0117\n",
      "Epoch 4 — Val Loss: 0.1523, Val F1: 0.9714 (Acc: 0.9715, P: 0.9729, R: 0.9699, F1: 0.9714, ROC: 0.9950, PR: 0.9950)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.1002\n",
      "\n",
      "Training finished. Total time: 63.74s. Model size: 2070494.87 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9815\n",
      "  - Recall: 0.9579\n",
      "  - F1: 0.9696\n",
      "  - Roc_auc: 0.9961\n",
      "  - Pr_auc: 0.9960\n",
      "  - Val_loss: 0.1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:14:16,169] Trial 12 finished with value: 0.9695740365111561 and parameters: {'max_learning_rate': 0.008975360627093466, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 0.00011953356837977742}. Best is trial 12 with value: 0.9695740365111561.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9696\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.002218128701578755, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0007959473978236647, embedding_dim=128, hidden_dims=[256, 128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.6905, LR: 8.93e-05\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6849, LR: 2.04e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6066, LR: 4.98e-04\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.1490, LR: 9.14e-04\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.1332, LR: 1.38e-03\n",
      "Epoch 1/5 — Train Loss: 0.4485\n",
      "Epoch 1 — Val Loss: 0.1552, Val F1: 0.9579 (Acc: 0.9575, P: 0.9471, R: 0.9689, F1: 0.9579, ROC: 0.9900, PR: 0.9865)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.1128, LR: 1.74e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.1085, LR: 2.06e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.1292, LR: 2.21e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.3407, LR: 2.21e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.0704, LR: 2.16e-03\n",
      "Epoch 2/5 — Train Loss: 0.1063\n",
      "Epoch 2 — Val Loss: 0.0942, Val F1: 0.9661 (Acc: 0.9665, P: 0.9745, R: 0.9579, F1: 0.9661, ROC: 0.9944, PR: 0.9934)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0264, LR: 2.09e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0184, LR: 1.98e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0744, LR: 1.84e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0149, LR: 1.68e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0079, LR: 1.49e-03\n",
      "Epoch 3/5 — Train Loss: 0.0383\n",
      "Epoch 3 — Val Loss: 0.1132, Val F1: 0.9639 (Acc: 0.9635, P: 0.9512, R: 0.9770, F1: 0.9639, ROC: 0.9948, PR: 0.9950)\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0006, LR: 1.32e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0056, LR: 1.12e-03\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0251, LR: 9.16e-04\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0494, LR: 7.19e-04\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0017, LR: 5.34e-04\n",
      "Epoch 4/5 — Train Loss: 0.0200\n",
      "Epoch 4 — Val Loss: 0.1292, Val F1: 0.9681 (Acc: 0.9680, P: 0.9624, R: 0.9739, F1: 0.9681, ROC: 0.9935, PR: 0.9934)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0942\n",
      "\n",
      "Training finished. Total time: 91.93s. Model size: 2070559.62 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9665\n",
      "  - Precision: 0.9745\n",
      "  - Recall: 0.9579\n",
      "  - F1: 0.9661\n",
      "  - Roc_auc: 0.9944\n",
      "  - Pr_auc: 0.9934\n",
      "  - Val_loss: 0.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:16:02,522] Trial 13 finished with value: 0.966144517433047 and parameters: {'max_learning_rate': 0.002218128701578755, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 0.0007959473978236647}. Best is trial 12 with value: 0.9695740365111561.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9661\n",
      "Selected hidden_dims: [128, 64] (index 9)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.0025714977363574146, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=9.412029297691989e-05, embedding_dim=128, hidden_dims=[128, 64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7015, LR: 1.04e-04\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6787, LR: 2.37e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6367, LR: 5.77e-04\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.3115, LR: 1.06e-03\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.1223, LR: 1.59e-03\n",
      "Epoch 1/5 — Train Loss: 0.4826\n",
      "Epoch 1 — Val Loss: 0.1742, Val F1: 0.9522 (Acc: 0.9530, P: 0.9660, R: 0.9389, F1: 0.9522, ROC: 0.9861, PR: 0.9782)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.0657, LR: 2.01e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.1498, LR: 2.39e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.1144, LR: 2.56e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.2079, LR: 2.56e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.0462, LR: 2.51e-03\n",
      "Epoch 2/5 — Train Loss: 0.1263\n",
      "Epoch 2 — Val Loss: 0.0966, Val F1: 0.9689 (Acc: 0.9690, P: 0.9689, R: 0.9689, F1: 0.9689, ROC: 0.9951, PR: 0.9949)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0167, LR: 2.43e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0091, LR: 2.30e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0042, LR: 2.14e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0097, LR: 1.94e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.1769, LR: 1.73e-03\n",
      "Epoch 3/5 — Train Loss: 0.0425\n",
      "Epoch 3 — Val Loss: 0.1091, Val F1: 0.9734 (Acc: 0.9735, P: 0.9739, R: 0.9729, F1: 0.9734, ROC: 0.9936, PR: 0.9934)\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0170, LR: 1.54e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0004, LR: 1.30e-03\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0003, LR: 1.06e-03\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0005, LR: 8.33e-04\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0002, LR: 6.19e-04\n",
      "Epoch 4/5 — Train Loss: 0.0135\n",
      "Epoch 4 — Val Loss: 0.1352, Val F1: 0.9734 (Acc: 0.9735, P: 0.9749, R: 0.9719, F1: 0.9734, ROC: 0.9936, PR: 0.9936)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0966\n",
      "\n",
      "Training finished. Total time: 60.67s. Model size: 2070013.87 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9690\n",
      "  - Precision: 0.9689\n",
      "  - Recall: 0.9689\n",
      "  - F1: 0.9689\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9949\n",
      "  - Val_loss: 0.0966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:17:17,298] Trial 14 finished with value: 0.968937875751503 and parameters: {'max_learning_rate': 0.0025714977363574146, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 9, 'dropout': 0.5, 'weight_decay': 9.412029297691989e-05}. Best is trial 12 with value: 0.9695740365111561.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9689\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.004140090545887836, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00030671695223794833, embedding_dim=64, hidden_dims=[256], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7020, LR: 1.70e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6390, LR: 4.43e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4727, LR: 1.08e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3344, LR: 1.95e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1330, LR: 2.87e-03\n",
      "Epoch 1/5 — Train Loss: 0.4217\n",
      "Epoch 1 — Val Loss: 0.1864, Val F1: 0.9424 (Acc: 0.9444, P: 0.9774, R: 0.9098, F1: 0.9424, ROC: 0.9866, PR: 0.9818)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1341, LR: 3.33e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2485, LR: 3.93e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.3051, LR: 4.14e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1800, LR: 4.10e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0795, LR: 3.98e-03\n",
      "Epoch 2/5 — Train Loss: 0.1141\n",
      "Epoch 2 — Val Loss: 0.1030, Val F1: 0.9626 (Acc: 0.9625, P: 0.9592, R: 0.9659, F1: 0.9626, ROC: 0.9934, PR: 0.9928)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0359, LR: 3.88e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0395, LR: 3.65e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0125, LR: 3.36e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0118, LR: 3.02e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0196, LR: 2.64e-03\n",
      "Epoch 3/5 — Train Loss: 0.0344\n",
      "Epoch 3 — Val Loss: 0.0946, Val F1: 0.9723 (Acc: 0.9725, P: 0.9787, R: 0.9659, F1: 0.9723, ROC: 0.9953, PR: 0.9954)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0056, LR: 2.42e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0076, LR: 2.01e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0022, LR: 1.61e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0253, LR: 1.22e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0188, LR: 8.72e-04\n",
      "Epoch 4/5 — Train Loss: 0.0148\n",
      "Epoch 4 — Val Loss: 0.0817, Val F1: 0.9720 (Acc: 0.9720, P: 0.9701, R: 0.9739, F1: 0.9720, ROC: 0.9960, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0079, LR: 6.91e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0104, LR: 4.16e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0045, LR: 2.05e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0075, LR: 6.56e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0029, LR: 3.27e-06\n",
      "Epoch 5/5 — Train Loss: 0.0091\n",
      "Epoch 5 — Val Loss: 0.0810, Val F1: 0.9714 (Acc: 0.9715, P: 0.9719, R: 0.9709, F1: 0.9714, ROC: 0.9960, PR: 0.9958)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0810\n",
      "\n",
      "Training finished. Total time: 33.25s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9719\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9714\n",
      "  - Roc_auc: 0.9960\n",
      "  - Pr_auc: 0.9958\n",
      "  - Val_loss: 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:18:03,117] Trial 15 finished with value: 0.9714285714285714 and parameters: {'max_learning_rate': 0.004140090545887836, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 0.00030671695223794833}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9714\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0010462263883440192, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0004167913462931006, embedding_dim=64, hidden_dims=[128], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6957, LR: 4.30e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6904, LR: 1.12e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6539, LR: 2.74e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5819, LR: 4.94e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.4029, LR: 7.25e-04\n",
      "Epoch 1/5 — Train Loss: 0.5982\n",
      "Epoch 1 — Val Loss: 0.3510, Val F1: 0.8658 (Acc: 0.8609, P: 0.8352, R: 0.8988, F1: 0.8658, ROC: 0.9309, PR: 0.9277)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.3257, LR: 8.42e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2982, LR: 9.92e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1897, LR: 1.05e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1940, LR: 1.04e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1676, LR: 1.01e-03\n",
      "Epoch 2/5 — Train Loss: 0.2063\n",
      "Epoch 2 — Val Loss: 0.1708, Val F1: 0.9493 (Acc: 0.9479, P: 0.9241, R: 0.9760, F1: 0.9493, ROC: 0.9888, PR: 0.9808)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1155, LR: 9.81e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0899, LR: 9.23e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0476, LR: 8.49e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1095, LR: 7.63e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1361, LR: 6.68e-04\n",
      "Epoch 3/5 — Train Loss: 0.0994\n",
      "Epoch 3 — Val Loss: 0.1157, Val F1: 0.9636 (Acc: 0.9635, P: 0.9584, R: 0.9689, F1: 0.9636, ROC: 0.9926, PR: 0.9901)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0699, LR: 6.11e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0961, LR: 5.08e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0384, LR: 4.07e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0236, LR: 3.09e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0141, LR: 2.20e-04\n",
      "Epoch 4/5 — Train Loss: 0.0701\n",
      "Epoch 4 — Val Loss: 0.1105, Val F1: 0.9683 (Acc: 0.9685, P: 0.9727, R: 0.9639, F1: 0.9683, ROC: 0.9930, PR: 0.9909)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0241, LR: 1.75e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0321, LR: 1.05e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.1722, LR: 5.18e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0341, LR: 1.66e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0213, LR: 8.27e-07\n",
      "Epoch 5/5 — Train Loss: 0.0598\n",
      "Epoch 5 — Val Loss: 0.1096, Val F1: 0.9683 (Acc: 0.9685, P: 0.9717, R: 0.9649, F1: 0.9683, ROC: 0.9932, PR: 0.9912)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1096\n",
      "\n",
      "Training finished. Total time: 33.47s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9685\n",
      "  - Precision: 0.9717\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9683\n",
      "  - Roc_auc: 0.9932\n",
      "  - Pr_auc: 0.9912\n",
      "  - Val_loss: 0.1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:18:49,624] Trial 16 finished with value: 0.9683257918552036 and parameters: {'max_learning_rate': 0.0010462263883440192, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.4, 'weight_decay': 0.0004167913462931006}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9683\n",
      "Selected hidden_dims: [128, 64] (index 9)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=1.2927548094328915e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=9.428790194913002e-05, embedding_dim=64, hidden_dims=[128, 64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7037, LR: 5.31e-07\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6972, LR: 1.38e-06\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6990, LR: 3.38e-06\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.7072, LR: 6.10e-06\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6950, LR: 8.95e-06\n",
      "Epoch 1/5 — Train Loss: 0.6970\n",
      "Epoch 1 — Val Loss: 0.6958, Val F1: 0.6660 (Acc: 0.4995, P: 0.4995, R: 0.9990, F1: 0.6660, ROC: 0.4720, PR: 0.5063)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.6846, LR: 1.04e-05\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.6970, LR: 1.23e-05\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.7025, LR: 1.29e-05\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.6983, LR: 1.28e-05\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.6811, LR: 1.24e-05\n",
      "Epoch 2/5 — Train Loss: 0.6935\n",
      "Epoch 2 — Val Loss: 0.6920, Val F1: 0.6664 (Acc: 0.5000, P: 0.4997, R: 1.0000, F1: 0.6664, ROC: 0.6330, PR: 0.6306)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.6865, LR: 1.21e-05\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.6884, LR: 1.14e-05\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.6930, LR: 1.05e-05\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.6871, LR: 9.43e-06\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.6737, LR: 8.25e-06\n",
      "Epoch 3/5 — Train Loss: 0.6908\n",
      "Epoch 3 — Val Loss: 0.6888, Val F1: 0.6664 (Acc: 0.5000, P: 0.4997, R: 1.0000, F1: 0.6664, ROC: 0.7380, PR: 0.7166)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.6909, LR: 7.55e-06\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.6972, LR: 6.28e-06\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.6806, LR: 5.03e-06\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.6881, LR: 3.82e-06\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.6787, LR: 2.72e-06\n",
      "Epoch 4/5 — Train Loss: 0.6882\n",
      "Epoch 4 — Val Loss: 0.6872, Val F1: 0.6664 (Acc: 0.5000, P: 0.4997, R: 1.0000, F1: 0.6664, ROC: 0.7761, PR: 0.7492)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.6913, LR: 2.16e-06\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.6715, LR: 1.30e-06\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.6889, LR: 6.40e-07\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.6819, LR: 2.05e-07\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.6922, LR: 1.02e-08\n",
      "Epoch 5/5 — Train Loss: 0.6877\n",
      "Epoch 5 — Val Loss: 0.6870, Val F1: 0.6664 (Acc: 0.5000, P: 0.4997, R: 1.0000, F1: 0.6664, ROC: 0.7816, PR: 0.7542)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.6870\n",
      "\n",
      "Training finished. Total time: 33.16s. Model size: 1034923.49 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.5000\n",
      "  - Precision: 0.4997\n",
      "  - Recall: 1.0000\n",
      "  - F1: 0.6664\n",
      "  - Roc_auc: 0.7816\n",
      "  - Pr_auc: 0.7542\n",
      "  - Val_loss: 0.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:19:35,703] Trial 17 finished with value: 0.6664440734557596 and parameters: {'max_learning_rate': 1.2927548094328915e-05, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 9, 'dropout': 0.30000000000000004, 'weight_decay': 9.428790194913002e-05}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.6664\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.004749449410493503, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.878047869259928e-05, embedding_dim=64, hidden_dims=[256], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7020, LR: 1.95e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6304, LR: 5.08e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4421, LR: 1.24e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3210, LR: 2.24e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1375, LR: 3.29e-03\n",
      "Epoch 1/5 — Train Loss: 0.4125\n",
      "Epoch 1 — Val Loss: 0.1840, Val F1: 0.9442 (Acc: 0.9459, P: 0.9754, R: 0.9148, F1: 0.9442, ROC: 0.9866, PR: 0.9817)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1222, LR: 3.82e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2249, LR: 4.50e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2345, LR: 4.75e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1759, LR: 4.70e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0974, LR: 4.57e-03\n",
      "Epoch 2/5 — Train Loss: 0.1095\n",
      "Epoch 2 — Val Loss: 0.0870, Val F1: 0.9678 (Acc: 0.9680, P: 0.9717, R: 0.9639, F1: 0.9678, ROC: 0.9952, PR: 0.9940)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0342, LR: 4.45e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0342, LR: 4.19e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0109, LR: 3.86e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0117, LR: 3.46e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0188, LR: 3.03e-03\n",
      "Epoch 3/5 — Train Loss: 0.0324\n",
      "Epoch 3 — Val Loss: 0.0912, Val F1: 0.9700 (Acc: 0.9700, P: 0.9690, R: 0.9709, F1: 0.9700, ROC: 0.9954, PR: 0.9958)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0047, LR: 2.77e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0033, LR: 2.31e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0014, LR: 1.85e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0319, LR: 1.40e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0169, LR: 1.00e-03\n",
      "Epoch 4/5 — Train Loss: 0.0117\n",
      "Epoch 4 — Val Loss: 0.0901, Val F1: 0.9713 (Acc: 0.9715, P: 0.9748, R: 0.9679, F1: 0.9713, ROC: 0.9954, PR: 0.9958)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0870\n",
      "\n",
      "Training finished. Total time: 28.48s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9680\n",
      "  - Precision: 0.9717\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9678\n",
      "  - Roc_auc: 0.9952\n",
      "  - Pr_auc: 0.9940\n",
      "  - Val_loss: 0.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:20:16,533] Trial 18 finished with value: 0.9678068410462777 and parameters: {'max_learning_rate': 0.004749449410493503, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 4.878047869259928e-05}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9678\n",
      "Selected hidden_dims: [256, 32] (index 7)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.001166643397544032, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=5.847394899470475e-06, embedding_dim=64, hidden_dims=[256, 32], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6970, LR: 4.79e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6905, LR: 1.25e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6722, LR: 3.05e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6479, LR: 5.51e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.4872, LR: 8.08e-04\n",
      "Epoch 1/5 — Train Loss: 0.6321\n",
      "Epoch 1 — Val Loss: 0.3665, Val F1: 0.8563 (Acc: 0.8534, P: 0.8386, R: 0.8747, F1: 0.8563, ROC: 0.9291, PR: 0.9236)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.3379, LR: 9.39e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1759, LR: 1.11e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1177, LR: 1.17e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0233, LR: 1.16e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1085, LR: 1.12e-03\n",
      "Epoch 2/5 — Train Loss: 0.2080\n",
      "Epoch 2 — Val Loss: 0.1592, Val F1: 0.9610 (Acc: 0.9610, P: 0.9600, R: 0.9619, F1: 0.9610, ROC: 0.9899, PR: 0.9785)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0685, LR: 1.09e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0813, LR: 1.03e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0883, LR: 9.47e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0461, LR: 8.51e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1309, LR: 7.45e-04\n",
      "Epoch 3/5 — Train Loss: 0.0926\n",
      "Epoch 3 — Val Loss: 0.1040, Val F1: 0.9675 (Acc: 0.9675, P: 0.9651, R: 0.9699, F1: 0.9675, ROC: 0.9930, PR: 0.9913)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0223, LR: 6.81e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0824, LR: 5.67e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0898, LR: 4.54e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0741, LR: 3.45e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0743, LR: 2.46e-04\n",
      "Epoch 4/5 — Train Loss: 0.0530\n",
      "Epoch 4 — Val Loss: 0.1035, Val F1: 0.9685 (Acc: 0.9685, P: 0.9670, R: 0.9699, F1: 0.9685, ROC: 0.9938, PR: 0.9930)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1032, LR: 1.95e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.1181, LR: 1.17e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0245, LR: 5.78e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0729, LR: 1.85e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0239, LR: 9.22e-07\n",
      "Epoch 5/5 — Train Loss: 0.0433\n",
      "Epoch 5 — Val Loss: 0.1034, Val F1: 0.9685 (Acc: 0.9685, P: 0.9680, R: 0.9689, F1: 0.9685, ROC: 0.9939, PR: 0.9931)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1034\n",
      "\n",
      "Training finished. Total time: 33.46s. Model size: 1035148.12 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9685\n",
      "  - Precision: 0.9680\n",
      "  - Recall: 0.9689\n",
      "  - F1: 0.9685\n",
      "  - Roc_auc: 0.9939\n",
      "  - Pr_auc: 0.9931\n",
      "  - Val_loss: 0.1034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:21:02,259] Trial 19 finished with value: 0.9684526790185278 and parameters: {'max_learning_rate': 0.001166643397544032, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 5.847394899470475e-06}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9685\n",
      "Selected hidden_dims: [16] (index 0)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.004855607694347289, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00037698615185622356, embedding_dim=64, hidden_dims=[16], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7276, LR: 1.99e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6578, LR: 5.20e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5409, LR: 1.27e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3127, LR: 2.29e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.5074, LR: 3.36e-03\n",
      "Epoch 1/5 — Train Loss: 0.5105\n",
      "Epoch 1 — Val Loss: 0.2053, Val F1: 0.9459 (Acc: 0.9459, P: 0.9459, R: 0.9459, F1: 0.9459, ROC: 0.9851, PR: 0.9788)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2455, LR: 3.91e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0996, LR: 4.61e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1732, LR: 4.86e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1863, LR: 4.81e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1624, LR: 4.67e-03\n",
      "Epoch 2/5 — Train Loss: 0.1464\n",
      "Epoch 2 — Val Loss: 0.1000, Val F1: 0.9638 (Acc: 0.9640, P: 0.9667, R: 0.9609, F1: 0.9638, ROC: 0.9934, PR: 0.9925)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0364, LR: 4.55e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0736, LR: 4.28e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0747, LR: 3.94e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0375, LR: 3.54e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0219, LR: 3.10e-03\n",
      "Epoch 3/5 — Train Loss: 0.0596\n",
      "Epoch 3 — Val Loss: 0.0911, Val F1: 0.9675 (Acc: 0.9675, P: 0.9670, R: 0.9679, F1: 0.9675, ROC: 0.9953, PR: 0.9961)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0691, LR: 2.83e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0333, LR: 2.36e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0265, LR: 1.89e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0107, LR: 1.44e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0195, LR: 1.02e-03\n",
      "Epoch 4/5 — Train Loss: 0.0324\n",
      "Epoch 4 — Val Loss: 0.0879, Val F1: 0.9700 (Acc: 0.9700, P: 0.9690, R: 0.9709, F1: 0.9700, ROC: 0.9957, PR: 0.9966)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0342, LR: 8.10e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0206, LR: 4.88e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0531, LR: 2.40e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0197, LR: 7.70e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0292, LR: 3.84e-06\n",
      "Epoch 5/5 — Train Loss: 0.0246\n",
      "Epoch 5 — Val Loss: 0.0910, Val F1: 0.9690 (Acc: 0.9690, P: 0.9671, R: 0.9709, F1: 0.9690, ROC: 0.9957, PR: 0.9965)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0879\n",
      "\n",
      "Training finished. Total time: 33.01s. Model size: 1034693.30 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9690\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9700\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9966\n",
      "  - Val_loss: 0.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:21:47,962] Trial 20 finished with value: 0.96996996996997 and parameters: {'max_learning_rate': 0.004855607694347289, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.4, 'weight_decay': 0.00037698615185622356}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9700\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0052173042925733664, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00028864678014902686, embedding_dim=64, hidden_dims=[32], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6855, LR: 2.14e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6788, LR: 5.58e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4926, LR: 1.37e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3747, LR: 2.46e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2277, LR: 3.61e-03\n",
      "Epoch 1/5 — Train Loss: 0.4619\n",
      "Epoch 1 — Val Loss: 0.1840, Val F1: 0.9434 (Acc: 0.9419, P: 0.9200, R: 0.9679, F1: 0.9434, ROC: 0.9855, PR: 0.9748)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1345, LR: 4.20e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0682, LR: 4.95e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1860, LR: 5.22e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1921, LR: 5.17e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1047, LR: 5.02e-03\n",
      "Epoch 2/5 — Train Loss: 0.1294\n",
      "Epoch 2 — Val Loss: 0.1006, Val F1: 0.9655 (Acc: 0.9655, P: 0.9640, R: 0.9669, F1: 0.9655, ROC: 0.9941, PR: 0.9940)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0848, LR: 4.89e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0201, LR: 4.60e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0448, LR: 4.24e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0515, LR: 3.81e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0828, LR: 3.33e-03\n",
      "Epoch 3/5 — Train Loss: 0.0562\n",
      "Epoch 3 — Val Loss: 0.0993, Val F1: 0.9695 (Acc: 0.9700, P: 0.9835, R: 0.9559, F1: 0.9695, ROC: 0.9951, PR: 0.9952)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0686, LR: 3.05e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0071, LR: 2.54e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0155, LR: 2.03e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0717, LR: 1.54e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0142, LR: 1.10e-03\n",
      "Epoch 4/5 — Train Loss: 0.0250\n",
      "Epoch 4 — Val Loss: 0.1143, Val F1: 0.9688 (Acc: 0.9690, P: 0.9718, R: 0.9659, F1: 0.9688, ROC: 0.9943, PR: 0.9948)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0221, LR: 8.70e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0084, LR: 5.24e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0076, LR: 2.58e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0121, LR: 8.27e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0242, LR: 4.12e-06\n",
      "Epoch 5/5 — Train Loss: 0.0177\n",
      "Epoch 5 — Val Loss: 0.1151, Val F1: 0.9688 (Acc: 0.9690, P: 0.9718, R: 0.9659, F1: 0.9688, ROC: 0.9943, PR: 0.9948)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0993\n",
      "\n",
      "Training finished. Total time: 32.88s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9835\n",
      "  - Recall: 0.9559\n",
      "  - F1: 0.9695\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9952\n",
      "  - Val_loss: 0.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:22:33,649] Trial 21 finished with value: 0.9695121951219512 and parameters: {'max_learning_rate': 0.0052173042925733664, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.4, 'weight_decay': 0.00028864678014902686}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9695\n",
      "Selected hidden_dims: [16] (index 0)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0013746221777638922, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0005069913565025937, embedding_dim=64, hidden_dims=[16], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7276, LR: 5.65e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6787, LR: 1.47e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6529, LR: 3.60e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6214, LR: 6.49e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.5618, LR: 9.52e-04\n",
      "Epoch 1/5 — Train Loss: 0.6286\n",
      "Epoch 1 — Val Loss: 0.4057, Val F1: 0.8300 (Acc: 0.8233, P: 0.7989, R: 0.8637, F1: 0.8300, ROC: 0.9081, PR: 0.9029)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.3130, LR: 1.11e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2480, LR: 1.30e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2224, LR: 1.37e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2624, LR: 1.36e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2171, LR: 1.32e-03\n",
      "Epoch 2/5 — Train Loss: 0.2466\n",
      "Epoch 2 — Val Loss: 0.1984, Val F1: 0.9461 (Acc: 0.9444, P: 0.9172, R: 0.9770, F1: 0.9461, ROC: 0.9871, PR: 0.9765)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1176, LR: 1.29e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1094, LR: 1.21e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.1626, LR: 1.12e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1307, LR: 1.00e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0700, LR: 8.78e-04\n",
      "Epoch 3/5 — Train Loss: 0.1325\n",
      "Epoch 3 — Val Loss: 0.1316, Val F1: 0.9568 (Acc: 0.9565, P: 0.9479, R: 0.9659, F1: 0.9568, ROC: 0.9903, PR: 0.9885)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.1836, LR: 8.02e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.1009, LR: 6.68e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0892, LR: 5.34e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0838, LR: 4.07e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0836, LR: 2.90e-04\n",
      "Epoch 4/5 — Train Loss: 0.1009\n",
      "Epoch 4 — Val Loss: 0.1266, Val F1: 0.9623 (Acc: 0.9625, P: 0.9648, R: 0.9599, F1: 0.9623, ROC: 0.9911, PR: 0.9893)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1277, LR: 2.29e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0445, LR: 1.38e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.1287, LR: 6.81e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0489, LR: 2.18e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0973, LR: 1.09e-06\n",
      "Epoch 5/5 — Train Loss: 0.0919\n",
      "Epoch 5 — Val Loss: 0.1264, Val F1: 0.9606 (Acc: 0.9605, P: 0.9554, R: 0.9659, F1: 0.9606, ROC: 0.9915, PR: 0.9904)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1264\n",
      "\n",
      "Training finished. Total time: 33.44s. Model size: 1034693.30 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9605\n",
      "  - Precision: 0.9554\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9606\n",
      "  - Roc_auc: 0.9915\n",
      "  - Pr_auc: 0.9904\n",
      "  - Val_loss: 0.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:23:19,814] Trial 22 finished with value: 0.9606377678126558 and parameters: {'max_learning_rate': 0.0013746221777638922, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.4, 'weight_decay': 0.0005069913565025937}. Best is trial 15 with value: 0.9714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9606\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005856428094809981, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00016062404609637696, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 2.41e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6336, LR: 6.27e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4106, LR: 1.53e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2002, LR: 2.76e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3360, LR: 4.06e-03\n",
      "Epoch 1/5 — Train Loss: 0.4170\n",
      "Epoch 1 — Val Loss: 0.1423, Val F1: 0.9491 (Acc: 0.9489, P: 0.9453, R: 0.9529, F1: 0.9491, ROC: 0.9890, PR: 0.9837)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0774, LR: 4.71e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1276, LR: 5.55e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1144, LR: 5.86e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0762, LR: 5.80e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1111, LR: 5.63e-03\n",
      "Epoch 2/5 — Train Loss: 0.1155\n",
      "Epoch 2 — Val Loss: 0.1000, Val F1: 0.9692 (Acc: 0.9695, P: 0.9756, R: 0.9629, F1: 0.9692, ROC: 0.9939, PR: 0.9936)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0468, LR: 5.49e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0262, LR: 5.17e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0172, LR: 4.75e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0218, LR: 4.27e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0888, LR: 3.74e-03\n",
      "Epoch 3/5 — Train Loss: 0.0401\n",
      "Epoch 3 — Val Loss: 0.0959, Val F1: 0.9728 (Acc: 0.9730, P: 0.9768, R: 0.9689, F1: 0.9728, ROC: 0.9952, PR: 0.9954)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0091, LR: 3.42e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0097, LR: 2.85e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0102, LR: 2.28e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0036, LR: 1.73e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0003, LR: 1.23e-03\n",
      "Epoch 4/5 — Train Loss: 0.0143\n",
      "Epoch 4 — Val Loss: 0.0994, Val F1: 0.9730 (Acc: 0.9730, P: 0.9720, R: 0.9739, F1: 0.9730, ROC: 0.9953, PR: 0.9956)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0016, LR: 9.77e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0012, LR: 5.89e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0430, LR: 2.90e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0015, LR: 9.28e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0031, LR: 4.63e-06\n",
      "Epoch 5/5 — Train Loss: 0.0083\n",
      "Epoch 5 — Val Loss: 0.1020, Val F1: 0.9730 (Acc: 0.9730, P: 0.9711, R: 0.9749, F1: 0.9730, ROC: 0.9952, PR: 0.9956)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0959\n",
      "\n",
      "Training finished. Total time: 33.13s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9730\n",
      "  - Precision: 0.9768\n",
      "  - Recall: 0.9689\n",
      "  - F1: 0.9728\n",
      "  - Roc_auc: 0.9952\n",
      "  - Pr_auc: 0.9954\n",
      "  - Val_loss: 0.0959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:24:05,650] Trial 23 finished with value: 0.9728370221327968 and parameters: {'max_learning_rate': 0.005856428094809981, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 0.00016062404609637696}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9728\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0038913719133630937, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00019478758771012758, embedding_dim=64, hidden_dims=[128], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6935, LR: 1.60e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6483, LR: 4.16e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5086, LR: 1.02e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2494, LR: 1.84e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2173, LR: 2.69e-03\n",
      "Epoch 1/5 — Train Loss: 0.4506\n",
      "Epoch 1 — Val Loss: 0.1543, Val F1: 0.9437 (Acc: 0.9424, P: 0.9225, R: 0.9659, F1: 0.9437, ROC: 0.9877, PR: 0.9827)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0915, LR: 3.13e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1302, LR: 3.69e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0977, LR: 3.89e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0872, LR: 3.85e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1218, LR: 3.74e-03\n",
      "Epoch 2/5 — Train Loss: 0.1176\n",
      "Epoch 2 — Val Loss: 0.1095, Val F1: 0.9653 (Acc: 0.9660, P: 0.9834, R: 0.9479, F1: 0.9653, ROC: 0.9942, PR: 0.9925)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0508, LR: 3.65e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0184, LR: 3.43e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0173, LR: 3.16e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0304, LR: 2.84e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1068, LR: 2.48e-03\n",
      "Epoch 3/5 — Train Loss: 0.0417\n",
      "Epoch 3 — Val Loss: 0.0936, Val F1: 0.9689 (Acc: 0.9690, P: 0.9708, R: 0.9669, F1: 0.9689, ROC: 0.9948, PR: 0.9945)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0140, LR: 2.27e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0149, LR: 1.89e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0188, LR: 1.51e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0027, LR: 1.15e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0006, LR: 8.20e-04\n",
      "Epoch 4/5 — Train Loss: 0.0175\n",
      "Epoch 4 — Val Loss: 0.0885, Val F1: 0.9708 (Acc: 0.9710, P: 0.9767, R: 0.9649, F1: 0.9708, ROC: 0.9956, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0021, LR: 6.49e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0020, LR: 3.91e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0499, LR: 1.93e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0041, LR: 6.17e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0063, LR: 3.08e-06\n",
      "Epoch 5/5 — Train Loss: 0.0104\n",
      "Epoch 5 — Val Loss: 0.0891, Val F1: 0.9718 (Acc: 0.9720, P: 0.9758, R: 0.9679, F1: 0.9718, ROC: 0.9957, PR: 0.9958)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0885\n",
      "\n",
      "Training finished. Total time: 33.39s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9767\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9708\n",
      "  - Roc_auc: 0.9956\n",
      "  - Pr_auc: 0.9957\n",
      "  - Val_loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:24:51,481] Trial 24 finished with value: 0.9707661290322581 and parameters: {'max_learning_rate': 0.0038913719133630937, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.30000000000000004, 'weight_decay': 0.00019478758771012758}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9708\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0028066157056636713, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0002029163347206826, embedding_dim=64, hidden_dims=[128], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6935, LR: 1.15e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6610, LR: 3.00e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5687, LR: 7.35e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3198, LR: 1.32e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3024, LR: 1.94e-03\n",
      "Epoch 1/5 — Train Loss: 0.4905\n",
      "Epoch 1 — Val Loss: 0.1888, Val F1: 0.9373 (Acc: 0.9369, P: 0.9308, R: 0.9439, F1: 0.9373, ROC: 0.9849, PR: 0.9799)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1608, LR: 2.26e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1528, LR: 2.66e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1126, LR: 2.81e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1371, LR: 2.78e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1303, LR: 2.70e-03\n",
      "Epoch 2/5 — Train Loss: 0.1286\n",
      "Epoch 2 — Val Loss: 0.1146, Val F1: 0.9645 (Acc: 0.9650, P: 0.9754, R: 0.9539, F1: 0.9645, ROC: 0.9932, PR: 0.9900)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0509, LR: 2.63e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0371, LR: 2.48e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0230, LR: 2.28e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0464, LR: 2.05e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1150, LR: 1.79e-03\n",
      "Epoch 3/5 — Train Loss: 0.0517\n",
      "Epoch 3 — Val Loss: 0.0954, Val F1: 0.9692 (Acc: 0.9695, P: 0.9756, R: 0.9629, F1: 0.9692, ROC: 0.9947, PR: 0.9943)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0234, LR: 1.64e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0330, LR: 1.36e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0167, LR: 1.09e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0059, LR: 8.30e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0012, LR: 5.91e-04\n",
      "Epoch 4/5 — Train Loss: 0.0246\n",
      "Epoch 4 — Val Loss: 0.0917, Val F1: 0.9698 (Acc: 0.9700, P: 0.9737, R: 0.9659, F1: 0.9698, ROC: 0.9954, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0035, LR: 4.68e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0035, LR: 2.82e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0702, LR: 1.39e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0121, LR: 4.45e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0062, LR: 2.22e-06\n",
      "Epoch 5/5 — Train Loss: 0.0159\n",
      "Epoch 5 — Val Loss: 0.0925, Val F1: 0.9703 (Acc: 0.9705, P: 0.9738, R: 0.9669, F1: 0.9703, ROC: 0.9954, PR: 0.9955)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0917\n",
      "\n",
      "Training finished. Total time: 33.34s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9737\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9698\n",
      "  - Roc_auc: 0.9954\n",
      "  - Pr_auc: 0.9955\n",
      "  - Val_loss: 0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:25:37,594] Trial 25 finished with value: 0.9698189134808853 and parameters: {'max_learning_rate': 0.0028066157056636713, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.30000000000000004, 'weight_decay': 0.0002029163347206826}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9698\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0016145541448908181, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.000978234595442972, embedding_dim=64, hidden_dims=[256], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7005, LR: 6.63e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6673, LR: 1.73e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6088, LR: 4.23e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4435, LR: 7.62e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2627, LR: 1.12e-03\n",
      "Epoch 1/5 — Train Loss: 0.5234\n",
      "Epoch 1 — Val Loss: 0.2671, Val F1: 0.8986 (Acc: 0.8949, P: 0.8669, R: 0.9329, F1: 0.8986, ROC: 0.9544, PR: 0.9516)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1062, LR: 1.30e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1998, LR: 1.53e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.4472, LR: 1.61e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2133, LR: 1.60e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0975, LR: 1.55e-03\n",
      "Epoch 2/5 — Train Loss: 0.1567\n",
      "Epoch 2 — Val Loss: 0.1165, Val F1: 0.9590 (Acc: 0.9585, P: 0.9455, R: 0.9729, F1: 0.9590, ROC: 0.9929, PR: 0.9889)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0709, LR: 1.51e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0487, LR: 1.42e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0369, LR: 1.31e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0328, LR: 1.18e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0299, LR: 1.03e-03\n",
      "Epoch 3/5 — Train Loss: 0.0686\n",
      "Epoch 3 — Val Loss: 0.0950, Val F1: 0.9713 (Acc: 0.9715, P: 0.9748, R: 0.9679, F1: 0.9713, ROC: 0.9949, PR: 0.9935)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0276, LR: 9.43e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0361, LR: 7.85e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0261, LR: 6.28e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.1028, LR: 4.78e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0497, LR: 3.40e-04\n",
      "Epoch 4/5 — Train Loss: 0.0417\n",
      "Epoch 4 — Val Loss: 0.0921, Val F1: 0.9697 (Acc: 0.9700, P: 0.9766, R: 0.9629, F1: 0.9697, ROC: 0.9949, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0488, LR: 2.69e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0222, LR: 1.62e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0136, LR: 8.00e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0291, LR: 2.56e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0206, LR: 1.28e-06\n",
      "Epoch 5/5 — Train Loss: 0.0316\n",
      "Epoch 5 — Val Loss: 0.0920, Val F1: 0.9717 (Acc: 0.9720, P: 0.9787, R: 0.9649, F1: 0.9717, ROC: 0.9949, PR: 0.9939)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0920\n",
      "\n",
      "Training finished. Total time: 33.06s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9720\n",
      "  - Precision: 0.9787\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9717\n",
      "  - Roc_auc: 0.9949\n",
      "  - Pr_auc: 0.9939\n",
      "  - Val_loss: 0.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:26:23,375] Trial 26 finished with value: 0.9717457114026236 and parameters: {'max_learning_rate': 0.0016145541448908181, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.30000000000000004, 'weight_decay': 0.000978234595442972}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9717\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.000717485636560264, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.000965204756403488, embedding_dim=64, hidden_dims=[256], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6985, LR: 2.95e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6785, LR: 7.68e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6508, LR: 1.88e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5875, LR: 3.39e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.4538, LR: 4.97e-04\n",
      "Epoch 1/5 — Train Loss: 0.6031\n",
      "Epoch 1 — Val Loss: 0.3639, Val F1: 0.8738 (Acc: 0.8699, P: 0.8475, R: 0.9018, F1: 0.8738, ROC: 0.9377, PR: 0.9321)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2481, LR: 5.77e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.3012, LR: 6.80e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2862, LR: 7.17e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2167, LR: 7.11e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1462, LR: 6.90e-04\n",
      "Epoch 2/5 — Train Loss: 0.2066\n",
      "Epoch 2 — Val Loss: 0.1365, Val F1: 0.9573 (Acc: 0.9570, P: 0.9479, R: 0.9669, F1: 0.9573, ROC: 0.9900, PR: 0.9846)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1185, LR: 6.73e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0591, LR: 6.33e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0670, LR: 5.82e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0583, LR: 5.23e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0518, LR: 4.58e-04\n",
      "Epoch 3/5 — Train Loss: 0.0979\n",
      "Epoch 3 — Val Loss: 0.1125, Val F1: 0.9650 (Acc: 0.9650, P: 0.9622, R: 0.9679, F1: 0.9650, ROC: 0.9932, PR: 0.9904)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0507, LR: 4.19e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0623, LR: 3.49e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0426, LR: 2.79e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.1423, LR: 2.12e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0686, LR: 1.51e-04\n",
      "Epoch 4/5 — Train Loss: 0.0679\n",
      "Epoch 4 — Val Loss: 0.1123, Val F1: 0.9671 (Acc: 0.9675, P: 0.9765, R: 0.9579, F1: 0.9671, ROC: 0.9934, PR: 0.9907)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0982, LR: 1.20e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0437, LR: 7.21e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0449, LR: 3.55e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0646, LR: 1.14e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0498, LR: 5.67e-07\n",
      "Epoch 5/5 — Train Loss: 0.0571\n",
      "Epoch 5 — Val Loss: 0.1072, Val F1: 0.9664 (Acc: 0.9665, P: 0.9678, R: 0.9649, F1: 0.9664, ROC: 0.9936, PR: 0.9914)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1072\n",
      "\n",
      "Training finished. Total time: 33.13s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9665\n",
      "  - Precision: 0.9678\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9664\n",
      "  - Roc_auc: 0.9936\n",
      "  - Pr_auc: 0.9914\n",
      "  - Val_loss: 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:27:10,620] Trial 27 finished with value: 0.9663823381836427 and parameters: {'max_learning_rate': 0.000717485636560264, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.1, 'weight_decay': 0.000965204756403488}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9664\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.00163149087413567, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=5.622740174265438e-05, embedding_dim=64, hidden_dims=[64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6865, LR: 6.70e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6763, LR: 1.75e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6488, LR: 4.27e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5422, LR: 7.70e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3530, LR: 1.13e-03\n",
      "Epoch 1/5 — Train Loss: 0.5773\n",
      "Epoch 1 — Val Loss: 0.3538, Val F1: 0.8585 (Acc: 0.8514, P: 0.8183, R: 0.9028, F1: 0.8585, ROC: 0.9214, PR: 0.9171)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.4417, LR: 1.31e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2680, LR: 1.55e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1568, LR: 1.63e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2167, LR: 1.62e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2168, LR: 1.57e-03\n",
      "Epoch 2/5 — Train Loss: 0.2035\n",
      "Epoch 2 — Val Loss: 0.1531, Val F1: 0.9469 (Acc: 0.9449, P: 0.9142, R: 0.9820, F1: 0.9469, ROC: 0.9906, PR: 0.9853)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1108, LR: 1.53e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0635, LR: 1.44e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0325, LR: 1.32e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0777, LR: 1.19e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0656, LR: 1.04e-03\n",
      "Epoch 3/5 — Train Loss: 0.1025\n",
      "Epoch 3 — Val Loss: 0.1082, Val F1: 0.9673 (Acc: 0.9675, P: 0.9726, R: 0.9619, F1: 0.9673, ROC: 0.9929, PR: 0.9896)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0466, LR: 9.52e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0753, LR: 7.93e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0754, LR: 6.34e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0423, LR: 4.83e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0234, LR: 3.44e-04\n",
      "Epoch 4/5 — Train Loss: 0.0678\n",
      "Epoch 4 — Val Loss: 0.0993, Val F1: 0.9683 (Acc: 0.9685, P: 0.9727, R: 0.9639, F1: 0.9683, ROC: 0.9938, PR: 0.9918)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0641, LR: 2.72e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0298, LR: 1.64e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0467, LR: 8.08e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0801, LR: 2.59e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0723, LR: 1.29e-06\n",
      "Epoch 5/5 — Train Loss: 0.0560\n",
      "Epoch 5 — Val Loss: 0.0988, Val F1: 0.9682 (Acc: 0.9685, P: 0.9766, R: 0.9599, F1: 0.9682, ROC: 0.9940, PR: 0.9919)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0988\n",
      "\n",
      "Training finished. Total time: 33.22s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9685\n",
      "  - Precision: 0.9766\n",
      "  - Recall: 0.9599\n",
      "  - F1: 0.9682\n",
      "  - Roc_auc: 0.9940\n",
      "  - Pr_auc: 0.9919\n",
      "  - Val_loss: 0.0988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:27:56,252] Trial 28 finished with value: 0.9681657402728651 and parameters: {'max_learning_rate': 0.00163149087413567, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 5.622740174265438e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9682\n",
      "Selected hidden_dims: [256, 16] (index 8)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.001863101980913933, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0005585386420247639, embedding_dim=256, hidden_dims=[256, 16], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6819, LR: 7.47e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6474, LR: 1.65e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.5229, LR: 4.08e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.6531, LR: 7.56e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.0603, LR: 1.14e-03\n",
      "Epoch 1/5 — Train Loss: 0.3906\n",
      "Epoch 1 — Val Loss: 0.1922, Val F1: 0.9541 (Acc: 0.9540, P: 0.9494, R: 0.9589, F1: 0.9541, ROC: 0.9878, PR: 0.9850)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.1995, LR: 1.44e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0211, LR: 1.72e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0631, LR: 1.85e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.1139, LR: 1.86e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0063, LR: 1.82e-03\n",
      "Epoch 2/5 — Train Loss: 0.1372\n",
      "Epoch 2 — Val Loss: 0.1063, Val F1: 0.9712 (Acc: 0.9715, P: 0.9786, R: 0.9639, F1: 0.9712, ROC: 0.9939, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0166, LR: 1.76e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0436, LR: 1.67e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0231, LR: 1.56e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0035, LR: 1.42e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.9267, LR: 1.26e-03\n",
      "Epoch 3/5 — Train Loss: 0.0687\n",
      "Epoch 3 — Val Loss: 0.1269, Val F1: 0.9687 (Acc: 0.9690, P: 0.9756, R: 0.9619, F1: 0.9687, ROC: 0.9954, PR: 0.9957)\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0616, LR: 1.13e-03\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0336, LR: 9.53e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0403, LR: 7.80e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0003, LR: 6.12e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0006, LR: 4.55e-04\n",
      "Epoch 4/5 — Train Loss: 0.0330\n",
      "Epoch 4 — Val Loss: 0.1511, Val F1: 0.9728 (Acc: 0.9730, P: 0.9787, R: 0.9669, F1: 0.9728, ROC: 0.9942, PR: 0.9944)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.1063\n",
      "\n",
      "Training finished. Total time: 1092.10s. Model size: 4141699.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9786\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9712\n",
      "  - Roc_auc: 0.9939\n",
      "  - Pr_auc: 0.9938\n",
      "  - Val_loss: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:46:33,986] Trial 29 finished with value: 0.9712266532054518 and parameters: {'max_learning_rate': 0.001863101980913933, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 8, 'dropout': 0.4, 'weight_decay': 0.0005585386420247639}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9712\n",
      "Selected hidden_dims: [128, 16] (index 11)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0008743174015609711, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0009120220055117417, embedding_dim=64, hidden_dims=[128, 16], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6897, LR: 3.50e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6958, LR: 7.76e-05\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.6514, LR: 1.91e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.5106, LR: 3.55e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.4027, LR: 5.37e-04\n",
      "Epoch 1/5 — Train Loss: 0.5556\n",
      "Epoch 1 — Val Loss: 0.2130, Val F1: 0.9374 (Acc: 0.9349, P: 0.9019, R: 0.9760, F1: 0.9374, ROC: 0.9822, PR: 0.9752)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.1519, LR: 6.75e-04\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.2227, LR: 8.05e-04\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.1570, LR: 8.70e-04\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.2612, LR: 8.71e-04\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0734, LR: 8.53e-04\n",
      "Epoch 2/5 — Train Loss: 0.1567\n",
      "Epoch 2 — Val Loss: 0.1375, Val F1: 0.9503 (Acc: 0.9494, P: 0.9342, R: 0.9669, F1: 0.9503, ROC: 0.9910, PR: 0.9898)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0216, LR: 8.28e-04\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0478, LR: 7.85e-04\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.1064, LR: 7.30e-04\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0293, LR: 6.65e-04\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0225, LR: 5.92e-04\n",
      "Epoch 3/5 — Train Loss: 0.0783\n",
      "Epoch 3 — Val Loss: 0.0851, Val F1: 0.9667 (Acc: 0.9670, P: 0.9736, R: 0.9599, F1: 0.9667, ROC: 0.9953, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0222, LR: 5.28e-04\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0449, LR: 4.47e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0745, LR: 3.66e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0126, LR: 2.87e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0081, LR: 2.14e-04\n",
      "Epoch 4/5 — Train Loss: 0.0411\n",
      "Epoch 4 — Val Loss: 0.0914, Val F1: 0.9717 (Acc: 0.9720, P: 0.9787, R: 0.9649, F1: 0.9717, ROC: 0.9951, PR: 0.9956)\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0693, LR: 1.60e-04\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0051, LR: 1.02e-04\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0131, LR: 5.56e-05\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.1004, LR: 2.26e-05\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0097, LR: 4.07e-06\n",
      "Epoch 5/5 — Train Loss: 0.0299\n",
      "Epoch 5 — Val Loss: 0.0917, Val F1: 0.9713 (Acc: 0.9715, P: 0.9757, R: 0.9669, F1: 0.9713, ROC: 0.9952, PR: 0.9958)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0851\n",
      "\n",
      "Training finished. Total time: 67.77s. Model size: 1034898.93 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9670\n",
      "  - Precision: 0.9736\n",
      "  - Recall: 0.9599\n",
      "  - F1: 0.9667\n",
      "  - Roc_auc: 0.9953\n",
      "  - Pr_auc: 0.9957\n",
      "  - Val_loss: 0.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 11:47:54,901] Trial 30 finished with value: 0.9667003027245207 and parameters: {'max_learning_rate': 0.0008743174015609711, 'batch_size': 16, 'embedding_dim': 64, 'hidden_dims_idx': 11, 'dropout': 0.30000000000000004, 'weight_decay': 0.0009120220055117417}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9667\n",
      "Selected hidden_dims: [256, 16] (index 8)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0018514500975375955, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0005340591213530987, embedding_dim=256, hidden_dims=[256, 16], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6819, LR: 7.42e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6480, LR: 1.64e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.5234, LR: 4.05e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.6529, LR: 7.51e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.0558, LR: 1.14e-03\n",
      "Epoch 1/5 — Train Loss: 0.3905\n",
      "Epoch 1 — Val Loss: 0.2122, Val F1: 0.9505 (Acc: 0.9505, P: 0.9482, R: 0.9529, F1: 0.9505, ROC: 0.9864, PR: 0.9838)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.2098, LR: 1.43e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0371, LR: 1.71e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0573, LR: 1.84e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.1106, LR: 1.84e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0130, LR: 1.81e-03\n",
      "Epoch 2/5 — Train Loss: 0.1497\n",
      "Epoch 2 — Val Loss: 0.1154, Val F1: 0.9675 (Acc: 0.9680, P: 0.9805, R: 0.9549, F1: 0.9675, ROC: 0.9937, PR: 0.9945)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0092, LR: 1.75e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0446, LR: 1.66e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0245, LR: 1.55e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0070, LR: 1.41e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.8925, LR: 1.25e-03\n",
      "Epoch 3/5 — Train Loss: 0.0648\n",
      "Epoch 3 — Val Loss: 0.1120, Val F1: 0.9693 (Acc: 0.9695, P: 0.9737, R: 0.9649, F1: 0.9693, ROC: 0.9951, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0402, LR: 1.12e-03\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0184, LR: 9.47e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0398, LR: 7.75e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0005, LR: 6.08e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0010, LR: 4.52e-04\n",
      "Epoch 4/5 — Train Loss: 0.0334\n",
      "Epoch 4 — Val Loss: 0.1382, Val F1: 0.9693 (Acc: 0.9695, P: 0.9747, R: 0.9639, F1: 0.9693, ROC: 0.9951, PR: 0.9956)\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0234, LR: 3.38e-04\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0005, LR: 2.16e-04\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0384, LR: 1.18e-04\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.0440, LR: 4.79e-05\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0015, LR: 8.61e-06\n",
      "Epoch 5/5 — Train Loss: 0.0249\n",
      "Epoch 5 — Val Loss: 0.1396, Val F1: 0.9683 (Acc: 0.9685, P: 0.9727, R: 0.9639, F1: 0.9683, ROC: 0.9950, PR: 0.9955)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1120\n",
      "\n",
      "Training finished. Total time: 1910.20s. Model size: 4141699.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9695\n",
      "  - Precision: 0.9737\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9693\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9955\n",
      "  - Val_loss: 0.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:20:07,632] Trial 31 finished with value: 0.9693004529441369 and parameters: {'max_learning_rate': 0.0018514500975375955, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 8, 'dropout': 0.4, 'weight_decay': 0.0005340591213530987}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9693\n",
      "Selected hidden_dims: [128, 16] (index 11)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.003485002473217171, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.000531261972037709, embedding_dim=256, hidden_dims=[128, 16], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6927, LR: 1.40e-04\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6129, LR: 3.09e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.3535, LR: 7.63e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.0779, LR: 1.41e-03\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.1223, LR: 2.14e-03\n",
      "Epoch 1/5 — Train Loss: 0.3809\n",
      "Epoch 1 — Val Loss: 0.2336, Val F1: 0.9560 (Acc: 0.9550, P: 0.9340, R: 0.9790, F1: 0.9560, ROC: 0.9872, PR: 0.9814)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.0705, LR: 2.69e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0022, LR: 3.21e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.7641, LR: 3.47e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.5345, LR: 3.47e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.1681, LR: 3.40e-03\n",
      "Epoch 2/5 — Train Loss: 0.1775\n",
      "Epoch 2 — Val Loss: 0.1485, Val F1: 0.9665 (Acc: 0.9670, P: 0.9784, R: 0.9549, F1: 0.9665, ROC: 0.9935, PR: 0.9939)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0130, LR: 3.30e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0167, LR: 3.13e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0023, LR: 2.91e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0053, LR: 2.65e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0175, LR: 2.36e-03\n",
      "Epoch 3/5 — Train Loss: 0.0535\n",
      "Epoch 3 — Val Loss: 0.1330, Val F1: 0.9705 (Acc: 0.9710, P: 0.9845, R: 0.9569, F1: 0.9705, ROC: 0.9949, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0145, LR: 2.11e-03\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0059, LR: 1.78e-03\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0407, LR: 1.46e-03\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0004, LR: 1.14e-03\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0006, LR: 8.51e-04\n",
      "Epoch 4/5 — Train Loss: 0.0182\n",
      "Epoch 4 — Val Loss: 0.1622, Val F1: 0.9724 (Acc: 0.9725, P: 0.9748, R: 0.9699, F1: 0.9724, ROC: 0.9946, PR: 0.9949)\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0001, LR: 6.37e-04\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0000, LR: 4.06e-04\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0066, LR: 2.22e-04\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.0001, LR: 9.02e-05\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0211, LR: 1.62e-05\n",
      "Epoch 5/5 — Train Loss: 0.0122\n",
      "Epoch 5 — Val Loss: 0.1714, Val F1: 0.9723 (Acc: 0.9725, P: 0.9787, R: 0.9659, F1: 0.9723, ROC: 0.9945, PR: 0.9948)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1330\n",
      "\n",
      "Training finished. Total time: 1798.98s. Model size: 4140794.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9845\n",
      "  - Recall: 0.9569\n",
      "  - F1: 0.9705\n",
      "  - Roc_auc: 0.9949\n",
      "  - Pr_auc: 0.9957\n",
      "  - Val_loss: 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 12:50:32,068] Trial 32 finished with value: 0.9705284552845529 and parameters: {'max_learning_rate': 0.003485002473217171, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 11, 'dropout': 0.4, 'weight_decay': 0.000531261972037709}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9705\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.005867103470513595, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0006241065370661097, embedding_dim=256, hidden_dims=[256, 128], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6935, LR: 2.35e-04\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.5449, LR: 5.21e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.0058, LR: 1.28e-03\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.2159, LR: 2.38e-03\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.0008, LR: 3.60e-03\n",
      "Epoch 1/5 — Train Loss: 0.2731\n",
      "Epoch 1 — Val Loss: 0.1290, Val F1: 0.9598 (Acc: 0.9590, P: 0.9404, R: 0.9800, F1: 0.9598, ROC: 0.9928, PR: 0.9893)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.0315, LR: 4.53e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0194, LR: 5.40e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0037, LR: 5.84e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.1108, LR: 5.84e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0016, LR: 5.73e-03\n",
      "Epoch 2/5 — Train Loss: 0.1495\n",
      "Epoch 2 — Val Loss: 0.1738, Val F1: 0.9677 (Acc: 0.9685, P: 0.9895, R: 0.9469, F1: 0.9677, ROC: 0.9958, PR: 0.9959)\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0548, LR: 5.56e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0021, LR: 5.27e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0001, LR: 4.90e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0001, LR: 4.46e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0345, LR: 3.97e-03\n",
      "Epoch 3/5 — Train Loss: 0.0387\n",
      "Epoch 3 — Val Loss: 0.1738, Val F1: 0.9602 (Acc: 0.9600, P: 0.9527, R: 0.9679, F1: 0.9602, ROC: 0.9928, PR: 0.9927)\n",
      "Early stopping triggered after 3 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 1 with Val Loss: 0.1290\n",
      "\n",
      "Training finished. Total time: 1294.73s. Model size: 4141812.37 KB\n",
      "Best model (by val_loss) obtained at epoch 1:\n",
      "  - Accuracy: 0.9590\n",
      "  - Precision: 0.9404\n",
      "  - Recall: 0.9800\n",
      "  - F1: 0.9598\n",
      "  - Roc_auc: 0.9928\n",
      "  - Pr_auc: 0.9893\n",
      "  - Val_loss: 0.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:12:34,972] Trial 33 finished with value: 0.9597644749754661 and parameters: {'max_learning_rate': 0.005867103470513595, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 5, 'dropout': 0.30000000000000004, 'weight_decay': 0.0006241065370661097}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9598\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0005252620660706986, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0003153548458680616, embedding_dim=256, hidden_dims=[256], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.7188, LR: 2.10e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6373, LR: 4.66e-05\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.4558, LR: 1.15e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.3087, LR: 2.13e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.0797, LR: 3.23e-04\n",
      "Epoch 1/5 — Train Loss: 0.3818\n",
      "Epoch 1 — Val Loss: 0.2074, Val F1: 0.9487 (Acc: 0.9494, P: 0.9628, R: 0.9349, F1: 0.9487, ROC: 0.9830, PR: 0.9739)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.1613, LR: 4.05e-04\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0394, LR: 4.84e-04\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0739, LR: 5.23e-04\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.0150, LR: 5.23e-04\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0666, LR: 5.13e-04\n",
      "Epoch 2/5 — Train Loss: 0.1110\n",
      "Epoch 2 — Val Loss: 0.1662, Val F1: 0.9617 (Acc: 0.9610, P: 0.9432, R: 0.9810, F1: 0.9617, ROC: 0.9895, PR: 0.9849)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.0048, LR: 4.98e-04\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0342, LR: 4.72e-04\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0067, LR: 4.39e-04\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0276, LR: 3.99e-04\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0092, LR: 3.55e-04\n",
      "Epoch 3/5 — Train Loss: 0.0398\n",
      "Epoch 3 — Val Loss: 0.1285, Val F1: 0.9701 (Acc: 0.9700, P: 0.9634, R: 0.9770, F1: 0.9701, ROC: 0.9936, PR: 0.9936)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0012, LR: 3.17e-04\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0020, LR: 2.69e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0006, LR: 2.20e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0025, LR: 1.73e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0132, LR: 1.28e-04\n",
      "Epoch 4/5 — Train Loss: 0.0154\n",
      "Epoch 4 — Val Loss: 0.1247, Val F1: 0.9705 (Acc: 0.9705, P: 0.9700, R: 0.9709, F1: 0.9705, ROC: 0.9931, PR: 0.9923)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0271, LR: 9.60e-05\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0017, LR: 6.12e-05\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0026, LR: 3.34e-05\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.0011, LR: 1.36e-05\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0008, LR: 2.44e-06\n",
      "Epoch 5/5 — Train Loss: 0.0091\n",
      "Epoch 5 — Val Loss: 0.1251, Val F1: 0.9714 (Acc: 0.9715, P: 0.9729, R: 0.9699, F1: 0.9714, ROC: 0.9932, PR: 0.9925)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1247\n",
      "\n",
      "Training finished. Total time: 1640.98s. Model size: 4141684.24 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9705\n",
      "  - Precision: 0.9700\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9705\n",
      "  - Roc_auc: 0.9931\n",
      "  - Pr_auc: 0.9923\n",
      "  - Val_loss: 0.1247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:40:16,782] Trial 34 finished with value: 0.9704556835252879 and parameters: {'max_learning_rate': 0.0005252620660706986, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 0.0003153548458680616}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9705\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0067740946004487875, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0009923518634051248, embedding_dim=256, hidden_dims=[256, 64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6953, LR: 2.78e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6072, LR: 7.25e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3247, LR: 1.77e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1532, LR: 3.20e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2181, LR: 4.69e-03\n",
      "Epoch 1/5 — Train Loss: 0.3662\n",
      "Epoch 1 — Val Loss: 0.1637, Val F1: 0.9440 (Acc: 0.9424, P: 0.9185, R: 0.9709, F1: 0.9440, ROC: 0.9875, PR: 0.9852)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1310, LR: 5.45e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.4386, LR: 6.42e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0486, LR: 6.77e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1260, LR: 6.71e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1411, LR: 6.52e-03\n",
      "Epoch 2/5 — Train Loss: 0.1000\n",
      "Epoch 2 — Val Loss: 0.1206, Val F1: 0.9702 (Acc: 0.9705, P: 0.9766, R: 0.9639, F1: 0.9702, ROC: 0.9937, PR: 0.9939)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1052, LR: 6.35e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0049, LR: 5.97e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.3187, LR: 5.50e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0369, LR: 4.94e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0030, LR: 4.32e-03\n",
      "Epoch 3/5 — Train Loss: 0.0478\n",
      "Epoch 3 — Val Loss: 0.1197, Val F1: 0.9621 (Acc: 0.9630, P: 0.9853, R: 0.9399, F1: 0.9621, ROC: 0.9950, PR: 0.9950)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0177, LR: 3.95e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0132, LR: 3.29e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0631, LR: 2.63e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0059, LR: 2.00e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0026, LR: 1.43e-03\n",
      "Epoch 4/5 — Train Loss: 0.0145\n",
      "Epoch 4 — Val Loss: 0.1383, Val F1: 0.9668 (Acc: 0.9670, P: 0.9707, R: 0.9629, F1: 0.9668, ROC: 0.9932, PR: 0.9932)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0004, LR: 1.13e-03\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0819, LR: 6.81e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0167, LR: 3.35e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0104, LR: 1.07e-04\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0019, LR: 5.36e-06\n",
      "Epoch 5/5 — Train Loss: 0.0070\n",
      "Epoch 5 — Val Loss: 0.1428, Val F1: 0.9663 (Acc: 0.9665, P: 0.9697, R: 0.9629, F1: 0.9663, ROC: 0.9931, PR: 0.9932)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1197\n",
      "\n",
      "Training finished. Total time: 381.30s. Model size: 4141747.62 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9630\n",
      "  - Precision: 0.9853\n",
      "  - Recall: 0.9399\n",
      "  - F1: 0.9621\n",
      "  - Roc_auc: 0.9950\n",
      "  - Pr_auc: 0.9950\n",
      "  - Val_loss: 0.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:47:02,895] Trial 35 finished with value: 0.9620512820512821 and parameters: {'max_learning_rate': 0.0067740946004487875, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 0.0009923518634051248}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9621\n",
      "Selected hidden_dims: [256, 16] (index 8)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0003129349723344516, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0003687749224284969, embedding_dim=64, hidden_dims=[256, 16], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.6852, LR: 1.25e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6869, LR: 2.78e-05\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.6803, LR: 6.85e-05\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.6420, LR: 1.27e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.4920, LR: 1.92e-04\n",
      "Epoch 1/5 — Train Loss: 0.6169\n",
      "Epoch 1 — Val Loss: 0.3567, Val F1: 0.8578 (Acc: 0.8519, P: 0.8238, R: 0.8948, F1: 0.8578, ROC: 0.9230, PR: 0.9186)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.4949, LR: 2.41e-04\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.2013, LR: 2.88e-04\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0899, LR: 3.11e-04\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.3309, LR: 3.12e-04\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0466, LR: 3.05e-04\n",
      "Epoch 2/5 — Train Loss: 0.2038\n",
      "Epoch 2 — Val Loss: 0.1401, Val F1: 0.9603 (Acc: 0.9610, P: 0.9752, R: 0.9459, F1: 0.9603, ROC: 0.9905, PR: 0.9836)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.2836, LR: 2.96e-04\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0389, LR: 2.81e-04\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.1903, LR: 2.61e-04\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0507, LR: 2.38e-04\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0522, LR: 2.12e-04\n",
      "Epoch 3/5 — Train Loss: 0.1121\n",
      "Epoch 3 — Val Loss: 0.1219, Val F1: 0.9579 (Acc: 0.9575, P: 0.9471, R: 0.9689, F1: 0.9579, ROC: 0.9924, PR: 0.9891)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0521, LR: 1.89e-04\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0174, LR: 1.60e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.1425, LR: 1.31e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0802, LR: 1.03e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.1368, LR: 7.65e-05\n",
      "Epoch 4/5 — Train Loss: 0.0770\n",
      "Epoch 4 — Val Loss: 0.1092, Val F1: 0.9648 (Acc: 0.9650, P: 0.9696, R: 0.9599, F1: 0.9648, ROC: 0.9932, PR: 0.9908)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0257, LR: 5.72e-05\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0478, LR: 3.64e-05\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0119, LR: 1.99e-05\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.0706, LR: 8.10e-06\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0052, LR: 1.46e-06\n",
      "Epoch 5/5 — Train Loss: 0.0654\n",
      "Epoch 5 — Val Loss: 0.1094, Val F1: 0.9664 (Acc: 0.9665, P: 0.9678, R: 0.9649, F1: 0.9664, ROC: 0.9933, PR: 0.9910)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1092\n",
      "\n",
      "Training finished. Total time: 63.20s. Model size: 1035131.93 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9650\n",
      "  - Precision: 0.9696\n",
      "  - Recall: 0.9599\n",
      "  - F1: 0.9648\n",
      "  - Roc_auc: 0.9932\n",
      "  - Pr_auc: 0.9908\n",
      "  - Val_loss: 0.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:48:18,854] Trial 36 finished with value: 0.9647532729103726 and parameters: {'max_learning_rate': 0.0003129349723344516, 'batch_size': 16, 'embedding_dim': 64, 'hidden_dims_idx': 8, 'dropout': 0.2, 'weight_decay': 0.0003687749224284969}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9648\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.00013682155455055448, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=7.288760580314762e-05, embedding_dim=256, hidden_dims=[64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6819, LR: 5.62e-06\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6850, LR: 1.46e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6804, LR: 3.58e-05\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6849, LR: 6.46e-05\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6358, LR: 9.48e-05\n",
      "Epoch 1/5 — Train Loss: 0.6724\n",
      "Epoch 1 — Val Loss: 0.6049, Val F1: 0.6159 (Acc: 0.7147, P: 0.9403, R: 0.4579, F1: 0.6159, ROC: 0.9420, PR: 0.9220)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.5904, LR: 1.10e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.5058, LR: 1.30e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.4224, LR: 1.37e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.3847, LR: 1.36e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.3230, LR: 1.32e-04\n",
      "Epoch 2/5 — Train Loss: 0.4266\n",
      "Epoch 2 — Val Loss: 0.2947, Val F1: 0.9000 (Acc: 0.8944, P: 0.8542, R: 0.9509, F1: 0.9000, ROC: 0.9468, PR: 0.9358)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.2604, LR: 1.28e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.2321, LR: 1.21e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.2826, LR: 1.11e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1422, LR: 9.98e-05\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1817, LR: 8.73e-05\n",
      "Epoch 3/5 — Train Loss: 0.2092\n",
      "Epoch 3 — Val Loss: 0.1992, Val F1: 0.9306 (Acc: 0.9274, P: 0.8909, R: 0.9739, F1: 0.9306, ROC: 0.9811, PR: 0.9752)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.2035, LR: 7.99e-05\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.1095, LR: 6.65e-05\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.1197, LR: 5.32e-05\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0597, LR: 4.05e-05\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.1152, LR: 2.88e-05\n",
      "Epoch 4/5 — Train Loss: 0.1583\n",
      "Epoch 4 — Val Loss: 0.1685, Val F1: 0.9473 (Acc: 0.9459, P: 0.9238, R: 0.9719, F1: 0.9473, ROC: 0.9870, PR: 0.9822)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1851, LR: 2.28e-05\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.1552, LR: 1.38e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.2011, LR: 6.78e-06\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.2116, LR: 2.17e-06\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.1359, LR: 1.08e-07\n",
      "Epoch 5/5 — Train Loss: 0.1385\n",
      "Epoch 5 — Val Loss: 0.1660, Val F1: 0.9478 (Acc: 0.9464, P: 0.9231, R: 0.9739, F1: 0.9478, ROC: 0.9875, PR: 0.9827)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1660\n",
      "\n",
      "Training finished. Total time: 355.48s. Model size: 4140337.24 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9464\n",
      "  - Precision: 0.9231\n",
      "  - Recall: 0.9739\n",
      "  - F1: 0.9478\n",
      "  - Roc_auc: 0.9875\n",
      "  - Pr_auc: 0.9827\n",
      "  - Val_loss: 0.1660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:54:39,273] Trial 37 finished with value: 0.9478303266699171 and parameters: {'max_learning_rate': 0.00013682155455055448, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 2, 'dropout': 0.30000000000000004, 'weight_decay': 7.288760580314762e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9478\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.002771202386714621, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.096098115678274e-05, embedding_dim=64, hidden_dims=[32], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6817, LR: 1.14e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6845, LR: 2.97e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5995, LR: 7.25e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4406, LR: 1.31e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3060, LR: 1.92e-03\n",
      "Epoch 1/5 — Train Loss: 0.5255\n",
      "Epoch 1 — Val Loss: 0.2775, Val F1: 0.9146 (Acc: 0.9179, P: 0.9523, R: 0.8798, F1: 0.9146, ROC: 0.9742, PR: 0.9688)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2642, LR: 2.23e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1404, LR: 2.63e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1779, LR: 2.77e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1970, LR: 2.74e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1736, LR: 2.67e-03\n",
      "Epoch 2/5 — Train Loss: 0.1501\n",
      "Epoch 2 — Val Loss: 0.1455, Val F1: 0.9522 (Acc: 0.9515, P: 0.9361, R: 0.9689, F1: 0.9522, ROC: 0.9907, PR: 0.9888)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1308, LR: 2.60e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0465, LR: 2.44e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0817, LR: 2.25e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0519, LR: 2.02e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1160, LR: 1.77e-03\n",
      "Epoch 3/5 — Train Loss: 0.0683\n",
      "Epoch 3 — Val Loss: 0.0947, Val F1: 0.9711 (Acc: 0.9715, P: 0.9826, R: 0.9599, F1: 0.9711, ROC: 0.9948, PR: 0.9935)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0670, LR: 1.62e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0364, LR: 1.35e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0245, LR: 1.08e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0966, LR: 8.20e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0318, LR: 5.84e-04\n",
      "Epoch 4/5 — Train Loss: 0.0338\n",
      "Epoch 4 — Val Loss: 0.0963, Val F1: 0.9722 (Acc: 0.9725, P: 0.9797, R: 0.9649, F1: 0.9722, ROC: 0.9951, PR: 0.9946)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0213, LR: 4.62e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0145, LR: 2.79e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0130, LR: 1.37e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0259, LR: 4.39e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0206, LR: 2.19e-06\n",
      "Epoch 5/5 — Train Loss: 0.0250\n",
      "Epoch 5 — Val Loss: 0.0966, Val F1: 0.9709 (Acc: 0.9710, P: 0.9719, R: 0.9699, F1: 0.9709, ROC: 0.9950, PR: 0.9946)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0947\n",
      "\n",
      "Training finished. Total time: 32.64s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9826\n",
      "  - Recall: 0.9599\n",
      "  - F1: 0.9711\n",
      "  - Roc_auc: 0.9948\n",
      "  - Pr_auc: 0.9935\n",
      "  - Val_loss: 0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:55:25,230] Trial 38 finished with value: 0.9711099847947289 and parameters: {'max_learning_rate': 0.002771202386714621, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 3.096098115678274e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9711\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0017962176894353544, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00026043267834772787, embedding_dim=64, hidden_dims=[256], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.7057, LR: 7.20e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6545, LR: 1.59e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.3556, LR: 3.93e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.1342, LR: 7.29e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.0602, LR: 1.10e-03\n",
      "Epoch 1/5 — Train Loss: 0.3681\n",
      "Epoch 1 — Val Loss: 0.2281, Val F1: 0.9202 (Acc: 0.9254, P: 0.9885, R: 0.8607, F1: 0.9202, ROC: 0.9881, PR: 0.9839)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.1961, LR: 1.39e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.2119, LR: 1.65e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0131, LR: 1.79e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.0212, LR: 1.79e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0551, LR: 1.75e-03\n",
      "Epoch 2/5 — Train Loss: 0.1139\n",
      "Epoch 2 — Val Loss: 0.1018, Val F1: 0.9625 (Acc: 0.9630, P: 0.9734, R: 0.9519, F1: 0.9625, ROC: 0.9934, PR: 0.9930)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.1790, LR: 1.70e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0070, LR: 1.61e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0139, LR: 1.50e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0010, LR: 1.37e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0020, LR: 1.22e-03\n",
      "Epoch 3/5 — Train Loss: 0.0411\n",
      "Epoch 3 — Val Loss: 0.0958, Val F1: 0.9707 (Acc: 0.9710, P: 0.9796, R: 0.9619, F1: 0.9707, ROC: 0.9951, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0084, LR: 1.09e-03\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0026, LR: 9.19e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0030, LR: 7.52e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0024, LR: 5.90e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0005, LR: 4.39e-04\n",
      "Epoch 4/5 — Train Loss: 0.0133\n",
      "Epoch 4 — Val Loss: 0.0998, Val F1: 0.9689 (Acc: 0.9690, P: 0.9699, R: 0.9679, F1: 0.9689, ROC: 0.9944, PR: 0.9941)\n",
      "Epoch 5, Batch 0/125, Train Loss: 0.0148, LR: 3.28e-04\n",
      "Epoch 5, Batch 26/125, Train Loss: 0.0009, LR: 2.09e-04\n",
      "Epoch 5, Batch 52/125, Train Loss: 0.0096, LR: 1.14e-04\n",
      "Epoch 5, Batch 78/125, Train Loss: 0.0255, LR: 4.65e-05\n",
      "Epoch 5, Batch 104/125, Train Loss: 0.0005, LR: 8.35e-06\n",
      "Epoch 5/5 — Train Loss: 0.0065\n",
      "Epoch 5 — Val Loss: 0.0951, Val F1: 0.9703 (Acc: 0.9705, P: 0.9738, R: 0.9669, F1: 0.9703, ROC: 0.9955, PR: 0.9956)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0951\n",
      "\n",
      "Training finished. Total time: 62.53s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9705\n",
      "  - Precision: 0.9738\n",
      "  - Recall: 0.9669\n",
      "  - F1: 0.9703\n",
      "  - Roc_auc: 0.9955\n",
      "  - Pr_auc: 0.9956\n",
      "  - Val_loss: 0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 13:56:39,653] Trial 39 finished with value: 0.9703368526897939 and parameters: {'max_learning_rate': 0.0017962176894353544, 'batch_size': 16, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 0.00026043267834772787}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9703\n",
      "Selected hidden_dims: [256, 16] (index 8)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0008264216554763365, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0006483336727608591, embedding_dim=256, hidden_dims=[256, 16], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6899, LR: 3.39e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6761, LR: 8.84e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6525, LR: 2.16e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5809, LR: 3.90e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.4137, LR: 5.72e-04\n",
      "Epoch 1/5 — Train Loss: 0.6010\n",
      "Epoch 1 — Val Loss: 0.3463, Val F1: 0.8854 (Acc: 0.8829, P: 0.8659, R: 0.9058, F1: 0.8854, ROC: 0.9361, PR: 0.9276)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.4460, LR: 6.65e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.3020, LR: 7.84e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.3305, LR: 8.26e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1819, LR: 8.18e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2982, LR: 7.95e-04\n",
      "Epoch 2/5 — Train Loss: 0.2420\n",
      "Epoch 2 — Val Loss: 0.1527, Val F1: 0.9515 (Acc: 0.9505, P: 0.9310, R: 0.9729, F1: 0.9515, ROC: 0.9888, PR: 0.9829)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.2063, LR: 7.75e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1478, LR: 7.29e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.1037, LR: 6.71e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0738, LR: 6.03e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.2715, LR: 5.28e-04\n",
      "Epoch 3/5 — Train Loss: 0.1407\n",
      "Epoch 3 — Val Loss: 0.1321, Val F1: 0.9651 (Acc: 0.9650, P: 0.9603, R: 0.9699, F1: 0.9651, ROC: 0.9908, PR: 0.9873)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.2058, LR: 4.82e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.1253, LR: 4.02e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0319, LR: 3.21e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0806, LR: 2.44e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0706, LR: 1.74e-04\n",
      "Epoch 4/5 — Train Loss: 0.0970\n",
      "Epoch 4 — Val Loss: 0.1321, Val F1: 0.9698 (Acc: 0.9700, P: 0.9737, R: 0.9659, F1: 0.9698, ROC: 0.9913, PR: 0.9876)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0986, LR: 1.38e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0901, LR: 8.31e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.1209, LR: 4.09e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.1423, LR: 1.31e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0935, LR: 6.53e-07\n",
      "Epoch 5/5 — Train Loss: 0.0888\n",
      "Epoch 5 — Val Loss: 0.1347, Val F1: 0.9686 (Acc: 0.9685, P: 0.9633, R: 0.9739, F1: 0.9686, ROC: 0.9912, PR: 0.9878)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1321\n",
      "\n",
      "Training finished. Total time: 379.51s. Model size: 4141699.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9737\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9698\n",
      "  - Roc_auc: 0.9913\n",
      "  - Pr_auc: 0.9876\n",
      "  - Val_loss: 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:03:21,676] Trial 40 finished with value: 0.9698189134808853 and parameters: {'max_learning_rate': 0.0008264216554763365, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 8, 'dropout': 0.5, 'weight_decay': 0.0006483336727608591}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9698\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.002800823033426711, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=2.5232938155273707e-05, embedding_dim=64, hidden_dims=[32], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6817, LR: 1.15e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6843, LR: 3.00e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5983, LR: 7.33e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4382, LR: 1.32e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3047, LR: 1.94e-03\n",
      "Epoch 1/5 — Train Loss: 0.5245\n",
      "Epoch 1 — Val Loss: 0.2749, Val F1: 0.9157 (Acc: 0.9189, P: 0.9524, R: 0.8818, F1: 0.9157, ROC: 0.9746, PR: 0.9692)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2599, LR: 2.25e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1399, LR: 2.66e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1763, LR: 2.80e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1943, LR: 2.77e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1737, LR: 2.69e-03\n",
      "Epoch 2/5 — Train Loss: 0.1492\n",
      "Epoch 2 — Val Loss: 0.1460, Val F1: 0.9523 (Acc: 0.9515, P: 0.9353, R: 0.9699, F1: 0.9523, ROC: 0.9906, PR: 0.9886)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1330, LR: 2.63e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0495, LR: 2.47e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0864, LR: 2.27e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0500, LR: 2.04e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1170, LR: 1.79e-03\n",
      "Epoch 3/5 — Train Loss: 0.0674\n",
      "Epoch 3 — Val Loss: 0.0939, Val F1: 0.9706 (Acc: 0.9710, P: 0.9806, R: 0.9609, F1: 0.9706, ROC: 0.9948, PR: 0.9937)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0665, LR: 1.63e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0375, LR: 1.36e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0243, LR: 1.09e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0903, LR: 8.28e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0332, LR: 5.90e-04\n",
      "Epoch 4/5 — Train Loss: 0.0331\n",
      "Epoch 4 — Val Loss: 0.0955, Val F1: 0.9728 (Acc: 0.9730, P: 0.9797, R: 0.9659, F1: 0.9728, ROC: 0.9950, PR: 0.9946)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0216, LR: 4.67e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0154, LR: 2.81e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0122, LR: 1.39e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0251, LR: 4.44e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0194, LR: 2.21e-06\n",
      "Epoch 5/5 — Train Loss: 0.0242\n",
      "Epoch 5 — Val Loss: 0.0954, Val F1: 0.9709 (Acc: 0.9710, P: 0.9719, R: 0.9699, F1: 0.9709, ROC: 0.9950, PR: 0.9947)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0939\n",
      "\n",
      "Training finished. Total time: 32.69s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9806\n",
      "  - Recall: 0.9609\n",
      "  - F1: 0.9706\n",
      "  - Roc_auc: 0.9948\n",
      "  - Pr_auc: 0.9937\n",
      "  - Val_loss: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:04:07,392] Trial 41 finished with value: 0.9706477732793523 and parameters: {'max_learning_rate': 0.002800823033426711, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 2.5232938155273707e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9706\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.003323361277491239, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.9175574886776315e-05, embedding_dim=64, hidden_dims=[32], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6817, LR: 1.36e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6797, LR: 3.56e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5774, LR: 8.70e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4043, LR: 1.57e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2862, LR: 2.30e-03\n",
      "Epoch 1/5 — Train Loss: 0.5045\n",
      "Epoch 1 — Val Loss: 0.2167, Val F1: 0.9319 (Acc: 0.9324, P: 0.9381, R: 0.9259, F1: 0.9319, ROC: 0.9808, PR: 0.9757)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1684, LR: 2.67e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1127, LR: 3.15e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1976, LR: 3.32e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2010, LR: 3.29e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1636, LR: 3.20e-03\n",
      "Epoch 2/5 — Train Loss: 0.1410\n",
      "Epoch 2 — Val Loss: 0.1310, Val F1: 0.9573 (Acc: 0.9570, P: 0.9497, R: 0.9649, F1: 0.9573, ROC: 0.9913, PR: 0.9897)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1065, LR: 3.12e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0459, LR: 2.93e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0641, LR: 2.70e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0676, LR: 2.42e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1225, LR: 2.12e-03\n",
      "Epoch 3/5 — Train Loss: 0.0620\n",
      "Epoch 3 — Val Loss: 0.1029, Val F1: 0.9726 (Acc: 0.9730, P: 0.9856, R: 0.9599, F1: 0.9726, ROC: 0.9945, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0742, LR: 1.94e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0212, LR: 1.62e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0173, LR: 1.29e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0874, LR: 9.83e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0280, LR: 7.00e-04\n",
      "Epoch 4/5 — Train Loss: 0.0289\n",
      "Epoch 4 — Val Loss: 0.0944, Val F1: 0.9730 (Acc: 0.9730, P: 0.9720, R: 0.9739, F1: 0.9730, ROC: 0.9952, PR: 0.9952)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0233, LR: 5.54e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0126, LR: 3.34e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0108, LR: 1.65e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0206, LR: 5.27e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0147, LR: 2.63e-06\n",
      "Epoch 5/5 — Train Loss: 0.0209\n",
      "Epoch 5 — Val Loss: 0.0937, Val F1: 0.9719 (Acc: 0.9720, P: 0.9738, R: 0.9699, F1: 0.9719, ROC: 0.9953, PR: 0.9952)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0937\n",
      "\n",
      "Training finished. Total time: 32.27s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9720\n",
      "  - Precision: 0.9738\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9719\n",
      "  - Roc_auc: 0.9953\n",
      "  - Pr_auc: 0.9952\n",
      "  - Val_loss: 0.0937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:04:52,164] Trial 42 finished with value: 0.9718875502008032 and parameters: {'max_learning_rate': 0.003323361277491239, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 1.9175574886776315e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9719\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0034715859703401287, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=8.822125767359051e-06, embedding_dim=64, hidden_dims=[64], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6876, LR: 1.43e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6575, LR: 3.71e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5794, LR: 9.09e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3234, LR: 1.64e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1923, LR: 2.40e-03\n",
      "Epoch 1/5 — Train Loss: 0.4893\n",
      "Epoch 1 — Val Loss: 0.1871, Val F1: 0.9400 (Acc: 0.9384, P: 0.9163, R: 0.9649, F1: 0.9400, ROC: 0.9825, PR: 0.9771)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2391, LR: 2.79e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1431, LR: 3.29e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0612, LR: 3.47e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1723, LR: 3.44e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1542, LR: 3.34e-03\n",
      "Epoch 2/5 — Train Loss: 0.1265\n",
      "Epoch 2 — Val Loss: 0.1080, Val F1: 0.9612 (Acc: 0.9605, P: 0.9431, R: 0.9800, F1: 0.9612, ROC: 0.9941, PR: 0.9918)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0604, LR: 3.26e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0173, LR: 3.06e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0088, LR: 2.82e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0231, LR: 2.53e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0277, LR: 2.22e-03\n",
      "Epoch 3/5 — Train Loss: 0.0538\n",
      "Epoch 3 — Val Loss: 0.0948, Val F1: 0.9705 (Acc: 0.9710, P: 0.9845, R: 0.9569, F1: 0.9705, ROC: 0.9955, PR: 0.9944)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0182, LR: 2.03e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0232, LR: 1.69e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0328, LR: 1.35e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0076, LR: 1.03e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0073, LR: 7.31e-04\n",
      "Epoch 4/5 — Train Loss: 0.0253\n",
      "Epoch 4 — Val Loss: 0.0861, Val F1: 0.9709 (Acc: 0.9710, P: 0.9719, R: 0.9699, F1: 0.9709, ROC: 0.9958, PR: 0.9956)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0167, LR: 5.79e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0053, LR: 3.49e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0129, LR: 1.72e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0368, LR: 5.50e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0192, LR: 2.74e-06\n",
      "Epoch 5/5 — Train Loss: 0.0158\n",
      "Epoch 5 — Val Loss: 0.0874, Val F1: 0.9717 (Acc: 0.9720, P: 0.9796, R: 0.9639, F1: 0.9717, ROC: 0.9957, PR: 0.9954)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0861\n",
      "\n",
      "Training finished. Total time: 31.70s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9719\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9709\n",
      "  - Roc_auc: 0.9958\n",
      "  - Pr_auc: 0.9956\n",
      "  - Val_loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:05:36,254] Trial 43 finished with value: 0.970912738214644 and parameters: {'max_learning_rate': 0.0034715859703401287, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.2, 'weight_decay': 8.822125767359051e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9709\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.007057379850224284, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.681290285793012e-06, embedding_dim=64, hidden_dims=[128], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6937, LR: 2.90e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6089, LR: 7.55e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3174, LR: 1.85e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1408, LR: 3.33e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2241, LR: 4.89e-03\n",
      "Epoch 1/5 — Train Loss: 0.3800\n",
      "Epoch 1 — Val Loss: 0.1560, Val F1: 0.9551 (Acc: 0.9550, P: 0.9513, R: 0.9589, F1: 0.9551, ROC: 0.9886, PR: 0.9847)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0699, LR: 5.68e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1685, LR: 6.69e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0999, LR: 7.06e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0701, LR: 6.99e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0828, LR: 6.79e-03\n",
      "Epoch 2/5 — Train Loss: 0.1246\n",
      "Epoch 2 — Val Loss: 0.0854, Val F1: 0.9708 (Acc: 0.9710, P: 0.9767, R: 0.9649, F1: 0.9708, ROC: 0.9958, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0248, LR: 6.62e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0469, LR: 6.22e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0112, LR: 5.73e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0207, LR: 5.15e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0617, LR: 4.51e-03\n",
      "Epoch 3/5 — Train Loss: 0.0304\n",
      "Epoch 3 — Val Loss: 0.0715, Val F1: 0.9718 (Acc: 0.9720, P: 0.9777, R: 0.9659, F1: 0.9718, ROC: 0.9971, PR: 0.9973)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0040, LR: 4.12e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0080, LR: 3.43e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0062, LR: 2.74e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0028, LR: 2.09e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0003, LR: 1.49e-03\n",
      "Epoch 4/5 — Train Loss: 0.0092\n",
      "Epoch 4 — Val Loss: 0.0767, Val F1: 0.9724 (Acc: 0.9725, P: 0.9739, R: 0.9709, F1: 0.9724, ROC: 0.9969, PR: 0.9971)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0006, LR: 1.18e-03\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0011, LR: 7.09e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0148, LR: 3.49e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0013, LR: 1.12e-04\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0019, LR: 5.58e-06\n",
      "Epoch 5/5 — Train Loss: 0.0043\n",
      "Epoch 5 — Val Loss: 0.0787, Val F1: 0.9714 (Acc: 0.9715, P: 0.9719, R: 0.9709, F1: 0.9714, ROC: 0.9969, PR: 0.9971)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0715\n",
      "\n",
      "Training finished. Total time: 31.86s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9720\n",
      "  - Precision: 0.9777\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9718\n",
      "  - Roc_auc: 0.9971\n",
      "  - Pr_auc: 0.9973\n",
      "  - Val_loss: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:06:20,871] Trial 44 finished with value: 0.9717741935483871 and parameters: {'max_learning_rate': 0.007057379850224284, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.2, 'weight_decay': 3.681290285793012e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9718\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.007499416744701274, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.179465984234056e-06, embedding_dim=64, hidden_dims=[128], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6937, LR: 3.08e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6034, LR: 8.02e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.2980, LR: 1.96e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1432, LR: 3.54e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2351, LR: 5.19e-03\n",
      "Epoch 1/5 — Train Loss: 0.3742\n",
      "Epoch 1 — Val Loss: 0.1530, Val F1: 0.9575 (Acc: 0.9575, P: 0.9551, R: 0.9599, F1: 0.9575, ROC: 0.9889, PR: 0.9850)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0579, LR: 6.03e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2028, LR: 7.11e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0806, LR: 7.50e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0630, LR: 7.43e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0898, LR: 7.21e-03\n",
      "Epoch 2/5 — Train Loss: 0.1208\n",
      "Epoch 2 — Val Loss: 0.0837, Val F1: 0.9698 (Acc: 0.9700, P: 0.9757, R: 0.9639, F1: 0.9698, ROC: 0.9959, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0250, LR: 7.03e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0406, LR: 6.61e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0090, LR: 6.09e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0139, LR: 5.47e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0598, LR: 4.79e-03\n",
      "Epoch 3/5 — Train Loss: 0.0283\n",
      "Epoch 3 — Val Loss: 0.0785, Val F1: 0.9709 (Acc: 0.9710, P: 0.9738, R: 0.9679, F1: 0.9709, ROC: 0.9966, PR: 0.9968)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0031, LR: 4.38e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0067, LR: 3.64e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0059, LR: 2.92e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0021, LR: 2.22e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0002, LR: 1.58e-03\n",
      "Epoch 4/5 — Train Loss: 0.0088\n",
      "Epoch 4 — Val Loss: 0.0848, Val F1: 0.9709 (Acc: 0.9710, P: 0.9738, R: 0.9679, F1: 0.9709, ROC: 0.9965, PR: 0.9967)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0005, LR: 1.25e-03\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0007, LR: 7.54e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0112, LR: 3.71e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0012, LR: 1.19e-04\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0012, LR: 5.93e-06\n",
      "Epoch 5/5 — Train Loss: 0.0033\n",
      "Epoch 5 — Val Loss: 0.0863, Val F1: 0.9719 (Acc: 0.9720, P: 0.9729, R: 0.9709, F1: 0.9719, ROC: 0.9965, PR: 0.9967)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0785\n",
      "\n",
      "Training finished. Total time: 31.70s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9738\n",
      "  - Recall: 0.9679\n",
      "  - F1: 0.9709\n",
      "  - Roc_auc: 0.9966\n",
      "  - Pr_auc: 0.9968\n",
      "  - Val_loss: 0.0785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:07:05,335] Trial 45 finished with value: 0.9708542713567839 and parameters: {'max_learning_rate': 0.007499416744701274, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.2, 'weight_decay': 3.179465984234056e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9709\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.006739027934069543, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.5441575789240153e-05, embedding_dim=64, hidden_dims=[32], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6817, LR: 2.77e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6496, LR: 7.21e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4326, LR: 1.76e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2716, LR: 3.18e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1769, LR: 4.67e-03\n",
      "Epoch 1/5 — Train Loss: 0.4240\n",
      "Epoch 1 — Val Loss: 0.1867, Val F1: 0.9514 (Acc: 0.9520, P: 0.9611, R: 0.9419, F1: 0.9514, ROC: 0.9872, PR: 0.9780)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0940, LR: 5.42e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0494, LR: 6.39e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1621, LR: 6.74e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1137, LR: 6.67e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0977, LR: 6.48e-03\n",
      "Epoch 2/5 — Train Loss: 0.1087\n",
      "Epoch 2 — Val Loss: 0.1071, Val F1: 0.9697 (Acc: 0.9700, P: 0.9766, R: 0.9629, F1: 0.9697, ROC: 0.9941, PR: 0.9939)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0693, LR: 6.32e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0316, LR: 5.94e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0271, LR: 5.47e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0453, LR: 4.92e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0614, LR: 4.30e-03\n",
      "Epoch 3/5 — Train Loss: 0.0369\n",
      "Epoch 3 — Val Loss: 0.0861, Val F1: 0.9704 (Acc: 0.9710, P: 0.9876, R: 0.9539, F1: 0.9704, ROC: 0.9959, PR: 0.9961)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0446, LR: 3.93e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0088, LR: 3.28e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0042, LR: 2.62e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0515, LR: 1.99e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0069, LR: 1.42e-03\n",
      "Epoch 4/5 — Train Loss: 0.0142\n",
      "Epoch 4 — Val Loss: 0.1449, Val F1: 0.9755 (Acc: 0.9755, P: 0.9721, R: 0.9790, F1: 0.9755, ROC: 0.9950, PR: 0.9950)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0179, LR: 1.12e-03\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0044, LR: 6.77e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0047, LR: 3.34e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0029, LR: 1.07e-04\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0085, LR: 5.33e-06\n",
      "Epoch 5/5 — Train Loss: 0.0088\n",
      "Epoch 5 — Val Loss: 0.1415, Val F1: 0.9750 (Acc: 0.9750, P: 0.9740, R: 0.9760, F1: 0.9750, ROC: 0.9949, PR: 0.9949)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0861\n",
      "\n",
      "Training finished. Total time: 31.89s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9876\n",
      "  - Recall: 0.9539\n",
      "  - F1: 0.9704\n",
      "  - Roc_auc: 0.9959\n",
      "  - Pr_auc: 0.9961\n",
      "  - Val_loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:07:49,863] Trial 46 finished with value: 0.9704383282364933 and parameters: {'max_learning_rate': 0.006739027934069543, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 1.5441575789240153e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9704\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.003829252053986063, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.3887739393895064e-06, embedding_dim=64, hidden_dims=[256, 128], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6950, LR: 1.57e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6611, LR: 4.10e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5693, LR: 1.00e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3183, LR: 1.81e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3101, LR: 2.65e-03\n",
      "Epoch 1/5 — Train Loss: 0.4605\n",
      "Epoch 1 — Val Loss: 0.1808, Val F1: 0.9321 (Acc: 0.9344, P: 0.9656, R: 0.9008, F1: 0.9321, ROC: 0.9870, PR: 0.9819)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2047, LR: 3.08e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0726, LR: 3.63e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0532, LR: 3.83e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0756, LR: 3.79e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1919, LR: 3.68e-03\n",
      "Epoch 2/5 — Train Loss: 0.1135\n",
      "Epoch 2 — Val Loss: 0.1345, Val F1: 0.9681 (Acc: 0.9680, P: 0.9642, R: 0.9719, F1: 0.9681, ROC: 0.9942, PR: 0.9935)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0367, LR: 3.59e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1325, LR: 3.38e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0528, LR: 3.11e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1292, LR: 2.79e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0033, LR: 2.44e-03\n",
      "Epoch 3/5 — Train Loss: 0.0348\n",
      "Epoch 3 — Val Loss: 0.1091, Val F1: 0.9674 (Acc: 0.9675, P: 0.9679, R: 0.9669, F1: 0.9674, ROC: 0.9950, PR: 0.9954)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0114, LR: 2.24e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0228, LR: 1.86e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0015, LR: 1.49e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0048, LR: 1.13e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0025, LR: 8.07e-04\n",
      "Epoch 4/5 — Train Loss: 0.0150\n",
      "Epoch 4 — Val Loss: 0.1094, Val F1: 0.9706 (Acc: 0.9710, P: 0.9825, R: 0.9589, F1: 0.9706, ROC: 0.9955, PR: 0.9960)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0311, LR: 6.39e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0044, LR: 3.85e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0015, LR: 1.90e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0005, LR: 6.07e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0118, LR: 3.03e-06\n",
      "Epoch 5/5 — Train Loss: 0.0055\n",
      "Epoch 5 — Val Loss: 0.1080, Val F1: 0.9702 (Acc: 0.9705, P: 0.9796, R: 0.9609, F1: 0.9702, ROC: 0.9955, PR: 0.9960)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1080\n",
      "\n",
      "Training finished. Total time: 32.10s. Model size: 1035245.24 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9705\n",
      "  - Precision: 0.9796\n",
      "  - Recall: 0.9609\n",
      "  - F1: 0.9702\n",
      "  - Roc_auc: 0.9955\n",
      "  - Pr_auc: 0.9960\n",
      "  - Val_loss: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:08:34,433] Trial 47 finished with value: 0.9701568032372281 and parameters: {'max_learning_rate': 0.003829252053986063, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.2, 'weight_decay': 1.3887739393895064e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9702\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=7.659257759498833e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.0955839445386013e-05, embedding_dim=64, hidden_dims=[64], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6866, LR: 3.15e-06\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6913, LR: 8.20e-06\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.7047, LR: 2.00e-05\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6751, LR: 3.61e-05\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6766, LR: 5.30e-05\n",
      "Epoch 1/5 — Train Loss: 0.6909\n",
      "Epoch 1 — Val Loss: 0.6753, Val F1: 0.3782 (Acc: 0.6001, P: 0.8467, R: 0.2435, F1: 0.3782, ROC: 0.7455, PR: 0.7437)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.6717, LR: 6.16e-05\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.6671, LR: 7.26e-05\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.6397, LR: 7.66e-05\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.6387, LR: 7.59e-05\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.6219, LR: 7.37e-05\n",
      "Epoch 2/5 — Train Loss: 0.6450\n",
      "Epoch 2 — Val Loss: 0.6022, Val F1: 0.7562 (Acc: 0.7948, P: 0.9298, R: 0.6373, F1: 0.7562, ROC: 0.9396, PR: 0.9270)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.6058, LR: 7.18e-05\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.5780, LR: 6.76e-05\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.5358, LR: 6.22e-05\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.5000, LR: 5.59e-05\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.5026, LR: 4.89e-05\n",
      "Epoch 3/5 — Train Loss: 0.5515\n",
      "Epoch 3 — Val Loss: 0.5088, Val F1: 0.8603 (Acc: 0.8624, P: 0.8723, R: 0.8487, F1: 0.8603, ROC: 0.9409, PR: 0.9345)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.5135, LR: 4.47e-05\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.4788, LR: 3.72e-05\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.4862, LR: 2.98e-05\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.4569, LR: 2.27e-05\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.4334, LR: 1.61e-05\n",
      "Epoch 4/5 — Train Loss: 0.4696\n",
      "Epoch 4 — Val Loss: 0.4638, Val F1: 0.8681 (Acc: 0.8664, P: 0.8559, R: 0.8808, F1: 0.8681, ROC: 0.9365, PR: 0.9312)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.4668, LR: 1.28e-05\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.4684, LR: 7.70e-06\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.4524, LR: 3.79e-06\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.4326, LR: 1.21e-06\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.4309, LR: 6.06e-08\n",
      "Epoch 5/5 — Train Loss: 0.4441\n",
      "Epoch 5 — Val Loss: 0.4574, Val F1: 0.8674 (Acc: 0.8654, P: 0.8535, R: 0.8818, F1: 0.8674, ROC: 0.9360, PR: 0.9309)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.4574\n",
      "\n",
      "Training finished. Total time: 31.94s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.8654\n",
      "  - Precision: 0.8535\n",
      "  - Recall: 0.8818\n",
      "  - F1: 0.8674\n",
      "  - Roc_auc: 0.9360\n",
      "  - Pr_auc: 0.9309\n",
      "  - Val_loss: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:09:19,163] Trial 48 finished with value: 0.8674223755544603 and parameters: {'max_learning_rate': 7.659257759498833e-05, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.1, 'weight_decay': 1.0955839445386013e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.8674\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.009653989451099665, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=5.000122699844908e-06, embedding_dim=64, hidden_dims=[128], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6937, LR: 3.97e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.5755, LR: 1.03e-03\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.2425, LR: 2.53e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1942, LR: 4.56e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1694, LR: 6.69e-03\n",
      "Epoch 1/5 — Train Loss: 0.3463\n",
      "Epoch 1 — Val Loss: 0.1553, Val F1: 0.9581 (Acc: 0.9575, P: 0.9436, R: 0.9729, F1: 0.9581, ROC: 0.9892, PR: 0.9860)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0332, LR: 7.77e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1514, LR: 9.16e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0673, LR: 9.65e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0592, LR: 9.56e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0697, LR: 9.29e-03\n",
      "Epoch 2/5 — Train Loss: 0.1069\n",
      "Epoch 2 — Val Loss: 0.0799, Val F1: 0.9681 (Acc: 0.9685, P: 0.9795, R: 0.9569, F1: 0.9681, ROC: 0.9961, PR: 0.9961)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0171, LR: 9.05e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0267, LR: 8.52e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0044, LR: 7.84e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0071, LR: 7.04e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0410, LR: 6.16e-03\n",
      "Epoch 3/5 — Train Loss: 0.0234\n",
      "Epoch 3 — Val Loss: 0.0867, Val F1: 0.9697 (Acc: 0.9700, P: 0.9766, R: 0.9629, F1: 0.9697, ROC: 0.9961, PR: 0.9964)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0013, LR: 5.64e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0020, LR: 4.69e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0020, LR: 3.75e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0008, LR: 2.86e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0001, LR: 2.03e-03\n",
      "Epoch 4/5 — Train Loss: 0.0048\n",
      "Epoch 4 — Val Loss: 0.1021, Val F1: 0.9696 (Acc: 0.9700, P: 0.9805, R: 0.9589, F1: 0.9696, ROC: 0.9958, PR: 0.9963)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0799\n",
      "\n",
      "Training finished. Total time: 27.50s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9685\n",
      "  - Precision: 0.9795\n",
      "  - Recall: 0.9569\n",
      "  - F1: 0.9681\n",
      "  - Roc_auc: 0.9961\n",
      "  - Pr_auc: 0.9961\n",
      "  - Val_loss: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:09:59,195] Trial 49 finished with value: 0.968068930562595 and parameters: {'max_learning_rate': 0.009653989451099665, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.2, 'weight_decay': 5.000122699844908e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9681\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.007549771670678614, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=2.1697883347776256e-05, embedding_dim=64, hidden_dims=[256], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6985, LR: 3.10e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.5738, LR: 8.08e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3862, LR: 1.98e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2563, LR: 3.56e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1362, LR: 5.23e-03\n",
      "Epoch 1/5 — Train Loss: 0.3505\n",
      "Epoch 1 — Val Loss: 0.5637, Val F1: 0.7877 (Acc: 0.8238, P: 0.9894, R: 0.6543, F1: 0.7877, ROC: 0.9830, PR: 0.9781)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.5471, LR: 6.08e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1437, LR: 7.16e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2685, LR: 7.55e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1190, LR: 7.48e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0901, LR: 7.26e-03\n",
      "Epoch 2/5 — Train Loss: 0.1110\n",
      "Epoch 2 — Val Loss: 0.0830, Val F1: 0.9687 (Acc: 0.9690, P: 0.9776, R: 0.9599, F1: 0.9687, ROC: 0.9956, PR: 0.9959)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0303, LR: 7.08e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0243, LR: 6.66e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0039, LR: 6.13e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0029, LR: 5.51e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0099, LR: 4.82e-03\n",
      "Epoch 3/5 — Train Loss: 0.0209\n",
      "Epoch 3 — Val Loss: 0.0964, Val F1: 0.9697 (Acc: 0.9700, P: 0.9766, R: 0.9629, F1: 0.9697, ROC: 0.9957, PR: 0.9959)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0017, LR: 4.41e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0014, LR: 3.67e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0003, LR: 2.93e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0253, LR: 2.23e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0044, LR: 1.59e-03\n",
      "Epoch 4/5 — Train Loss: 0.0059\n",
      "Epoch 4 — Val Loss: 0.1059, Val F1: 0.9687 (Acc: 0.9690, P: 0.9776, R: 0.9599, F1: 0.9687, ROC: 0.9954, PR: 0.9957)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0830\n",
      "\n",
      "Training finished. Total time: 27.17s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9690\n",
      "  - Precision: 0.9776\n",
      "  - Recall: 0.9599\n",
      "  - F1: 0.9687\n",
      "  - Roc_auc: 0.9956\n",
      "  - Pr_auc: 0.9959\n",
      "  - Val_loss: 0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:10:38,939] Trial 50 finished with value: 0.9686552072800809 and parameters: {'max_learning_rate': 0.007549771670678614, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.1, 'weight_decay': 2.1697883347776256e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9687\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=16, max_learning_rate=0.0013281427489252125, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=2.266944820555747e-06, embedding_dim=256, hidden_dims=[256, 64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/125, Train Loss: 0.7286, LR: 5.32e-05\n",
      "Epoch 1, Batch 26/125, Train Loss: 0.6848, LR: 1.18e-04\n",
      "Epoch 1, Batch 52/125, Train Loss: 0.2925, LR: 2.91e-04\n",
      "Epoch 1, Batch 78/125, Train Loss: 0.0897, LR: 5.39e-04\n",
      "Epoch 1, Batch 104/125, Train Loss: 0.2133, LR: 8.16e-04\n",
      "Epoch 1/5 — Train Loss: 0.3686\n",
      "Epoch 1 — Val Loss: 0.1496, Val F1: 0.9558 (Acc: 0.9545, P: 0.9266, R: 0.9870, F1: 0.9558, ROC: 0.9906, PR: 0.9844)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/125, Train Loss: 0.0787, LR: 1.02e-03\n",
      "Epoch 2, Batch 26/125, Train Loss: 0.0383, LR: 1.22e-03\n",
      "Epoch 2, Batch 52/125, Train Loss: 0.0332, LR: 1.32e-03\n",
      "Epoch 2, Batch 78/125, Train Loss: 0.0771, LR: 1.32e-03\n",
      "Epoch 2, Batch 104/125, Train Loss: 0.0100, LR: 1.30e-03\n",
      "Epoch 2/5 — Train Loss: 0.1003\n",
      "Epoch 2 — Val Loss: 0.0978, Val F1: 0.9714 (Acc: 0.9715, P: 0.9719, R: 0.9709, F1: 0.9714, ROC: 0.9943, PR: 0.9934)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/125, Train Loss: 0.1541, LR: 1.26e-03\n",
      "Epoch 3, Batch 26/125, Train Loss: 0.0138, LR: 1.19e-03\n",
      "Epoch 3, Batch 52/125, Train Loss: 0.0023, LR: 1.11e-03\n",
      "Epoch 3, Batch 78/125, Train Loss: 0.0030, LR: 1.01e-03\n",
      "Epoch 3, Batch 104/125, Train Loss: 0.0010, LR: 8.99e-04\n",
      "Epoch 3/5 — Train Loss: 0.0275\n",
      "Epoch 3 — Val Loss: 0.1284, Val F1: 0.9716 (Acc: 0.9715, P: 0.9654, R: 0.9780, F1: 0.9716, ROC: 0.9944, PR: 0.9942)\n",
      "Epoch 4, Batch 0/125, Train Loss: 0.0090, LR: 8.03e-04\n",
      "Epoch 4, Batch 26/125, Train Loss: 0.0001, LR: 6.80e-04\n",
      "Epoch 4, Batch 52/125, Train Loss: 0.0016, LR: 5.56e-04\n",
      "Epoch 4, Batch 78/125, Train Loss: 0.0106, LR: 4.36e-04\n",
      "Epoch 4, Batch 104/125, Train Loss: 0.0014, LR: 3.24e-04\n",
      "Epoch 4/5 — Train Loss: 0.0091\n",
      "Epoch 4 — Val Loss: 0.1474, Val F1: 0.9682 (Acc: 0.9685, P: 0.9766, R: 0.9599, F1: 0.9682, ROC: 0.9940, PR: 0.9942)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0978\n",
      "\n",
      "Training finished. Total time: 1416.42s. Model size: 4141747.62 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9719\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9714\n",
      "  - Roc_auc: 0.9943\n",
      "  - Pr_auc: 0.9934\n",
      "  - Val_loss: 0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:34:38,623] Trial 51 finished with value: 0.9714285714285714 and parameters: {'max_learning_rate': 0.0013281427489252125, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 2.266944820555747e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9714\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.002324635205605679, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.8681822334832825e-06, embedding_dim=64, hidden_dims=[256, 64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6925, LR: 9.55e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6956, LR: 2.49e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6563, LR: 6.08e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5196, LR: 1.10e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2159, LR: 1.61e-03\n",
      "Epoch 1/5 — Train Loss: 0.5464\n",
      "Epoch 1 — Val Loss: 0.2191, Val F1: 0.9220 (Acc: 0.9189, P: 0.8878, R: 0.9589, F1: 0.9220, ROC: 0.9685, PR: 0.9657)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1455, LR: 1.87e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1335, LR: 2.20e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0355, LR: 2.32e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1450, LR: 2.30e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1221, LR: 2.24e-03\n",
      "Epoch 2/5 — Train Loss: 0.1346\n",
      "Epoch 2 — Val Loss: 0.1288, Val F1: 0.9546 (Acc: 0.9540, P: 0.9407, R: 0.9689, F1: 0.9546, ROC: 0.9922, PR: 0.9919)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0371, LR: 2.18e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1272, LR: 2.05e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0179, LR: 1.89e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0324, LR: 1.70e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0548, LR: 1.48e-03\n",
      "Epoch 3/5 — Train Loss: 0.0515\n",
      "Epoch 3 — Val Loss: 0.1038, Val F1: 0.9718 (Acc: 0.9720, P: 0.9777, R: 0.9659, F1: 0.9718, ROC: 0.9949, PR: 0.9944)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0316, LR: 1.36e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0257, LR: 1.13e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0097, LR: 9.04e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0114, LR: 6.88e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0426, LR: 4.90e-04\n",
      "Epoch 4/5 — Train Loss: 0.0239\n",
      "Epoch 4 — Val Loss: 0.1156, Val F1: 0.9718 (Acc: 0.9720, P: 0.9758, R: 0.9679, F1: 0.9718, ROC: 0.9953, PR: 0.9950)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0186, LR: 3.88e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0227, LR: 2.34e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0078, LR: 1.15e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0120, LR: 3.69e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0129, LR: 1.84e-06\n",
      "Epoch 5/5 — Train Loss: 0.0155\n",
      "Epoch 5 — Val Loss: 0.1236, Val F1: 0.9702 (Acc: 0.9705, P: 0.9796, R: 0.9609, F1: 0.9702, ROC: 0.9951, PR: 0.9948)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1038\n",
      "\n",
      "Training finished. Total time: 33.91s. Model size: 1035180.49 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9720\n",
      "  - Precision: 0.9777\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9718\n",
      "  - Roc_auc: 0.9949\n",
      "  - Pr_auc: 0.9944\n",
      "  - Val_loss: 0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:35:24,862] Trial 52 finished with value: 0.9717741935483871 and parameters: {'max_learning_rate': 0.002324635205605679, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 1.8681822334832825e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9718\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005021819508804257, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.0758615799743215e-06, embedding_dim=64, hidden_dims=[256, 128], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6950, LR: 2.06e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6524, LR: 5.37e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5054, LR: 1.31e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3235, LR: 2.37e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3547, LR: 3.48e-03\n",
      "Epoch 1/5 — Train Loss: 0.4352\n",
      "Epoch 1 — Val Loss: 0.1902, Val F1: 0.9327 (Acc: 0.9354, P: 0.9728, R: 0.8958, F1: 0.9327, ROC: 0.9877, PR: 0.9832)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1466, LR: 4.04e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0812, LR: 4.76e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0585, LR: 5.02e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0716, LR: 4.97e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2051, LR: 4.83e-03\n",
      "Epoch 2/5 — Train Loss: 0.1059\n",
      "Epoch 2 — Val Loss: 0.1528, Val F1: 0.9693 (Acc: 0.9690, P: 0.9579, R: 0.9810, F1: 0.9693, ROC: 0.9944, PR: 0.9939)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0445, LR: 4.71e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1071, LR: 4.43e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0445, LR: 4.08e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1130, LR: 3.66e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0091, LR: 3.21e-03\n",
      "Epoch 3/5 — Train Loss: 0.0305\n",
      "Epoch 3 — Val Loss: 0.0991, Val F1: 0.9673 (Acc: 0.9675, P: 0.9707, R: 0.9639, F1: 0.9673, ROC: 0.9949, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0059, LR: 2.93e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0150, LR: 2.44e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0019, LR: 1.95e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0057, LR: 1.49e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0024, LR: 1.06e-03\n",
      "Epoch 4/5 — Train Loss: 0.0133\n",
      "Epoch 4 — Val Loss: 0.1168, Val F1: 0.9659 (Acc: 0.9665, P: 0.9804, R: 0.9519, F1: 0.9659, ROC: 0.9954, PR: 0.9958)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0460, LR: 8.38e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0035, LR: 5.05e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0012, LR: 2.49e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0007, LR: 7.96e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0090, LR: 3.97e-06\n",
      "Epoch 5/5 — Train Loss: 0.0051\n",
      "Epoch 5 — Val Loss: 0.1147, Val F1: 0.9670 (Acc: 0.9675, P: 0.9794, R: 0.9549, F1: 0.9670, ROC: 0.9955, PR: 0.9960)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0991\n",
      "\n",
      "Training finished. Total time: 31.93s. Model size: 1035245.24 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9675\n",
      "  - Precision: 0.9707\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9673\n",
      "  - Roc_auc: 0.9949\n",
      "  - Pr_auc: 0.9951\n",
      "  - Val_loss: 0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:36:08,961] Trial 53 finished with value: 0.9673202614379085 and parameters: {'max_learning_rate': 0.005021819508804257, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.2, 'weight_decay': 1.0758615799743215e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9673\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.00237264866231627, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.866092646435174e-06, embedding_dim=64, hidden_dims=[128], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6935, LR: 9.74e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6661, LR: 2.54e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5911, LR: 6.21e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3764, LR: 1.12e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3351, LR: 1.64e-03\n",
      "Epoch 1/5 — Train Loss: 0.5098\n",
      "Epoch 1 — Val Loss: 0.2031, Val F1: 0.9381 (Acc: 0.9369, P: 0.9208, R: 0.9559, F1: 0.9381, ROC: 0.9813, PR: 0.9756)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1925, LR: 1.91e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1494, LR: 2.25e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1263, LR: 2.37e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1349, LR: 2.35e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1364, LR: 2.28e-03\n",
      "Epoch 2/5 — Train Loss: 0.1347\n",
      "Epoch 2 — Val Loss: 0.1200, Val F1: 0.9656 (Acc: 0.9660, P: 0.9755, R: 0.9559, F1: 0.9656, ROC: 0.9927, PR: 0.9899)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0599, LR: 2.22e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0450, LR: 2.09e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0289, LR: 1.93e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0513, LR: 1.73e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1021, LR: 1.51e-03\n",
      "Epoch 3/5 — Train Loss: 0.0557\n",
      "Epoch 3 — Val Loss: 0.0974, Val F1: 0.9702 (Acc: 0.9705, P: 0.9776, R: 0.9629, F1: 0.9702, ROC: 0.9945, PR: 0.9937)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0289, LR: 1.39e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0457, LR: 1.15e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0191, LR: 9.22e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0074, LR: 7.02e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0017, LR: 5.00e-04\n",
      "Epoch 4/5 — Train Loss: 0.0282\n",
      "Epoch 4 — Val Loss: 0.0950, Val F1: 0.9678 (Acc: 0.9680, P: 0.9727, R: 0.9629, F1: 0.9678, ROC: 0.9951, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0048, LR: 3.96e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0048, LR: 2.38e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0746, LR: 1.17e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0139, LR: 3.76e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0089, LR: 1.88e-06\n",
      "Epoch 5/5 — Train Loss: 0.0191\n",
      "Epoch 5 — Val Loss: 0.0956, Val F1: 0.9703 (Acc: 0.9705, P: 0.9747, R: 0.9659, F1: 0.9703, ROC: 0.9950, PR: 0.9951)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0950\n",
      "\n",
      "Training finished. Total time: 31.90s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9680\n",
      "  - Precision: 0.9727\n",
      "  - Recall: 0.9629\n",
      "  - F1: 0.9678\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9951\n",
      "  - Val_loss: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:36:52,877] Trial 54 finished with value: 0.9677744209466264 and parameters: {'max_learning_rate': 0.00237264866231627, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.30000000000000004, 'weight_decay': 1.866092646435174e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9678\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.004350249077303315, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.8407113101477e-06, embedding_dim=64, hidden_dims=[256, 64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6925, LR: 1.79e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6845, LR: 4.66e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5902, LR: 1.14e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3569, LR: 2.05e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1108, LR: 3.01e-03\n",
      "Epoch 1/5 — Train Loss: 0.4720\n",
      "Epoch 1 — Val Loss: 0.1705, Val F1: 0.9425 (Acc: 0.9409, P: 0.9175, R: 0.9689, F1: 0.9425, ROC: 0.9857, PR: 0.9802)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1170, LR: 3.50e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1307, LR: 4.13e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0317, LR: 4.35e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1263, LR: 4.31e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0682, LR: 4.18e-03\n",
      "Epoch 2/5 — Train Loss: 0.1182\n",
      "Epoch 2 — Val Loss: 0.0931, Val F1: 0.9693 (Acc: 0.9695, P: 0.9737, R: 0.9649, F1: 0.9693, ROC: 0.9950, PR: 0.9948)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0178, LR: 4.08e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1059, LR: 3.84e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0071, LR: 3.53e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0392, LR: 3.17e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0740, LR: 2.78e-03\n",
      "Epoch 3/5 — Train Loss: 0.0391\n",
      "Epoch 3 — Val Loss: 0.0855, Val F1: 0.9713 (Acc: 0.9715, P: 0.9748, R: 0.9679, F1: 0.9713, ROC: 0.9955, PR: 0.9958)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0120, LR: 2.54e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0099, LR: 2.11e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0089, LR: 1.69e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0066, LR: 1.29e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0444, LR: 9.16e-04\n",
      "Epoch 4/5 — Train Loss: 0.0138\n",
      "Epoch 4 — Val Loss: 0.0963, Val F1: 0.9712 (Acc: 0.9715, P: 0.9786, R: 0.9639, F1: 0.9712, ROC: 0.9954, PR: 0.9958)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0180, LR: 7.26e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0164, LR: 4.37e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0015, LR: 2.15e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0060, LR: 6.90e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0026, LR: 3.44e-06\n",
      "Epoch 5/5 — Train Loss: 0.0072\n",
      "Epoch 5 — Val Loss: 0.1007, Val F1: 0.9697 (Acc: 0.9700, P: 0.9786, R: 0.9609, F1: 0.9697, ROC: 0.9954, PR: 0.9958)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0855\n",
      "\n",
      "Training finished. Total time: 31.59s. Model size: 1035180.49 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9748\n",
      "  - Recall: 0.9679\n",
      "  - F1: 0.9713\n",
      "  - Roc_auc: 0.9955\n",
      "  - Pr_auc: 0.9958\n",
      "  - Val_loss: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:37:36,586] Trial 55 finished with value: 0.971342383107089 and parameters: {'max_learning_rate': 0.004350249077303315, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 3.8407113101477e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9713\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.003383042351743511, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00013189627394376267, embedding_dim=64, hidden_dims=[256], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7028, LR: 1.36e-04\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6156, LR: 3.12e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.3049, LR: 7.59e-04\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.1890, LR: 1.39e-03\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.1399, LR: 2.10e-03\n",
      "Epoch 1/5 — Train Loss: 0.3603\n",
      "Epoch 1 — Val Loss: 0.3037, Val F1: 0.8922 (Acc: 0.9019, P: 0.9890, R: 0.8126, F1: 0.8922, ROC: 0.9863, PR: 0.9820)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.3266, LR: 2.65e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.0580, LR: 3.14e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.0224, LR: 3.37e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.0493, LR: 3.37e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.1023, LR: 3.30e-03\n",
      "Epoch 2/5 — Train Loss: 0.1112\n",
      "Epoch 2 — Val Loss: 0.0913, Val F1: 0.9646 (Acc: 0.9645, P: 0.9603, R: 0.9689, F1: 0.9646, ROC: 0.9950, PR: 0.9945)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0532, LR: 3.19e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0568, LR: 3.03e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.0185, LR: 2.81e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0622, LR: 2.56e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0036, LR: 2.28e-03\n",
      "Epoch 3/5 — Train Loss: 0.0269\n",
      "Epoch 3 — Val Loss: 0.0944, Val F1: 0.9715 (Acc: 0.9720, P: 0.9866, R: 0.9569, F1: 0.9715, ROC: 0.9954, PR: 0.9959)\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0016, LR: 2.02e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0012, LR: 1.71e-03\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0032, LR: 1.40e-03\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0013, LR: 1.10e-03\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0003, LR: 8.15e-04\n",
      "Epoch 4/5 — Train Loss: 0.0078\n",
      "Epoch 4 — Val Loss: 0.0983, Val F1: 0.9705 (Acc: 0.9705, P: 0.9690, R: 0.9719, F1: 0.9705, ROC: 0.9952, PR: 0.9956)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0913\n",
      "\n",
      "Training finished. Total time: 35.06s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9645\n",
      "  - Precision: 0.9603\n",
      "  - Recall: 0.9689\n",
      "  - F1: 0.9646\n",
      "  - Roc_auc: 0.9950\n",
      "  - Pr_auc: 0.9945\n",
      "  - Val_loss: 0.0913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:38:23,858] Trial 56 finished with value: 0.9645885286783042 and parameters: {'max_learning_rate': 0.003383042351743511, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.2, 'weight_decay': 0.00013189627394376267}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9646\n",
      "Selected hidden_dims: [16] (index 0)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005674547319844819, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.043860907800924e-05, embedding_dim=128, hidden_dims=[16], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6954, LR: 2.33e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6365, LR: 6.07e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4050, LR: 1.49e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2119, LR: 2.68e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1452, LR: 3.93e-03\n",
      "Epoch 1/5 — Train Loss: 0.4109\n",
      "Epoch 1 — Val Loss: 0.2232, Val F1: 0.9507 (Acc: 0.9520, P: 0.9757, R: 0.9269, F1: 0.9507, ROC: 0.9847, PR: 0.9815)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1127, LR: 4.57e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1472, LR: 5.38e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0630, LR: 5.67e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0620, LR: 5.62e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0054, LR: 5.46e-03\n",
      "Epoch 2/5 — Train Loss: 0.1254\n",
      "Epoch 2 — Val Loss: 0.1779, Val F1: 0.9510 (Acc: 0.9525, P: 0.9798, R: 0.9238, F1: 0.9510, ROC: 0.9896, PR: 0.9862)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1037, LR: 5.32e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0314, LR: 5.01e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0193, LR: 4.61e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0263, LR: 4.14e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0167, LR: 3.62e-03\n",
      "Epoch 3/5 — Train Loss: 0.0390\n",
      "Epoch 3 — Val Loss: 0.0912, Val F1: 0.9706 (Acc: 0.9710, P: 0.9825, R: 0.9589, F1: 0.9706, ROC: 0.9957, PR: 0.9959)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0074, LR: 3.31e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0079, LR: 2.76e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0266, LR: 2.21e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0029, LR: 1.68e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0038, LR: 1.20e-03\n",
      "Epoch 4/5 — Train Loss: 0.0161\n",
      "Epoch 4 — Val Loss: 0.1161, Val F1: 0.9745 (Acc: 0.9745, P: 0.9740, R: 0.9749, F1: 0.9745, ROC: 0.9940, PR: 0.9929)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0282, LR: 9.47e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0154, LR: 5.70e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0007, LR: 2.81e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0075, LR: 9.00e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0054, LR: 4.49e-06\n",
      "Epoch 5/5 — Train Loss: 0.0108\n",
      "Epoch 5 — Val Loss: 0.0965, Val F1: 0.9744 (Acc: 0.9745, P: 0.9778, R: 0.9709, F1: 0.9744, ROC: 0.9963, PR: 0.9963)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0912\n",
      "\n",
      "Training finished. Total time: 64.51s. Model size: 2069587.68 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9825\n",
      "  - Recall: 0.9589\n",
      "  - F1: 0.9706\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9959\n",
      "  - Val_loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:39:42,224] Trial 57 finished with value: 0.9705882352941176 and parameters: {'max_learning_rate': 0.005674547319844819, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 0, 'dropout': 0.30000000000000004, 'weight_decay': 4.043860907800924e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9706\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0020158600955377044, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=5.7300513877587005e-06, embedding_dim=64, hidden_dims=[256, 128], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6950, LR: 8.28e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6735, LR: 2.16e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6403, LR: 5.28e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4922, LR: 9.51e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3678, LR: 1.40e-03\n",
      "Epoch 1/5 — Train Loss: 0.5385\n",
      "Epoch 1 — Val Loss: 0.2687, Val F1: 0.9012 (Acc: 0.9074, P: 0.9646, R: 0.8457, F1: 0.9012, ROC: 0.9772, PR: 0.9778)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.3714, LR: 1.62e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2148, LR: 1.91e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0624, LR: 2.02e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0582, LR: 2.00e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2149, LR: 1.94e-03\n",
      "Epoch 2/5 — Train Loss: 0.1520\n",
      "Epoch 2 — Val Loss: 0.1123, Val F1: 0.9629 (Acc: 0.9630, P: 0.9648, R: 0.9609, F1: 0.9629, ROC: 0.9925, PR: 0.9914)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0334, LR: 1.89e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1676, LR: 1.78e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0713, LR: 1.64e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1713, LR: 1.47e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0125, LR: 1.29e-03\n",
      "Epoch 3/5 — Train Loss: 0.0563\n",
      "Epoch 3 — Val Loss: 0.0970, Val F1: 0.9667 (Acc: 0.9665, P: 0.9604, R: 0.9729, F1: 0.9667, ROC: 0.9947, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0282, LR: 1.18e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0284, LR: 9.80e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0055, LR: 7.84e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0245, LR: 5.96e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0048, LR: 4.25e-04\n",
      "Epoch 4/5 — Train Loss: 0.0284\n",
      "Epoch 4 — Val Loss: 0.0915, Val F1: 0.9668 (Acc: 0.9670, P: 0.9707, R: 0.9629, F1: 0.9668, ROC: 0.9950, PR: 0.9949)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0683, LR: 3.36e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0105, LR: 2.03e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0079, LR: 9.98e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0025, LR: 3.20e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0454, LR: 1.59e-06\n",
      "Epoch 5/5 — Train Loss: 0.0149\n",
      "Epoch 5 — Val Loss: 0.0931, Val F1: 0.9674 (Acc: 0.9675, P: 0.9688, R: 0.9659, F1: 0.9674, ROC: 0.9950, PR: 0.9950)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0915\n",
      "\n",
      "Training finished. Total time: 31.87s. Model size: 1035245.24 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9670\n",
      "  - Precision: 0.9707\n",
      "  - Recall: 0.9629\n",
      "  - F1: 0.9668\n",
      "  - Roc_auc: 0.9950\n",
      "  - Pr_auc: 0.9949\n",
      "  - Val_loss: 0.0915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:40:26,759] Trial 58 finished with value: 0.9668008048289738 and parameters: {'max_learning_rate': 0.0020158600955377044, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.2, 'weight_decay': 5.7300513877587005e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9668\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0014379201746909933, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.6400262607564408e-06, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 5.91e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6823, LR: 1.54e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6457, LR: 3.76e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5316, LR: 6.79e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3372, LR: 9.96e-04\n",
      "Epoch 1/5 — Train Loss: 0.5713\n",
      "Epoch 1 — Val Loss: 0.3329, Val F1: 0.8798 (Acc: 0.8724, P: 0.8308, R: 0.9349, F1: 0.8798, ROC: 0.9309, PR: 0.9269)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2880, LR: 1.16e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1995, LR: 1.36e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1458, LR: 1.44e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1378, LR: 1.42e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1923, LR: 1.38e-03\n",
      "Epoch 2/5 — Train Loss: 0.1792\n",
      "Epoch 2 — Val Loss: 0.1371, Val F1: 0.9596 (Acc: 0.9595, P: 0.9553, R: 0.9639, F1: 0.9596, ROC: 0.9912, PR: 0.9870)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1029, LR: 1.35e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0791, LR: 1.27e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0425, LR: 1.17e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0798, LR: 1.05e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1287, LR: 9.18e-04\n",
      "Epoch 3/5 — Train Loss: 0.0858\n",
      "Epoch 3 — Val Loss: 0.1075, Val F1: 0.9699 (Acc: 0.9700, P: 0.9718, R: 0.9679, F1: 0.9699, ROC: 0.9933, PR: 0.9916)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0555, LR: 8.39e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0678, LR: 6.99e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0289, LR: 5.59e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0225, LR: 4.25e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0094, LR: 3.03e-04\n",
      "Epoch 4/5 — Train Loss: 0.0557\n",
      "Epoch 4 — Val Loss: 0.1040, Val F1: 0.9713 (Acc: 0.9715, P: 0.9777, R: 0.9649, F1: 0.9713, ROC: 0.9936, PR: 0.9922)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0128, LR: 2.40e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0246, LR: 1.45e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.1484, LR: 7.12e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0277, LR: 2.28e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0165, LR: 1.14e-06\n",
      "Epoch 5/5 — Train Loss: 0.0459\n",
      "Epoch 5 — Val Loss: 0.1023, Val F1: 0.9703 (Acc: 0.9705, P: 0.9747, R: 0.9659, F1: 0.9703, ROC: 0.9937, PR: 0.9926)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1023\n",
      "\n",
      "Training finished. Total time: 31.49s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9705\n",
      "  - Precision: 0.9747\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9703\n",
      "  - Roc_auc: 0.9937\n",
      "  - Pr_auc: 0.9926\n",
      "  - Val_loss: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:41:10,563] Trial 59 finished with value: 0.9703069954705587 and parameters: {'max_learning_rate': 0.0014379201746909933, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 1.6400262607564408e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9703\n",
      "Selected hidden_dims: [256, 32] (index 7)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0029766576498514823, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00018061845437668714, embedding_dim=64, hidden_dims=[256, 32], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6970, LR: 1.22e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6834, LR: 3.19e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6355, LR: 7.79e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4686, LR: 1.40e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2417, LR: 2.06e-03\n",
      "Epoch 1/5 — Train Loss: 0.5414\n",
      "Epoch 1 — Val Loss: 0.2228, Val F1: 0.9352 (Acc: 0.9334, P: 0.9100, R: 0.9619, F1: 0.9352, ROC: 0.9796, PR: 0.9697)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1662, LR: 2.40e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0984, LR: 2.82e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0232, LR: 2.98e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0194, LR: 2.95e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1077, LR: 2.86e-03\n",
      "Epoch 2/5 — Train Loss: 0.1406\n",
      "Epoch 2 — Val Loss: 0.1195, Val F1: 0.9684 (Acc: 0.9685, P: 0.9689, R: 0.9679, F1: 0.9684, ROC: 0.9938, PR: 0.9893)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0399, LR: 2.79e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0603, LR: 2.63e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0531, LR: 2.42e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0167, LR: 2.17e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0587, LR: 1.90e-03\n",
      "Epoch 3/5 — Train Loss: 0.0503\n",
      "Epoch 3 — Val Loss: 0.0970, Val F1: 0.9713 (Acc: 0.9715, P: 0.9748, R: 0.9679, F1: 0.9713, ROC: 0.9951, PR: 0.9954)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0043, LR: 1.74e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0314, LR: 1.45e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0514, LR: 1.16e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0407, LR: 8.80e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0380, LR: 6.27e-04\n",
      "Epoch 4/5 — Train Loss: 0.0219\n",
      "Epoch 4 — Val Loss: 0.0912, Val F1: 0.9719 (Acc: 0.9720, P: 0.9738, R: 0.9699, F1: 0.9719, ROC: 0.9957, PR: 0.9959)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0556, LR: 4.97e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0494, LR: 2.99e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0113, LR: 1.47e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0212, LR: 4.72e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0045, LR: 2.35e-06\n",
      "Epoch 5/5 — Train Loss: 0.0147\n",
      "Epoch 5 — Val Loss: 0.1042, Val F1: 0.9729 (Acc: 0.9730, P: 0.9729, R: 0.9729, F1: 0.9729, ROC: 0.9957, PR: 0.9958)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0912\n",
      "\n",
      "Training finished. Total time: 31.85s. Model size: 1035148.12 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9720\n",
      "  - Precision: 0.9738\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9719\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9959\n",
      "  - Val_loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:41:54,214] Trial 60 finished with value: 0.9718875502008032 and parameters: {'max_learning_rate': 0.0029766576498514823, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 0.00018061845437668714}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9719\n",
      "Selected hidden_dims: [256, 32] (index 7)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0031249881086333493, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=9.797624711192913e-05, embedding_dim=64, hidden_dims=[256, 32], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6970, LR: 1.28e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6829, LR: 3.34e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6316, LR: 8.18e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4552, LR: 1.47e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2231, LR: 2.16e-03\n",
      "Epoch 1/5 — Train Loss: 0.5361\n",
      "Epoch 1 — Val Loss: 0.2481, Val F1: 0.9276 (Acc: 0.9244, P: 0.8896, R: 0.9689, F1: 0.9276, ROC: 0.9757, PR: 0.9610)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1715, LR: 2.51e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1018, LR: 2.96e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0195, LR: 3.12e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0172, LR: 3.09e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1094, LR: 3.01e-03\n",
      "Epoch 2/5 — Train Loss: 0.1367\n",
      "Epoch 2 — Val Loss: 0.1249, Val F1: 0.9615 (Acc: 0.9610, P: 0.9466, R: 0.9770, F1: 0.9615, ROC: 0.9941, PR: 0.9912)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0328, LR: 2.93e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0604, LR: 2.76e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0504, LR: 2.54e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0137, LR: 2.28e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0446, LR: 2.00e-03\n",
      "Epoch 3/5 — Train Loss: 0.0517\n",
      "Epoch 3 — Val Loss: 0.1010, Val F1: 0.9682 (Acc: 0.9685, P: 0.9766, R: 0.9599, F1: 0.9682, ROC: 0.9947, PR: 0.9950)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0046, LR: 1.82e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0366, LR: 1.52e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0500, LR: 1.21e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0425, LR: 9.24e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0323, LR: 6.58e-04\n",
      "Epoch 4/5 — Train Loss: 0.0218\n",
      "Epoch 4 — Val Loss: 0.0854, Val F1: 0.9713 (Acc: 0.9715, P: 0.9757, R: 0.9669, F1: 0.9713, ROC: 0.9961, PR: 0.9961)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0512, LR: 5.21e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0453, LR: 3.14e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0122, LR: 1.55e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0344, LR: 4.95e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0045, LR: 2.47e-06\n",
      "Epoch 5/5 — Train Loss: 0.0143\n",
      "Epoch 5 — Val Loss: 0.0862, Val F1: 0.9713 (Acc: 0.9715, P: 0.9757, R: 0.9669, F1: 0.9713, ROC: 0.9962, PR: 0.9962)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0854\n",
      "\n",
      "Training finished. Total time: 31.76s. Model size: 1035148.12 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9757\n",
      "  - Recall: 0.9669\n",
      "  - F1: 0.9713\n",
      "  - Roc_auc: 0.9961\n",
      "  - Pr_auc: 0.9961\n",
      "  - Val_loss: 0.0854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:42:37,918] Trial 61 finished with value: 0.9713135379969804 and parameters: {'max_learning_rate': 0.0031249881086333493, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 9.797624711192913e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9713\n",
      "Selected hidden_dims: [256, 32] (index 7)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0024628396305713613, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00020065710101465958, embedding_dim=64, hidden_dims=[256, 32], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6970, LR: 1.01e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6854, LR: 2.64e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6473, LR: 6.45e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5236, LR: 1.16e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2938, LR: 1.71e-03\n",
      "Epoch 1/5 — Train Loss: 0.5581\n",
      "Epoch 1 — Val Loss: 0.2105, Val F1: 0.9329 (Acc: 0.9324, P: 0.9251, R: 0.9409, F1: 0.9329, ROC: 0.9779, PR: 0.9708)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1890, LR: 1.98e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1358, LR: 2.34e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0296, LR: 2.46e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0220, LR: 2.44e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1154, LR: 2.37e-03\n",
      "Epoch 2/5 — Train Loss: 0.1435\n",
      "Epoch 2 — Val Loss: 0.1250, Val F1: 0.9638 (Acc: 0.9635, P: 0.9530, R: 0.9749, F1: 0.9638, ROC: 0.9937, PR: 0.9898)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0320, LR: 2.31e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0637, LR: 2.17e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0537, LR: 2.00e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0175, LR: 1.80e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0615, LR: 1.57e-03\n",
      "Epoch 3/5 — Train Loss: 0.0561\n",
      "Epoch 3 — Val Loss: 0.1098, Val F1: 0.9678 (Acc: 0.9680, P: 0.9708, R: 0.9649, F1: 0.9678, ROC: 0.9942, PR: 0.9944)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0056, LR: 1.44e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0402, LR: 1.20e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0568, LR: 9.57e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0416, LR: 7.28e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0363, LR: 5.19e-04\n",
      "Epoch 4/5 — Train Loss: 0.0268\n",
      "Epoch 4 — Val Loss: 0.1070, Val F1: 0.9674 (Acc: 0.9675, P: 0.9698, R: 0.9649, F1: 0.9674, ROC: 0.9957, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0534, LR: 4.11e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0482, LR: 2.48e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0142, LR: 1.22e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0296, LR: 3.90e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0068, LR: 1.95e-06\n",
      "Epoch 5/5 — Train Loss: 0.0181\n",
      "Epoch 5 — Val Loss: 0.1137, Val F1: 0.9679 (Acc: 0.9680, P: 0.9679, R: 0.9679, F1: 0.9679, ROC: 0.9954, PR: 0.9949)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1070\n",
      "\n",
      "Training finished. Total time: 31.59s. Model size: 1035148.12 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9675\n",
      "  - Precision: 0.9698\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9674\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9955\n",
      "  - Val_loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:43:21,157] Trial 62 finished with value: 0.9673530889000502 and parameters: {'max_learning_rate': 0.0024628396305713613, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 0.00020065710101465958}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9674\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0041869033102684, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.0223907628695964e-06, embedding_dim=64, hidden_dims=[256, 64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6925, LR: 1.72e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6854, LR: 4.48e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5967, LR: 1.10e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3567, LR: 1.98e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1125, LR: 2.90e-03\n",
      "Epoch 1/5 — Train Loss: 0.4766\n",
      "Epoch 1 — Val Loss: 0.1732, Val F1: 0.9409 (Acc: 0.9394, P: 0.9172, R: 0.9659, F1: 0.9409, ROC: 0.9850, PR: 0.9787)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1229, LR: 3.37e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1224, LR: 3.97e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0292, LR: 4.19e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1178, LR: 4.15e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0660, LR: 4.03e-03\n",
      "Epoch 2/5 — Train Loss: 0.1177\n",
      "Epoch 2 — Val Loss: 0.0840, Val F1: 0.9713 (Acc: 0.9715, P: 0.9757, R: 0.9669, F1: 0.9713, ROC: 0.9952, PR: 0.9950)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0173, LR: 3.93e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1067, LR: 3.69e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0055, LR: 3.40e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0437, LR: 3.05e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0398, LR: 2.67e-03\n",
      "Epoch 3/5 — Train Loss: 0.0387\n",
      "Epoch 3 — Val Loss: 0.1029, Val F1: 0.9705 (Acc: 0.9705, P: 0.9672, R: 0.9739, F1: 0.9705, ROC: 0.9956, PR: 0.9954)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0121, LR: 2.44e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0097, LR: 2.03e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0062, LR: 1.63e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0047, LR: 1.24e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0371, LR: 8.82e-04\n",
      "Epoch 4/5 — Train Loss: 0.0133\n",
      "Epoch 4 — Val Loss: 0.0933, Val F1: 0.9758 (Acc: 0.9760, P: 0.9808, R: 0.9709, F1: 0.9758, ROC: 0.9960, PR: 0.9963)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0840\n",
      "\n",
      "Training finished. Total time: 27.45s. Model size: 1035180.49 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9757\n",
      "  - Recall: 0.9669\n",
      "  - F1: 0.9713\n",
      "  - Roc_auc: 0.9952\n",
      "  - Pr_auc: 0.9950\n",
      "  - Val_loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:44:00,656] Trial 63 finished with value: 0.9713135379969804 and parameters: {'max_learning_rate': 0.0041869033102684, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 3.0223907628695964e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9713\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0010720989362068222, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00017046401180989928, embedding_dim=64, hidden_dims=[256, 128], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6880, LR: 4.40e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6836, LR: 1.15e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6734, LR: 2.81e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6313, LR: 5.06e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.4881, LR: 7.42e-04\n",
      "Epoch 1/5 — Train Loss: 0.6235\n",
      "Epoch 1 — Val Loss: 0.3546, Val F1: 0.8624 (Acc: 0.8579, P: 0.8349, R: 0.8918, F1: 0.8624, ROC: 0.9275, PR: 0.9237)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.4433, LR: 8.63e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.3049, LR: 1.02e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1303, LR: 1.07e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0979, LR: 1.06e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1698, LR: 1.03e-03\n",
      "Epoch 2/5 — Train Loss: 0.2008\n",
      "Epoch 2 — Val Loss: 0.1218, Val F1: 0.9590 (Acc: 0.9590, P: 0.9562, R: 0.9619, F1: 0.9590, ROC: 0.9906, PR: 0.9862)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0807, LR: 1.01e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.2238, LR: 9.46e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.1202, LR: 8.70e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.2235, LR: 7.82e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0604, LR: 6.84e-04\n",
      "Epoch 3/5 — Train Loss: 0.0833\n",
      "Epoch 3 — Val Loss: 0.1189, Val F1: 0.9590 (Acc: 0.9585, P: 0.9463, R: 0.9719, F1: 0.9590, ROC: 0.9934, PR: 0.9932)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.1097, LR: 6.26e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0590, LR: 5.21e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0131, LR: 4.17e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0540, LR: 3.17e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0123, LR: 2.26e-04\n",
      "Epoch 4/5 — Train Loss: 0.0529\n",
      "Epoch 4 — Val Loss: 0.1008, Val F1: 0.9634 (Acc: 0.9635, P: 0.9630, R: 0.9639, F1: 0.9634, ROC: 0.9943, PR: 0.9943)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1198, LR: 1.79e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0210, LR: 1.08e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0388, LR: 5.31e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0074, LR: 1.70e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0539, LR: 8.48e-07\n",
      "Epoch 5/5 — Train Loss: 0.0412\n",
      "Epoch 5 — Val Loss: 0.0961, Val F1: 0.9653 (Acc: 0.9655, P: 0.9687, R: 0.9619, F1: 0.9653, ROC: 0.9945, PR: 0.9943)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0961\n",
      "\n",
      "Training finished. Total time: 31.89s. Model size: 1035245.24 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9655\n",
      "  - Precision: 0.9687\n",
      "  - Recall: 0.9619\n",
      "  - F1: 0.9653\n",
      "  - Roc_auc: 0.9945\n",
      "  - Pr_auc: 0.9943\n",
      "  - Val_loss: 0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:44:44,526] Trial 64 finished with value: 0.9653092006033183 and parameters: {'max_learning_rate': 0.0010720989362068222, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.4, 'weight_decay': 0.00017046401180989928}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9653\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=1.1632998764279112e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=6.769225483674067e-05, embedding_dim=64, hidden_dims=[256], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7006, LR: 4.68e-07\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.7088, LR: 1.07e-06\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6892, LR: 2.61e-06\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.7030, LR: 4.79e-06\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.6825, LR: 7.21e-06\n",
      "Epoch 1/5 — Train Loss: 0.6942\n",
      "Epoch 1 — Val Loss: 0.6879, Val F1: 0.5000 (Acc: 0.5996, P: 0.6645, R: 0.4008, F1: 0.5000, ROC: 0.5963, PR: 0.6193)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.6795, LR: 9.11e-06\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.6771, LR: 1.08e-05\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.6722, LR: 1.16e-05\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.6728, LR: 1.16e-05\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.6891, LR: 1.13e-05\n",
      "Epoch 2/5 — Train Loss: 0.6750\n",
      "Epoch 2 — Val Loss: 0.6629, Val F1: 0.6529 (Acc: 0.7132, P: 0.8254, R: 0.5401, F1: 0.6529, ROC: 0.8202, PR: 0.8036)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.6744, LR: 1.10e-05\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.6553, LR: 1.04e-05\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.6489, LR: 9.67e-06\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.6543, LR: 8.80e-06\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.6253, LR: 7.83e-06\n",
      "Epoch 3/5 — Train Loss: 0.6488\n",
      "Epoch 3 — Val Loss: 0.6403, Val F1: 0.7396 (Acc: 0.7713, P: 0.8573, R: 0.6503, F1: 0.7396, ROC: 0.8929, PR: 0.8710)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.6403, LR: 6.95e-06\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.6198, LR: 5.88e-06\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.6157, LR: 4.81e-06\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.6296, LR: 3.77e-06\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.6047, LR: 2.80e-06\n",
      "Epoch 4/5 — Train Loss: 0.6290\n",
      "Epoch 4 — Val Loss: 0.6283, Val F1: 0.7868 (Acc: 0.8053, P: 0.8682, R: 0.7194, F1: 0.7868, ROC: 0.9103, PR: 0.8888)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.6131, LR: 2.06e-06\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.6480, LR: 1.31e-06\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.6214, LR: 7.08e-07\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.6192, LR: 2.83e-07\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.6191, LR: 4.78e-08\n",
      "Epoch 5/5 — Train Loss: 0.6219\n",
      "Epoch 5 — Val Loss: 0.6264, Val F1: 0.7902 (Acc: 0.8078, P: 0.8690, R: 0.7244, F1: 0.7902, ROC: 0.9123, PR: 0.8911)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.6264\n",
      "\n",
      "Training finished. Total time: 41.68s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.8078\n",
      "  - Precision: 0.8690\n",
      "  - Recall: 0.7244\n",
      "  - F1: 0.7902\n",
      "  - Roc_auc: 0.9123\n",
      "  - Pr_auc: 0.8911\n",
      "  - Val_loss: 0.6264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:45:37,711] Trial 65 finished with value: 0.7901639344262295 and parameters: {'max_learning_rate': 1.1632998764279112e-05, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.30000000000000004, 'weight_decay': 6.769225483674067e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.7902\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005845987426525882, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=7.73613136733225e-06, embedding_dim=64, hidden_dims=[64], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6859, LR: 2.40e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6345, LR: 6.26e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4778, LR: 1.53e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3049, LR: 2.76e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1829, LR: 4.05e-03\n",
      "Epoch 1/5 — Train Loss: 0.4442\n",
      "Epoch 1 — Val Loss: 0.1759, Val F1: 0.9323 (Acc: 0.9289, P: 0.8891, R: 0.9800, F1: 0.9323, ROC: 0.9864, PR: 0.9813)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2833, LR: 4.70e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1496, LR: 5.54e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0823, LR: 5.85e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1632, LR: 5.79e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0912, LR: 5.62e-03\n",
      "Epoch 2/5 — Train Loss: 0.1112\n",
      "Epoch 2 — Val Loss: 0.0893, Val F1: 0.9659 (Acc: 0.9655, P: 0.9523, R: 0.9800, F1: 0.9659, ROC: 0.9951, PR: 0.9946)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0348, LR: 5.48e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0056, LR: 5.16e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0024, LR: 4.75e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0143, LR: 4.26e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0257, LR: 3.73e-03\n",
      "Epoch 3/5 — Train Loss: 0.0395\n",
      "Epoch 3 — Val Loss: 0.1080, Val F1: 0.9653 (Acc: 0.9660, P: 0.9824, R: 0.9489, F1: 0.9653, ROC: 0.9953, PR: 0.9950)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0114, LR: 3.41e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0136, LR: 2.84e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0200, LR: 2.27e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0073, LR: 1.73e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0046, LR: 1.23e-03\n",
      "Epoch 4/5 — Train Loss: 0.0154\n",
      "Epoch 4 — Val Loss: 0.0941, Val F1: 0.9734 (Acc: 0.9735, P: 0.9749, R: 0.9719, F1: 0.9734, ROC: 0.9956, PR: 0.9959)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0893\n",
      "\n",
      "Training finished. Total time: 27.24s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9655\n",
      "  - Precision: 0.9523\n",
      "  - Recall: 0.9800\n",
      "  - F1: 0.9659\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9946\n",
      "  - Val_loss: 0.0893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:46:16,440] Trial 66 finished with value: 0.965925925925926 and parameters: {'max_learning_rate': 0.005845987426525882, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.4, 'weight_decay': 7.73613136733225e-06}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9659\n",
      "Selected hidden_dims: [128, 64] (index 9)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.007869747342425501, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00010779531381111566, embedding_dim=128, hidden_dims=[128, 64], dropout=0.30000000000000004, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6972, LR: 3.23e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6613, LR: 8.42e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3340, LR: 2.06e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2209, LR: 3.71e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.0885, LR: 5.45e-03\n",
      "Epoch 1/5 — Train Loss: 0.3980\n",
      "Epoch 1 — Val Loss: 0.1487, Val F1: 0.9588 (Acc: 0.9590, P: 0.9608, R: 0.9569, F1: 0.9588, ROC: 0.9883, PR: 0.9796)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0592, LR: 6.33e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0829, LR: 7.46e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0455, LR: 7.87e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0434, LR: 7.79e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0920, LR: 7.57e-03\n",
      "Epoch 2/5 — Train Loss: 0.1157\n",
      "Epoch 2 — Val Loss: 0.1062, Val F1: 0.9594 (Acc: 0.9605, P: 0.9852, R: 0.9349, F1: 0.9594, ROC: 0.9947, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0568, LR: 7.38e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0393, LR: 6.94e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.2406, LR: 6.39e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0064, LR: 5.74e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0013, LR: 5.02e-03\n",
      "Epoch 3/5 — Train Loss: 0.0485\n",
      "Epoch 3 — Val Loss: 0.1066, Val F1: 0.9683 (Acc: 0.9685, P: 0.9727, R: 0.9639, F1: 0.9683, ROC: 0.9950, PR: 0.9949)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0037, LR: 4.59e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0112, LR: 3.82e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0517, LR: 3.06e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0018, LR: 2.33e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0030, LR: 1.66e-03\n",
      "Epoch 4/5 — Train Loss: 0.0085\n",
      "Epoch 4 — Val Loss: 0.1380, Val F1: 0.9688 (Acc: 0.9690, P: 0.9746, R: 0.9629, F1: 0.9688, ROC: 0.9935, PR: 0.9934)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.1062\n",
      "\n",
      "Training finished. Total time: 53.66s. Model size: 2070013.87 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9605\n",
      "  - Precision: 0.9852\n",
      "  - Recall: 0.9349\n",
      "  - F1: 0.9594\n",
      "  - Roc_auc: 0.9947\n",
      "  - Pr_auc: 0.9951\n",
      "  - Val_loss: 0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:47:26,740] Trial 67 finished with value: 0.9593830334190231 and parameters: {'max_learning_rate': 0.007869747342425501, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 9, 'dropout': 0.30000000000000004, 'weight_decay': 0.00010779531381111566}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9594\n",
      "Selected hidden_dims: [256, 32] (index 7)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.004690617671725093, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00040944037963854555, embedding_dim=64, hidden_dims=[256, 32], dropout=0.2, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6987, LR: 1.93e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6748, LR: 5.02e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5638, LR: 1.23e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.4490, LR: 2.21e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2156, LR: 3.25e-03\n",
      "Epoch 1/5 — Train Loss: 0.4756\n",
      "Epoch 1 — Val Loss: 0.1736, Val F1: 0.9428 (Acc: 0.9404, P: 0.9066, R: 0.9820, F1: 0.9428, ROC: 0.9877, PR: 0.9782)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1106, LR: 3.77e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0900, LR: 4.45e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0198, LR: 4.69e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0158, LR: 4.65e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0750, LR: 4.51e-03\n",
      "Epoch 2/5 — Train Loss: 0.1102\n",
      "Epoch 2 — Val Loss: 0.0982, Val F1: 0.9657 (Acc: 0.9655, P: 0.9585, R: 0.9729, F1: 0.9657, ROC: 0.9946, PR: 0.9940)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0302, LR: 4.40e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0489, LR: 4.14e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0334, LR: 3.81e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0008, LR: 3.42e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0523, LR: 2.99e-03\n",
      "Epoch 3/5 — Train Loss: 0.0344\n",
      "Epoch 3 — Val Loss: 0.1018, Val F1: 0.9707 (Acc: 0.9710, P: 0.9796, R: 0.9619, F1: 0.9707, ROC: 0.9952, PR: 0.9959)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0023, LR: 2.74e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0205, LR: 2.28e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0146, LR: 1.82e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0564, LR: 1.39e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0229, LR: 9.88e-04\n",
      "Epoch 4/5 — Train Loss: 0.0121\n",
      "Epoch 4 — Val Loss: 0.1014, Val F1: 0.9728 (Acc: 0.9730, P: 0.9787, R: 0.9669, F1: 0.9728, ROC: 0.9953, PR: 0.9958)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0982\n",
      "\n",
      "Training finished. Total time: 27.63s. Model size: 1035148.12 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9655\n",
      "  - Precision: 0.9585\n",
      "  - Recall: 0.9729\n",
      "  - F1: 0.9657\n",
      "  - Roc_auc: 0.9946\n",
      "  - Pr_auc: 0.9940\n",
      "  - Val_loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:48:07,192] Trial 68 finished with value: 0.9656887120835406 and parameters: {'max_learning_rate': 0.004690617671725093, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.2, 'weight_decay': 0.00040944037963854555}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9657\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0004345252238696999, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0002579497262152991, embedding_dim=64, hidden_dims=[32], dropout=0.1, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6817, LR: 1.78e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.7057, LR: 4.65e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6812, LR: 1.14e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6585, LR: 2.05e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6236, LR: 3.01e-04\n",
      "Epoch 1/5 — Train Loss: 0.6638\n",
      "Epoch 1 — Val Loss: 0.5887, Val F1: 0.8440 (Acc: 0.8218, P: 0.7500, R: 0.9649, F1: 0.8440, ROC: 0.9202, PR: 0.8975)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.5538, LR: 3.50e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.4629, LR: 4.12e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.4471, LR: 4.35e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.4053, LR: 4.30e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.3231, LR: 4.18e-04\n",
      "Epoch 2/5 — Train Loss: 0.3917\n",
      "Epoch 2 — Val Loss: 0.2652, Val F1: 0.9123 (Acc: 0.9084, P: 0.8742, R: 0.9539, F1: 0.9123, ROC: 0.9667, PR: 0.9586)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.2732, LR: 4.07e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.2013, LR: 3.83e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.2833, LR: 3.53e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.2011, LR: 3.17e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.2228, LR: 2.77e-04\n",
      "Epoch 3/5 — Train Loss: 0.1978\n",
      "Epoch 3 — Val Loss: 0.1799, Val F1: 0.9458 (Acc: 0.9444, P: 0.9228, R: 0.9699, F1: 0.9458, ROC: 0.9854, PR: 0.9809)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.1923, LR: 2.54e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.1964, LR: 2.11e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.2000, LR: 1.69e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.2285, LR: 1.29e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.1586, LR: 9.15e-05\n",
      "Epoch 4/5 — Train Loss: 0.1439\n",
      "Epoch 4 — Val Loss: 0.1645, Val F1: 0.9536 (Acc: 0.9530, P: 0.9405, R: 0.9669, F1: 0.9536, ROC: 0.9880, PR: 0.9824)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1061, LR: 7.25e-05\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.1412, LR: 4.37e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.1022, LR: 2.15e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.1370, LR: 6.89e-06\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.1505, LR: 3.44e-07\n",
      "Epoch 5/5 — Train Loss: 0.1281\n",
      "Epoch 5 — Val Loss: 0.1641, Val F1: 0.9531 (Acc: 0.9525, P: 0.9396, R: 0.9669, F1: 0.9531, ROC: 0.9879, PR: 0.9819)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1641\n",
      "\n",
      "Training finished. Total time: 31.78s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9525\n",
      "  - Precision: 0.9396\n",
      "  - Recall: 0.9669\n",
      "  - F1: 0.9531\n",
      "  - Roc_auc: 0.9879\n",
      "  - Pr_auc: 0.9819\n",
      "  - Val_loss: 0.1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:48:50,870] Trial 69 finished with value: 0.9530864197530864 and parameters: {'max_learning_rate': 0.0004345252238696999, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 0.0002579497262152991}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9531\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.002381087409215055, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.1252075198582384e-05, embedding_dim=64, hidden_dims=[256], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7020, LR: 9.78e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6637, LR: 2.55e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5703, LR: 6.23e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3542, LR: 1.12e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1995, LR: 1.65e-03\n",
      "Epoch 1/5 — Train Loss: 0.4769\n",
      "Epoch 1 — Val Loss: 0.2063, Val F1: 0.9310 (Acc: 0.9329, P: 0.9576, R: 0.9058, F1: 0.9310, ROC: 0.9826, PR: 0.9774)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1322, LR: 1.92e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2345, LR: 2.26e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.4185, LR: 2.38e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2198, LR: 2.36e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0994, LR: 2.29e-03\n",
      "Epoch 2/5 — Train Loss: 0.1362\n",
      "Epoch 2 — Val Loss: 0.1087, Val F1: 0.9610 (Acc: 0.9605, P: 0.9474, R: 0.9749, F1: 0.9610, ROC: 0.9938, PR: 0.9916)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0467, LR: 2.23e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0442, LR: 2.10e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0301, LR: 1.93e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0247, LR: 1.74e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0209, LR: 1.52e-03\n",
      "Epoch 3/5 — Train Loss: 0.0525\n",
      "Epoch 3 — Val Loss: 0.0927, Val F1: 0.9728 (Acc: 0.9730, P: 0.9787, R: 0.9669, F1: 0.9728, ROC: 0.9950, PR: 0.9949)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0148, LR: 1.39e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0188, LR: 1.16e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0138, LR: 9.26e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0681, LR: 7.04e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0339, LR: 5.02e-04\n",
      "Epoch 4/5 — Train Loss: 0.0306\n",
      "Epoch 4 — Val Loss: 0.0858, Val F1: 0.9719 (Acc: 0.9720, P: 0.9748, R: 0.9689, F1: 0.9719, ROC: 0.9951, PR: 0.9950)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0314, LR: 3.97e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0193, LR: 2.39e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0074, LR: 1.18e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0196, LR: 3.77e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0116, LR: 1.88e-06\n",
      "Epoch 5/5 — Train Loss: 0.0203\n",
      "Epoch 5 — Val Loss: 0.0856, Val F1: 0.9728 (Acc: 0.9730, P: 0.9768, R: 0.9689, F1: 0.9728, ROC: 0.9951, PR: 0.9949)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0856\n",
      "\n",
      "Training finished. Total time: 31.90s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9730\n",
      "  - Precision: 0.9768\n",
      "  - Recall: 0.9689\n",
      "  - F1: 0.9728\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9949\n",
      "  - Val_loss: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:49:34,676] Trial 70 finished with value: 0.9728370221327968 and parameters: {'max_learning_rate': 0.002381087409215055, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 4.1252075198582384e-05}. Best is trial 23 with value: 0.9728370221327968.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9728\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0021826284394301206, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.3224939159096505e-05, embedding_dim=64, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6983, LR: 8.96e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6684, LR: 2.34e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5887, LR: 5.71e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3858, LR: 1.03e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2310, LR: 1.51e-03\n",
      "Epoch 1/5 — Train Loss: 0.4956\n",
      "Epoch 1 — Val Loss: 0.2111, Val F1: 0.9225 (Acc: 0.9229, P: 0.9263, R: 0.9188, F1: 0.9225, ROC: 0.9766, PR: 0.9710)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1056, LR: 1.76e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1971, LR: 2.07e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.4962, LR: 2.18e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2353, LR: 2.16e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1000, LR: 2.10e-03\n",
      "Epoch 2/5 — Train Loss: 0.1469\n",
      "Epoch 2 — Val Loss: 0.1211, Val F1: 0.9537 (Acc: 0.9530, P: 0.9371, R: 0.9709, F1: 0.9537, ROC: 0.9923, PR: 0.9890)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0553, LR: 2.05e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0528, LR: 1.93e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0377, LR: 1.77e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0288, LR: 1.59e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0320, LR: 1.39e-03\n",
      "Epoch 3/5 — Train Loss: 0.0620\n",
      "Epoch 3 — Val Loss: 0.0930, Val F1: 0.9718 (Acc: 0.9720, P: 0.9758, R: 0.9679, F1: 0.9718, ROC: 0.9949, PR: 0.9944)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0213, LR: 1.27e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0297, LR: 1.06e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0142, LR: 8.48e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0997, LR: 6.46e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0389, LR: 4.60e-04\n",
      "Epoch 4/5 — Train Loss: 0.0368\n",
      "Epoch 4 — Val Loss: 0.0856, Val F1: 0.9734 (Acc: 0.9735, P: 0.9758, R: 0.9709, F1: 0.9734, ROC: 0.9951, PR: 0.9950)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0473, LR: 3.64e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0202, LR: 2.19e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0111, LR: 1.08e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0245, LR: 3.46e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0161, LR: 1.73e-06\n",
      "Epoch 5/5 — Train Loss: 0.0267\n",
      "Epoch 5 — Val Loss: 0.0866, Val F1: 0.9718 (Acc: 0.9720, P: 0.9777, R: 0.9659, F1: 0.9718, ROC: 0.9950, PR: 0.9947)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0856\n",
      "\n",
      "Training finished. Total time: 32.04s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9735\n",
      "  - Precision: 0.9758\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9734\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9950\n",
      "  - Val_loss: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:50:18,841] Trial 71 finished with value: 0.9733802109492717 and parameters: {'max_learning_rate': 0.0021826284394301206, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 4.3224939159096505e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9734\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.002224671363017776, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.958859596707406e-05, embedding_dim=64, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6983, LR: 9.14e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6679, LR: 2.38e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5866, LR: 5.82e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3809, LR: 1.05e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2269, LR: 1.54e-03\n",
      "Epoch 1/5 — Train Loss: 0.4929\n",
      "Epoch 1 — Val Loss: 0.2098, Val F1: 0.9271 (Acc: 0.9279, P: 0.9366, R: 0.9178, F1: 0.9271, ROC: 0.9780, PR: 0.9727)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1102, LR: 1.79e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1979, LR: 2.11e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.4878, LR: 2.22e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2351, LR: 2.20e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1073, LR: 2.14e-03\n",
      "Epoch 2/5 — Train Loss: 0.1458\n",
      "Epoch 2 — Val Loss: 0.1204, Val F1: 0.9552 (Acc: 0.9545, P: 0.9399, R: 0.9709, F1: 0.9552, ROC: 0.9923, PR: 0.9889)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0543, LR: 2.09e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0495, LR: 1.96e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0373, LR: 1.81e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0272, LR: 1.62e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0321, LR: 1.42e-03\n",
      "Epoch 3/5 — Train Loss: 0.0617\n",
      "Epoch 3 — Val Loss: 0.0944, Val F1: 0.9708 (Acc: 0.9710, P: 0.9747, R: 0.9669, F1: 0.9708, ROC: 0.9946, PR: 0.9941)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0205, LR: 1.30e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0312, LR: 1.08e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0129, LR: 8.65e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0927, LR: 6.58e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0385, LR: 4.69e-04\n",
      "Epoch 4/5 — Train Loss: 0.0358\n",
      "Epoch 4 — Val Loss: 0.0874, Val F1: 0.9719 (Acc: 0.9720, P: 0.9738, R: 0.9699, F1: 0.9719, ROC: 0.9949, PR: 0.9947)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0486, LR: 3.71e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0193, LR: 2.24e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0106, LR: 1.10e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0244, LR: 3.53e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0154, LR: 1.76e-06\n",
      "Epoch 5/5 — Train Loss: 0.0258\n",
      "Epoch 5 — Val Loss: 0.0883, Val F1: 0.9718 (Acc: 0.9720, P: 0.9777, R: 0.9659, F1: 0.9718, ROC: 0.9947, PR: 0.9943)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0874\n",
      "\n",
      "Training finished. Total time: 31.91s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9720\n",
      "  - Precision: 0.9738\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9719\n",
      "  - Roc_auc: 0.9949\n",
      "  - Pr_auc: 0.9947\n",
      "  - Val_loss: 0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:51:02,862] Trial 72 finished with value: 0.9718875502008032 and parameters: {'max_learning_rate': 0.002224671363017776, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 3.958859596707406e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9719\n",
      "Selected hidden_dims: [256, 64] (index 6)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0021359966394775567, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=2.3536115793976603e-05, embedding_dim=64, hidden_dims=[256, 64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7003, LR: 8.77e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.7045, LR: 2.29e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6744, LR: 5.59e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5907, LR: 1.01e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2595, LR: 1.48e-03\n",
      "Epoch 1/5 — Train Loss: 0.5819\n",
      "Epoch 1 — Val Loss: 0.3646, Val F1: 0.8850 (Acc: 0.8784, P: 0.8386, R: 0.9369, F1: 0.8850, ROC: 0.9331, PR: 0.9281)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2634, LR: 1.72e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1949, LR: 2.03e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0611, LR: 2.14e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1662, LR: 2.12e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1428, LR: 2.05e-03\n",
      "Epoch 2/5 — Train Loss: 0.1653\n",
      "Epoch 2 — Val Loss: 0.1303, Val F1: 0.9570 (Acc: 0.9565, P: 0.9453, R: 0.9689, F1: 0.9570, ROC: 0.9914, PR: 0.9901)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0411, LR: 2.00e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.1674, LR: 1.88e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0272, LR: 1.73e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0928, LR: 1.56e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0566, LR: 1.36e-03\n",
      "Epoch 3/5 — Train Loss: 0.0650\n",
      "Epoch 3 — Val Loss: 0.1368, Val F1: 0.9713 (Acc: 0.9715, P: 0.9767, R: 0.9659, F1: 0.9713, ROC: 0.9946, PR: 0.9942)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0440, LR: 1.25e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0621, LR: 1.04e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0299, LR: 8.30e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0136, LR: 6.32e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0747, LR: 4.50e-04\n",
      "Epoch 4/5 — Train Loss: 0.0341\n",
      "Epoch 4 — Val Loss: 0.1437, Val F1: 0.9743 (Acc: 0.9745, P: 0.9807, R: 0.9679, F1: 0.9743, ROC: 0.9945, PR: 0.9943)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.1303\n",
      "\n",
      "Training finished. Total time: 28.13s. Model size: 1035180.49 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9565\n",
      "  - Precision: 0.9453\n",
      "  - Recall: 0.9689\n",
      "  - F1: 0.9570\n",
      "  - Roc_auc: 0.9914\n",
      "  - Pr_auc: 0.9901\n",
      "  - Val_loss: 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:51:42,912] Trial 73 finished with value: 0.9569520039584364 and parameters: {'max_learning_rate': 0.0021359966394775567, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 2.3536115793976603e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9570\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0030351319771814867, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.979288879054223e-05, embedding_dim=64, hidden_dims=[64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6865, LR: 1.25e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6629, LR: 3.25e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5985, LR: 7.94e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3903, LR: 1.43e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2608, LR: 2.10e-03\n",
      "Epoch 1/5 — Train Loss: 0.5134\n",
      "Epoch 1 — Val Loss: 0.2257, Val F1: 0.9197 (Acc: 0.9164, P: 0.8844, R: 0.9579, F1: 0.9197, ROC: 0.9715, PR: 0.9659)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2777, LR: 2.44e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1751, LR: 2.88e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0600, LR: 3.04e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1868, LR: 3.01e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1470, LR: 2.92e-03\n",
      "Epoch 2/5 — Train Loss: 0.1434\n",
      "Epoch 2 — Val Loss: 0.1460, Val F1: 0.9444 (Acc: 0.9429, P: 0.9194, R: 0.9709, F1: 0.9444, ROC: 0.9908, PR: 0.9888)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0867, LR: 2.85e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0307, LR: 2.68e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0113, LR: 2.46e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0599, LR: 2.21e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0415, LR: 1.94e-03\n",
      "Epoch 3/5 — Train Loss: 0.0711\n",
      "Epoch 3 — Val Loss: 0.0920, Val F1: 0.9701 (Acc: 0.9705, P: 0.9806, R: 0.9599, F1: 0.9701, ROC: 0.9950, PR: 0.9937)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0293, LR: 1.77e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0320, LR: 1.48e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0358, LR: 1.18e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0180, LR: 8.98e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0123, LR: 6.39e-04\n",
      "Epoch 4/5 — Train Loss: 0.0362\n",
      "Epoch 4 — Val Loss: 0.0874, Val F1: 0.9703 (Acc: 0.9705, P: 0.9757, R: 0.9649, F1: 0.9703, ROC: 0.9951, PR: 0.9947)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0286, LR: 5.06e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0128, LR: 3.05e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0186, LR: 1.50e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0611, LR: 4.81e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0307, LR: 2.40e-06\n",
      "Epoch 5/5 — Train Loss: 0.0290\n",
      "Epoch 5 — Val Loss: 0.0898, Val F1: 0.9712 (Acc: 0.9715, P: 0.9786, R: 0.9639, F1: 0.9712, ROC: 0.9951, PR: 0.9946)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0874\n",
      "\n",
      "Training finished. Total time: 32.04s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9705\n",
      "  - Precision: 0.9757\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9703\n",
      "  - Roc_auc: 0.9951\n",
      "  - Pr_auc: 0.9947\n",
      "  - Val_loss: 0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:52:26,917] Trial 74 finished with value: 0.9702770780856423 and parameters: {'max_learning_rate': 0.0030351319771814867, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 4.979288879054223e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9703\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0023623514241845928, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.939736612736251e-05, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 9.70e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6724, LR: 2.53e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6026, LR: 6.18e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3979, LR: 1.11e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3584, LR: 1.64e-03\n",
      "Epoch 1/5 — Train Loss: 0.5213\n",
      "Epoch 1 — Val Loss: 0.2147, Val F1: 0.9320 (Acc: 0.9299, P: 0.9040, R: 0.9619, F1: 0.9320, ROC: 0.9760, PR: 0.9691)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1971, LR: 1.90e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1456, LR: 2.24e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1315, LR: 2.36e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1379, LR: 2.34e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1414, LR: 2.27e-03\n",
      "Epoch 2/5 — Train Loss: 0.1416\n",
      "Epoch 2 — Val Loss: 0.1260, Val F1: 0.9629 (Acc: 0.9630, P: 0.9648, R: 0.9609, F1: 0.9629, ROC: 0.9918, PR: 0.9891)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0679, LR: 2.21e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0583, LR: 2.08e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0306, LR: 1.92e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0541, LR: 1.72e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1107, LR: 1.51e-03\n",
      "Epoch 3/5 — Train Loss: 0.0644\n",
      "Epoch 3 — Val Loss: 0.1035, Val F1: 0.9708 (Acc: 0.9710, P: 0.9747, R: 0.9669, F1: 0.9708, ROC: 0.9937, PR: 0.9924)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0341, LR: 1.38e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0380, LR: 1.15e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0212, LR: 9.18e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0096, LR: 6.99e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0029, LR: 4.98e-04\n",
      "Epoch 4/5 — Train Loss: 0.0354\n",
      "Epoch 4 — Val Loss: 0.0989, Val F1: 0.9713 (Acc: 0.9715, P: 0.9777, R: 0.9649, F1: 0.9713, ROC: 0.9944, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0049, LR: 3.94e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0096, LR: 2.37e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0927, LR: 1.17e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0156, LR: 3.74e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0096, LR: 1.87e-06\n",
      "Epoch 5/5 — Train Loss: 0.0258\n",
      "Epoch 5 — Val Loss: 0.0994, Val F1: 0.9694 (Acc: 0.9695, P: 0.9709, R: 0.9679, F1: 0.9694, ROC: 0.9945, PR: 0.9942)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0989\n",
      "\n",
      "Training finished. Total time: 31.72s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9777\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9713\n",
      "  - Roc_auc: 0.9944\n",
      "  - Pr_auc: 0.9938\n",
      "  - Val_loss: 0.0989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:53:10,819] Trial 75 finished with value: 0.9712556732223904 and parameters: {'max_learning_rate': 0.0023623514241845928, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 3.939736612736251e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9713\n",
      "Selected hidden_dims: [64, 16] (index 13)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.0015003779118791976, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.1934910208205549e-05, embedding_dim=64, hidden_dims=[64, 16], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.7010, LR: 6.04e-05\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6935, LR: 1.38e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6894, LR: 3.37e-04\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.6716, LR: 6.18e-04\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.5457, LR: 9.30e-04\n",
      "Epoch 1/5 — Train Loss: 0.6292\n",
      "Epoch 1 — Val Loss: 0.3659, Val F1: 0.8792 (Acc: 0.8724, P: 0.8338, R: 0.9299, F1: 0.8792, ROC: 0.9378, PR: 0.9313)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.5821, LR: 1.17e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.3568, LR: 1.39e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.1747, LR: 1.50e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.4956, LR: 1.49e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.1089, LR: 1.46e-03\n",
      "Epoch 2/5 — Train Loss: 0.2336\n",
      "Epoch 2 — Val Loss: 0.2047, Val F1: 0.9455 (Acc: 0.9444, P: 0.9269, R: 0.9649, F1: 0.9455, ROC: 0.9875, PR: 0.9841)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0964, LR: 1.42e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.1528, LR: 1.34e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.1318, LR: 1.25e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0450, LR: 1.13e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0663, LR: 1.01e-03\n",
      "Epoch 3/5 — Train Loss: 0.1099\n",
      "Epoch 3 — Val Loss: 0.1355, Val F1: 0.9663 (Acc: 0.9665, P: 0.9707, R: 0.9619, F1: 0.9663, ROC: 0.9913, PR: 0.9910)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0266, LR: 8.96e-04\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0714, LR: 7.58e-04\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.0347, LR: 6.20e-04\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0368, LR: 4.86e-04\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0264, LR: 3.61e-04\n",
      "Epoch 4/5 — Train Loss: 0.0678\n",
      "Epoch 4 — Val Loss: 0.1278, Val F1: 0.9677 (Acc: 0.9680, P: 0.9736, R: 0.9619, F1: 0.9677, ROC: 0.9922, PR: 0.9920)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.0389, LR: 2.66e-04\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.0586, LR: 1.69e-04\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.0432, LR: 9.14e-05\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.0567, LR: 3.66e-05\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.0313, LR: 6.17e-06\n",
      "Epoch 5/5 — Train Loss: 0.0595\n",
      "Epoch 5 — Val Loss: 0.1306, Val F1: 0.9664 (Acc: 0.9665, P: 0.9678, R: 0.9649, F1: 0.9664, ROC: 0.9924, PR: 0.9926)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.1278\n",
      "\n",
      "Training finished. Total time: 41.58s. Model size: 1034782.43 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9680\n",
      "  - Precision: 0.9736\n",
      "  - Recall: 0.9619\n",
      "  - F1: 0.9677\n",
      "  - Roc_auc: 0.9922\n",
      "  - Pr_auc: 0.9920\n",
      "  - Val_loss: 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:54:04,776] Trial 76 finished with value: 0.967741935483871 and parameters: {'max_learning_rate': 0.0015003779118791976, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 13, 'dropout': 0.5, 'weight_decay': 1.1934910208205549e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9677\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=2.2199402095439714e-05, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=6.704692944992521e-05, embedding_dim=128, hidden_dims=[256, 128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6909, LR: 9.12e-07\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6895, LR: 2.38e-06\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.7011, LR: 5.81e-06\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6972, LR: 1.05e-05\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.6882, LR: 1.54e-05\n",
      "Epoch 1/5 — Train Loss: 0.6953\n",
      "Epoch 1 — Val Loss: 0.6908, Val F1: 0.5547 (Acc: 0.6031, P: 0.6309, R: 0.4950, F1: 0.5547, ROC: 0.6152, PR: 0.6208)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.7001, LR: 1.79e-05\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.6830, LR: 2.11e-05\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.6915, LR: 2.22e-05\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.6863, LR: 2.20e-05\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.6849, LR: 2.14e-05\n",
      "Epoch 2/5 — Train Loss: 0.6872\n",
      "Epoch 2 — Val Loss: 0.6781, Val F1: 0.7868 (Acc: 0.8033, P: 0.8580, R: 0.7265, F1: 0.7868, ROC: 0.8855, PR: 0.8607)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.6806, LR: 2.08e-05\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.6665, LR: 1.96e-05\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.6801, LR: 1.80e-05\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.6748, LR: 1.62e-05\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.6661, LR: 1.42e-05\n",
      "Epoch 3/5 — Train Loss: 0.6746\n",
      "Epoch 3 — Val Loss: 0.6658, Val F1: 0.8698 (Acc: 0.8709, P: 0.8760, R: 0.8637, F1: 0.8698, ROC: 0.9349, PR: 0.9167)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.6633, LR: 1.30e-05\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.6712, LR: 1.08e-05\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.6561, LR: 8.63e-06\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.6594, LR: 6.57e-06\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.6549, LR: 4.68e-06\n",
      "Epoch 4/5 — Train Loss: 0.6640\n",
      "Epoch 4 — Val Loss: 0.6587, Val F1: 0.8856 (Acc: 0.8844, P: 0.8756, R: 0.8958, F1: 0.8856, ROC: 0.9454, PR: 0.9306)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.6571, LR: 3.70e-06\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.6532, LR: 2.23e-06\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.6682, LR: 1.10e-06\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.6625, LR: 3.52e-07\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.6618, LR: 1.76e-08\n",
      "Epoch 5/5 — Train Loss: 0.6617\n",
      "Epoch 5 — Val Loss: 0.6575, Val F1: 0.8864 (Acc: 0.8849, P: 0.8743, R: 0.8988, F1: 0.8864, ROC: 0.9465, PR: 0.9323)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.6575\n",
      "\n",
      "Training finished. Total time: 64.34s. Model size: 2070559.62 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.8849\n",
      "  - Precision: 0.8743\n",
      "  - Recall: 0.8988\n",
      "  - F1: 0.8864\n",
      "  - Roc_auc: 0.9465\n",
      "  - Pr_auc: 0.9323\n",
      "  - Val_loss: 0.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:55:23,069] Trial 77 finished with value: 0.8863636363636364 and parameters: {'max_learning_rate': 2.2199402095439714e-05, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 6.704692944992521e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.8864\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0012111910174994387, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.592750383629086e-05, embedding_dim=64, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6983, LR: 4.97e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6818, LR: 1.30e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6372, LR: 3.17e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.5285, LR: 5.72e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3381, LR: 8.39e-04\n",
      "Epoch 1/5 — Train Loss: 0.5653\n",
      "Epoch 1 — Val Loss: 0.3263, Val F1: 0.8760 (Acc: 0.8704, P: 0.8387, R: 0.9168, F1: 0.8760, ROC: 0.9326, PR: 0.9283)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1535, LR: 9.75e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2801, LR: 1.15e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2554, LR: 1.21e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2361, LR: 1.20e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1487, LR: 1.17e-03\n",
      "Epoch 2/5 — Train Loss: 0.1789\n",
      "Epoch 2 — Val Loss: 0.1295, Val F1: 0.9564 (Acc: 0.9555, P: 0.9349, R: 0.9790, F1: 0.9564, ROC: 0.9913, PR: 0.9859)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0689, LR: 1.14e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0527, LR: 1.07e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0616, LR: 9.83e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0473, LR: 8.84e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0513, LR: 7.73e-04\n",
      "Epoch 3/5 — Train Loss: 0.0871\n",
      "Epoch 3 — Val Loss: 0.1028, Val F1: 0.9694 (Acc: 0.9695, P: 0.9699, R: 0.9689, F1: 0.9694, ROC: 0.9937, PR: 0.9916)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0440, LR: 7.07e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0466, LR: 5.89e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0305, LR: 4.71e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.1406, LR: 3.58e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0775, LR: 2.55e-04\n",
      "Epoch 4/5 — Train Loss: 0.0560\n",
      "Epoch 4 — Val Loss: 0.1046, Val F1: 0.9701 (Acc: 0.9705, P: 0.9806, R: 0.9599, F1: 0.9701, ROC: 0.9937, PR: 0.9918)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0935, LR: 2.02e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0323, LR: 1.22e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0280, LR: 6.00e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0531, LR: 1.92e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0342, LR: 9.58e-07\n",
      "Epoch 5/5 — Train Loss: 0.0460\n",
      "Epoch 5 — Val Loss: 0.0988, Val F1: 0.9709 (Acc: 0.9710, P: 0.9719, R: 0.9699, F1: 0.9709, ROC: 0.9940, PR: 0.9925)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0988\n",
      "\n",
      "Training finished. Total time: 31.84s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9719\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9709\n",
      "  - Roc_auc: 0.9940\n",
      "  - Pr_auc: 0.9925\n",
      "  - Val_loss: 0.0988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:56:07,202] Trial 78 finished with value: 0.970912738214644 and parameters: {'max_learning_rate': 0.0012111910174994387, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 3.592750383629086e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9709\n",
      "Selected hidden_dims: [256, 128] (index 5)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0008367180243799377, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=1.8562334653201786e-05, embedding_dim=64, hidden_dims=[256, 128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6830, LR: 3.44e-05\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6869, LR: 8.95e-05\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.6820, LR: 2.19e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.6498, LR: 3.95e-04\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.5885, LR: 5.79e-04\n",
      "Epoch 1/5 — Train Loss: 0.6540\n",
      "Epoch 1 — Val Loss: 0.4760, Val F1: 0.8669 (Acc: 0.8619, P: 0.8355, R: 0.9008, F1: 0.8669, ROC: 0.9364, PR: 0.9310)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.5245, LR: 6.73e-04\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.3645, LR: 7.94e-04\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1619, LR: 8.37e-04\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1370, LR: 8.29e-04\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2158, LR: 8.05e-04\n",
      "Epoch 2/5 — Train Loss: 0.2529\n",
      "Epoch 2 — Val Loss: 0.1378, Val F1: 0.9507 (Acc: 0.9505, P: 0.9446, R: 0.9569, F1: 0.9507, ROC: 0.9884, PR: 0.9839)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.1333, LR: 7.85e-04\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.2412, LR: 7.38e-04\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.1374, LR: 6.79e-04\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.2420, LR: 6.10e-04\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0960, LR: 5.34e-04\n",
      "Epoch 3/5 — Train Loss: 0.1069\n",
      "Epoch 3 — Val Loss: 0.1338, Val F1: 0.9537 (Acc: 0.9530, P: 0.9371, R: 0.9709, F1: 0.9537, ROC: 0.9915, PR: 0.9900)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.1433, LR: 4.88e-04\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0775, LR: 4.07e-04\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0221, LR: 3.25e-04\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0790, LR: 2.47e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0251, LR: 1.76e-04\n",
      "Epoch 4/5 — Train Loss: 0.0711\n",
      "Epoch 4 — Val Loss: 0.1125, Val F1: 0.9591 (Acc: 0.9590, P: 0.9553, R: 0.9629, F1: 0.9591, ROC: 0.9931, PR: 0.9923)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.1333, LR: 1.40e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0335, LR: 8.41e-05\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0575, LR: 4.14e-05\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0125, LR: 1.33e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0609, LR: 6.62e-07\n",
      "Epoch 5/5 — Train Loss: 0.0623\n",
      "Epoch 5 — Val Loss: 0.1062, Val F1: 0.9633 (Acc: 0.9635, P: 0.9658, R: 0.9609, F1: 0.9633, ROC: 0.9933, PR: 0.9924)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.1062\n",
      "\n",
      "Training finished. Total time: 31.92s. Model size: 1035245.24 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9635\n",
      "  - Precision: 0.9658\n",
      "  - Recall: 0.9609\n",
      "  - F1: 0.9633\n",
      "  - Roc_auc: 0.9933\n",
      "  - Pr_auc: 0.9924\n",
      "  - Val_loss: 0.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:56:51,007] Trial 79 finished with value: 0.9633350075339026 and parameters: {'max_learning_rate': 0.0008367180243799377, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 1.8562334653201786e-05}. Best is trial 71 with value: 0.9733802109492717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9633\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.006311264200084833, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=8.413267202596088e-05, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 2.59e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6285, LR: 6.75e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3857, LR: 1.65e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1768, LR: 2.98e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3508, LR: 4.37e-03\n",
      "Epoch 1/5 — Train Loss: 0.4082\n",
      "Epoch 1 — Val Loss: 0.1565, Val F1: 0.9470 (Acc: 0.9469, P: 0.9451, R: 0.9489, F1: 0.9470, ROC: 0.9881, PR: 0.9822)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0995, LR: 5.08e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1238, LR: 5.99e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1168, LR: 6.31e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0705, LR: 6.25e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1034, LR: 6.07e-03\n",
      "Epoch 2/5 — Train Loss: 0.1199\n",
      "Epoch 2 — Val Loss: 0.0952, Val F1: 0.9697 (Acc: 0.9700, P: 0.9786, R: 0.9609, F1: 0.9697, ROC: 0.9943, PR: 0.9940)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0454, LR: 5.92e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0270, LR: 5.57e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0105, LR: 5.12e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0260, LR: 4.60e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1017, LR: 4.03e-03\n",
      "Epoch 3/5 — Train Loss: 0.0397\n",
      "Epoch 3 — Val Loss: 0.0866, Val F1: 0.9702 (Acc: 0.9705, P: 0.9786, R: 0.9619, F1: 0.9702, ROC: 0.9957, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0102, LR: 3.68e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0096, LR: 3.07e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0127, LR: 2.45e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0035, LR: 1.87e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0007, LR: 1.33e-03\n",
      "Epoch 4/5 — Train Loss: 0.0154\n",
      "Epoch 4 — Val Loss: 0.0858, Val F1: 0.9734 (Acc: 0.9735, P: 0.9739, R: 0.9729, F1: 0.9734, ROC: 0.9957, PR: 0.9958)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0021, LR: 1.05e-03\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0015, LR: 6.34e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0358, LR: 3.13e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0024, LR: 1.00e-04\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0035, LR: 4.99e-06\n",
      "Epoch 5/5 — Train Loss: 0.0075\n",
      "Epoch 5 — Val Loss: 0.0878, Val F1: 0.9739 (Acc: 0.9740, P: 0.9739, R: 0.9739, F1: 0.9739, ROC: 0.9957, PR: 0.9959)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0858\n",
      "\n",
      "Training finished. Total time: 31.82s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9735\n",
      "  - Precision: 0.9739\n",
      "  - Recall: 0.9729\n",
      "  - F1: 0.9734\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9958\n",
      "  - Val_loss: 0.0858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:57:34,772] Trial 80 finished with value: 0.9734335839598998 and parameters: {'max_learning_rate': 0.006311264200084833, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 8.413267202596088e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9734\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0062338028367451195, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=2.8138484113782066e-05, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 2.56e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6294, LR: 6.67e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3897, LR: 1.63e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1799, LR: 2.94e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3516, LR: 4.32e-03\n",
      "Epoch 1/5 — Train Loss: 0.4099\n",
      "Epoch 1 — Val Loss: 0.1536, Val F1: 0.9489 (Acc: 0.9489, P: 0.9489, R: 0.9489, F1: 0.9489, ROC: 0.9883, PR: 0.9829)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0903, LR: 5.02e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1284, LR: 5.91e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1175, LR: 6.23e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0644, LR: 6.17e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0962, LR: 6.00e-03\n",
      "Epoch 2/5 — Train Loss: 0.1209\n",
      "Epoch 2 — Val Loss: 0.0949, Val F1: 0.9697 (Acc: 0.9700, P: 0.9766, R: 0.9629, F1: 0.9697, ROC: 0.9943, PR: 0.9942)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0434, LR: 5.84e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0252, LR: 5.50e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0109, LR: 5.06e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0241, LR: 4.55e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0893, LR: 3.98e-03\n",
      "Epoch 3/5 — Train Loss: 0.0400\n",
      "Epoch 3 — Val Loss: 0.0868, Val F1: 0.9712 (Acc: 0.9715, P: 0.9786, R: 0.9639, F1: 0.9712, ROC: 0.9956, PR: 0.9956)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0093, LR: 3.64e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0100, LR: 3.03e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0122, LR: 2.42e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0021, LR: 1.84e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0006, LR: 1.31e-03\n",
      "Epoch 4/5 — Train Loss: 0.0151\n",
      "Epoch 4 — Val Loss: 0.0893, Val F1: 0.9728 (Acc: 0.9730, P: 0.9768, R: 0.9689, F1: 0.9728, ROC: 0.9958, PR: 0.9962)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0018, LR: 1.04e-03\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0015, LR: 6.26e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0482, LR: 3.09e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0023, LR: 9.88e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0044, LR: 4.93e-06\n",
      "Epoch 5/5 — Train Loss: 0.0084\n",
      "Epoch 5 — Val Loss: 0.0907, Val F1: 0.9724 (Acc: 0.9725, P: 0.9748, R: 0.9699, F1: 0.9724, ROC: 0.9954, PR: 0.9957)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0868\n",
      "\n",
      "Training finished. Total time: 31.87s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9715\n",
      "  - Precision: 0.9786\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9712\n",
      "  - Roc_auc: 0.9956\n",
      "  - Pr_auc: 0.9956\n",
      "  - Val_loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:58:18,901] Trial 81 finished with value: 0.9712266532054518 and parameters: {'max_learning_rate': 0.0062338028367451195, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 2.8138484113782066e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9712\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.008371098494573922, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=5.282023956047794e-05, embedding_dim=64, hidden_dims=[64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6865, LR: 3.44e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6109, LR: 8.96e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3779, LR: 2.19e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3326, LR: 3.95e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1390, LR: 5.80e-03\n",
      "Epoch 1/5 — Train Loss: 0.4134\n",
      "Epoch 1 — Val Loss: 0.1605, Val F1: 0.9455 (Acc: 0.9439, P: 0.9187, R: 0.9739, F1: 0.9455, ROC: 0.9883, PR: 0.9840)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2836, LR: 6.74e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1323, LR: 7.94e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0687, LR: 8.37e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1814, LR: 8.29e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0872, LR: 8.05e-03\n",
      "Epoch 2/5 — Train Loss: 0.1059\n",
      "Epoch 2 — Val Loss: 0.0761, Val F1: 0.9702 (Acc: 0.9700, P: 0.9625, R: 0.9780, F1: 0.9702, ROC: 0.9968, PR: 0.9970)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0259, LR: 7.85e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0050, LR: 7.38e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0008, LR: 6.80e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0169, LR: 6.11e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0410, LR: 5.34e-03\n",
      "Epoch 3/5 — Train Loss: 0.0399\n",
      "Epoch 3 — Val Loss: 0.0809, Val F1: 0.9663 (Acc: 0.9670, P: 0.9864, R: 0.9469, F1: 0.9663, ROC: 0.9974, PR: 0.9975)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0102, LR: 4.89e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0149, LR: 4.07e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0118, LR: 3.25e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0147, LR: 2.48e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0089, LR: 1.76e-03\n",
      "Epoch 4/5 — Train Loss: 0.0140\n",
      "Epoch 4 — Val Loss: 0.0769, Val F1: 0.9743 (Acc: 0.9745, P: 0.9797, R: 0.9689, F1: 0.9743, ROC: 0.9970, PR: 0.9972)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0761\n",
      "\n",
      "Training finished. Total time: 27.31s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9625\n",
      "  - Recall: 0.9780\n",
      "  - F1: 0.9702\n",
      "  - Roc_auc: 0.9968\n",
      "  - Pr_auc: 0.9970\n",
      "  - Val_loss: 0.0761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:58:57,942] Trial 82 finished with value: 0.9701789264413518 and parameters: {'max_learning_rate': 0.008371098494573922, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 5.282023956047794e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9702\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0036641223825818665, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=8.568563130131614e-05, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 1.50e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6582, LR: 3.92e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5364, LR: 9.59e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2667, LR: 1.73e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2682, LR: 2.54e-03\n",
      "Epoch 1/5 — Train Loss: 0.4732\n",
      "Epoch 1 — Val Loss: 0.1754, Val F1: 0.9423 (Acc: 0.9409, P: 0.9198, R: 0.9659, F1: 0.9423, ROC: 0.9856, PR: 0.9806)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1094, LR: 2.95e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1412, LR: 3.48e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0972, LR: 3.66e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1068, LR: 3.63e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1416, LR: 3.52e-03\n",
      "Epoch 2/5 — Train Loss: 0.1254\n",
      "Epoch 2 — Val Loss: 0.1070, Val F1: 0.9646 (Acc: 0.9650, P: 0.9735, R: 0.9559, F1: 0.9646, ROC: 0.9937, PR: 0.9917)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0530, LR: 3.44e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0373, LR: 3.23e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0166, LR: 2.97e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0334, LR: 2.67e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1013, LR: 2.34e-03\n",
      "Epoch 3/5 — Train Loss: 0.0472\n",
      "Epoch 3 — Val Loss: 0.0930, Val F1: 0.9684 (Acc: 0.9685, P: 0.9689, R: 0.9679, F1: 0.9684, ROC: 0.9951, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0194, LR: 2.14e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0175, LR: 1.78e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0146, LR: 1.42e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0053, LR: 1.08e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0008, LR: 7.72e-04\n",
      "Epoch 4/5 — Train Loss: 0.0218\n",
      "Epoch 4 — Val Loss: 0.0919, Val F1: 0.9694 (Acc: 0.9695, P: 0.9718, R: 0.9669, F1: 0.9694, ROC: 0.9954, PR: 0.9956)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0022, LR: 6.11e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0035, LR: 3.68e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0594, LR: 1.81e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0075, LR: 5.81e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0067, LR: 2.90e-06\n",
      "Epoch 5/5 — Train Loss: 0.0142\n",
      "Epoch 5 — Val Loss: 0.0927, Val F1: 0.9709 (Acc: 0.9710, P: 0.9728, R: 0.9689, F1: 0.9709, ROC: 0.9954, PR: 0.9956)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0919\n",
      "\n",
      "Training finished. Total time: 31.69s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9695\n",
      "  - Precision: 0.9718\n",
      "  - Recall: 0.9669\n",
      "  - F1: 0.9694\n",
      "  - Roc_auc: 0.9954\n",
      "  - Pr_auc: 0.9956\n",
      "  - Val_loss: 0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 14:59:41,690] Trial 83 finished with value: 0.9693621295831241 and parameters: {'max_learning_rate': 0.0036641223825818665, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 8.568563130131614e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9694\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0049924552122237766, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=7.976990608893044e-05, embedding_dim=64, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6983, LR: 2.05e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6301, LR: 5.34e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4442, LR: 1.31e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3101, LR: 2.36e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1303, LR: 3.46e-03\n",
      "Epoch 1/5 — Train Loss: 0.4137\n",
      "Epoch 1 — Val Loss: 0.1704, Val F1: 0.9442 (Acc: 0.9454, P: 0.9645, R: 0.9248, F1: 0.9442, ROC: 0.9869, PR: 0.9817)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0981, LR: 4.02e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.2196, LR: 4.73e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2717, LR: 4.99e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1809, LR: 4.94e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1009, LR: 4.80e-03\n",
      "Epoch 2/5 — Train Loss: 0.1121\n",
      "Epoch 2 — Val Loss: 0.0855, Val F1: 0.9687 (Acc: 0.9690, P: 0.9756, R: 0.9619, F1: 0.9687, ROC: 0.9955, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0360, LR: 4.68e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0257, LR: 4.40e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0086, LR: 4.05e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0103, LR: 3.64e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0161, LR: 3.19e-03\n",
      "Epoch 3/5 — Train Loss: 0.0321\n",
      "Epoch 3 — Val Loss: 0.1072, Val F1: 0.9703 (Acc: 0.9705, P: 0.9747, R: 0.9659, F1: 0.9703, ROC: 0.9946, PR: 0.9952)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0054, LR: 2.91e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0047, LR: 2.43e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0010, LR: 1.94e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0261, LR: 1.48e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0102, LR: 1.05e-03\n",
      "Epoch 4/5 — Train Loss: 0.0176\n",
      "Epoch 4 — Val Loss: 0.0726, Val F1: 0.9729 (Acc: 0.9730, P: 0.9748, R: 0.9709, F1: 0.9729, ROC: 0.9971, PR: 0.9973)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0080, LR: 8.33e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0097, LR: 5.02e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0036, LR: 2.47e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0113, LR: 7.91e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0027, LR: 3.95e-06\n",
      "Epoch 5/5 — Train Loss: 0.0092\n",
      "Epoch 5 — Val Loss: 0.0732, Val F1: 0.9714 (Acc: 0.9715, P: 0.9719, R: 0.9709, F1: 0.9714, ROC: 0.9971, PR: 0.9973)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0726\n",
      "\n",
      "Training finished. Total time: 31.86s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9730\n",
      "  - Precision: 0.9748\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9729\n",
      "  - Roc_auc: 0.9971\n",
      "  - Pr_auc: 0.9973\n",
      "  - Val_loss: 0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:00:25,459] Trial 84 finished with value: 0.9728915662650602 and parameters: {'max_learning_rate': 0.0049924552122237766, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 7.976990608893044e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9729\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005149598527004532, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00012174638608686812, embedding_dim=64, hidden_dims=[32], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6895, LR: 2.12e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6728, LR: 5.51e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5106, LR: 1.35e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3653, LR: 2.43e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2574, LR: 3.57e-03\n",
      "Epoch 1/5 — Train Loss: 0.4715\n",
      "Epoch 1 — Val Loss: 0.1723, Val F1: 0.9433 (Acc: 0.9419, P: 0.9208, R: 0.9669, F1: 0.9433, ROC: 0.9863, PR: 0.9794)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1581, LR: 4.14e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0747, LR: 4.88e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1904, LR: 5.15e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2296, LR: 5.10e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1532, LR: 4.95e-03\n",
      "Epoch 2/5 — Train Loss: 0.1446\n",
      "Epoch 2 — Val Loss: 0.1059, Val F1: 0.9631 (Acc: 0.9630, P: 0.9574, R: 0.9689, F1: 0.9631, ROC: 0.9942, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0954, LR: 4.83e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0395, LR: 4.54e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0581, LR: 4.18e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0698, LR: 3.76e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1192, LR: 3.29e-03\n",
      "Epoch 3/5 — Train Loss: 0.0692\n",
      "Epoch 3 — Val Loss: 0.0934, Val F1: 0.9722 (Acc: 0.9725, P: 0.9806, R: 0.9639, F1: 0.9722, ROC: 0.9948, PR: 0.9950)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0557, LR: 3.01e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0133, LR: 2.50e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0228, LR: 2.00e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0726, LR: 1.52e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0172, LR: 1.08e-03\n",
      "Epoch 4/5 — Train Loss: 0.0336\n",
      "Epoch 4 — Val Loss: 0.1167, Val F1: 0.9683 (Acc: 0.9685, P: 0.9737, R: 0.9629, F1: 0.9683, ROC: 0.9940, PR: 0.9951)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0261, LR: 8.59e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0156, LR: 5.18e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0120, LR: 2.55e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0206, LR: 8.16e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0375, LR: 4.07e-06\n",
      "Epoch 5/5 — Train Loss: 0.0241\n",
      "Epoch 5 — Val Loss: 0.1156, Val F1: 0.9698 (Acc: 0.9700, P: 0.9747, R: 0.9649, F1: 0.9698, ROC: 0.9940, PR: 0.9951)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0934\n",
      "\n",
      "Training finished. Total time: 31.90s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9725\n",
      "  - Precision: 0.9806\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9722\n",
      "  - Roc_auc: 0.9948\n",
      "  - Pr_auc: 0.9950\n",
      "  - Val_loss: 0.0934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:01:09,214] Trial 85 finished with value: 0.9722081859525012 and parameters: {'max_learning_rate': 0.005149598527004532, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.5, 'weight_decay': 0.00012174638608686812}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9722\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005169115428450399, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=8.02622298471298e-05, embedding_dim=64, hidden_dims=[32], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6895, LR: 2.12e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6726, LR: 5.53e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5098, LR: 1.35e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3652, LR: 2.44e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2615, LR: 3.58e-03\n",
      "Epoch 1/5 — Train Loss: 0.4713\n",
      "Epoch 1 — Val Loss: 0.1771, Val F1: 0.9419 (Acc: 0.9404, P: 0.9182, R: 0.9669, F1: 0.9419, ROC: 0.9858, PR: 0.9785)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1628, LR: 4.16e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0727, LR: 4.90e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1862, LR: 5.17e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2297, LR: 5.12e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1520, LR: 4.97e-03\n",
      "Epoch 2/5 — Train Loss: 0.1441\n",
      "Epoch 2 — Val Loss: 0.1086, Val F1: 0.9623 (Acc: 0.9620, P: 0.9528, R: 0.9719, F1: 0.9623, ROC: 0.9945, PR: 0.9942)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0986, LR: 4.85e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0401, LR: 4.56e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0558, LR: 4.20e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0650, LR: 3.77e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1101, LR: 3.30e-03\n",
      "Epoch 3/5 — Train Loss: 0.0680\n",
      "Epoch 3 — Val Loss: 0.0961, Val F1: 0.9706 (Acc: 0.9710, P: 0.9806, R: 0.9609, F1: 0.9706, ROC: 0.9947, PR: 0.9948)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0568, LR: 3.02e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0126, LR: 2.51e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0209, LR: 2.01e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0699, LR: 1.53e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0165, LR: 1.09e-03\n",
      "Epoch 4/5 — Train Loss: 0.0326\n",
      "Epoch 4 — Val Loss: 0.1181, Val F1: 0.9708 (Acc: 0.9710, P: 0.9757, R: 0.9659, F1: 0.9708, ROC: 0.9935, PR: 0.9943)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0252, LR: 8.62e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0137, LR: 5.19e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0138, LR: 2.56e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0204, LR: 8.19e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0486, LR: 4.09e-06\n",
      "Epoch 5/5 — Train Loss: 0.0233\n",
      "Epoch 5 — Val Loss: 0.1179, Val F1: 0.9708 (Acc: 0.9710, P: 0.9747, R: 0.9669, F1: 0.9708, ROC: 0.9936, PR: 0.9944)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0961\n",
      "\n",
      "Training finished. Total time: 32.54s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9806\n",
      "  - Recall: 0.9609\n",
      "  - F1: 0.9706\n",
      "  - Roc_auc: 0.9947\n",
      "  - Pr_auc: 0.9948\n",
      "  - Val_loss: 0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:01:54,297] Trial 86 finished with value: 0.9706477732793523 and parameters: {'max_learning_rate': 0.005169115428450399, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.5, 'weight_decay': 8.02622298471298e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9706\n",
      "Selected hidden_dims: [16] (index 0)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.004239308070358591, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00011963457479574425, embedding_dim=64, hidden_dims=[16], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7248, LR: 1.74e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6596, LR: 4.54e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5713, LR: 1.11e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3401, LR: 2.00e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.7008, LR: 2.94e-03\n",
      "Epoch 1/5 — Train Loss: 0.5369\n",
      "Epoch 1 — Val Loss: 0.2449, Val F1: 0.9399 (Acc: 0.9399, P: 0.9390, R: 0.9409, F1: 0.9399, ROC: 0.9821, PR: 0.9767)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2506, LR: 3.41e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1293, LR: 4.02e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1362, LR: 4.24e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1915, LR: 4.20e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2263, LR: 4.08e-03\n",
      "Epoch 2/5 — Train Loss: 0.1729\n",
      "Epoch 2 — Val Loss: 0.1074, Val F1: 0.9660 (Acc: 0.9665, P: 0.9794, R: 0.9529, F1: 0.9660, ROC: 0.9932, PR: 0.9913)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0644, LR: 3.97e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0906, LR: 3.74e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0745, LR: 3.44e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0811, LR: 3.09e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0408, LR: 2.71e-03\n",
      "Epoch 3/5 — Train Loss: 0.0830\n",
      "Epoch 3 — Val Loss: 0.0977, Val F1: 0.9649 (Acc: 0.9650, P: 0.9649, R: 0.9649, F1: 0.9649, ROC: 0.9947, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0892, LR: 2.47e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0370, LR: 2.06e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0607, LR: 1.65e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0233, LR: 1.25e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0344, LR: 8.93e-04\n",
      "Epoch 4/5 — Train Loss: 0.0463\n",
      "Epoch 4 — Val Loss: 0.1131, Val F1: 0.9684 (Acc: 0.9685, P: 0.9698, R: 0.9669, F1: 0.9684, ROC: 0.9943, PR: 0.9944)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0354, LR: 7.07e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0211, LR: 4.26e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0808, LR: 2.10e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0188, LR: 6.72e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0657, LR: 3.35e-06\n",
      "Epoch 5/5 — Train Loss: 0.0390\n",
      "Epoch 5 — Val Loss: 0.1240, Val F1: 0.9675 (Acc: 0.9675, P: 0.9670, R: 0.9679, F1: 0.9675, ROC: 0.9940, PR: 0.9939)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0977\n",
      "\n",
      "Training finished. Total time: 33.14s. Model size: 1034693.30 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9650\n",
      "  - Precision: 0.9649\n",
      "  - Recall: 0.9649\n",
      "  - F1: 0.9649\n",
      "  - Roc_auc: 0.9947\n",
      "  - Pr_auc: 0.9955\n",
      "  - Val_loss: 0.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:02:39,161] Trial 87 finished with value: 0.9649298597194389 and parameters: {'max_learning_rate': 0.004239308070358591, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.5, 'weight_decay': 0.00011963457479574425}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9649\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0030205050841267886, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0001700339922872021, embedding_dim=64, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6983, LR: 1.24e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6570, LR: 3.23e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5450, LR: 7.91e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3341, LR: 1.43e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1587, LR: 2.09e-03\n",
      "Epoch 1/5 — Train Loss: 0.4526\n",
      "Epoch 1 — Val Loss: 0.2181, Val F1: 0.9236 (Acc: 0.9279, P: 0.9809, R: 0.8727, F1: 0.9236, ROC: 0.9851, PR: 0.9801)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2067, LR: 2.43e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.3234, LR: 2.86e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.3612, LR: 3.02e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2225, LR: 2.99e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1103, LR: 2.91e-03\n",
      "Epoch 2/5 — Train Loss: 0.1333\n",
      "Epoch 2 — Val Loss: 0.1074, Val F1: 0.9613 (Acc: 0.9610, P: 0.9510, R: 0.9719, F1: 0.9613, ROC: 0.9935, PR: 0.9925)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0327, LR: 2.83e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0451, LR: 2.66e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0226, LR: 2.45e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0195, LR: 2.20e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0279, LR: 1.93e-03\n",
      "Epoch 3/5 — Train Loss: 0.0485\n",
      "Epoch 3 — Val Loss: 0.0938, Val F1: 0.9719 (Acc: 0.9720, P: 0.9748, R: 0.9689, F1: 0.9719, ROC: 0.9950, PR: 0.9953)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0116, LR: 1.76e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0146, LR: 1.47e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0048, LR: 1.17e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0574, LR: 8.93e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0283, LR: 6.36e-04\n",
      "Epoch 4/5 — Train Loss: 0.0242\n",
      "Epoch 4 — Val Loss: 0.0846, Val F1: 0.9703 (Acc: 0.9705, P: 0.9747, R: 0.9659, F1: 0.9703, ROC: 0.9958, PR: 0.9964)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0255, LR: 5.04e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0155, LR: 3.04e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0052, LR: 1.50e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0138, LR: 4.79e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0067, LR: 2.39e-06\n",
      "Epoch 5/5 — Train Loss: 0.0169\n",
      "Epoch 5 — Val Loss: 0.0843, Val F1: 0.9709 (Acc: 0.9710, P: 0.9738, R: 0.9679, F1: 0.9709, ROC: 0.9956, PR: 0.9962)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0843\n",
      "\n",
      "Training finished. Total time: 33.15s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9710\n",
      "  - Precision: 0.9738\n",
      "  - Recall: 0.9679\n",
      "  - F1: 0.9709\n",
      "  - Roc_auc: 0.9956\n",
      "  - Pr_auc: 0.9962\n",
      "  - Val_loss: 0.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:03:24,124] Trial 88 finished with value: 0.9708542713567839 and parameters: {'max_learning_rate': 0.0030205050841267886, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 0.0001700339922872021}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9709\n",
      "Selected hidden_dims: [16] (index 0)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0038535216342476474, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=5.9010470975694065e-05, embedding_dim=64, hidden_dims=[16], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.7248, LR: 1.58e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6624, LR: 4.12e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5859, LR: 1.01e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3711, LR: 1.82e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.7507, LR: 2.67e-03\n",
      "Epoch 1/5 — Train Loss: 0.5484\n",
      "Epoch 1 — Val Loss: 0.2517, Val F1: 0.9341 (Acc: 0.9329, P: 0.9178, R: 0.9509, F1: 0.9341, ROC: 0.9784, PR: 0.9725)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2306, LR: 3.10e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1361, LR: 3.65e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1327, LR: 3.85e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2052, LR: 3.82e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.2172, LR: 3.71e-03\n",
      "Epoch 2/5 — Train Loss: 0.1748\n",
      "Epoch 2 — Val Loss: 0.1254, Val F1: 0.9641 (Acc: 0.9645, P: 0.9744, R: 0.9539, F1: 0.9641, ROC: 0.9921, PR: 0.9894)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0659, LR: 3.61e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0939, LR: 3.40e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0921, LR: 3.13e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0824, LR: 2.81e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0486, LR: 2.46e-03\n",
      "Epoch 3/5 — Train Loss: 0.0844\n",
      "Epoch 3 — Val Loss: 0.0946, Val F1: 0.9683 (Acc: 0.9685, P: 0.9727, R: 0.9639, F1: 0.9683, ROC: 0.9946, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0890, LR: 2.25e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0505, LR: 1.87e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0556, LR: 1.50e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0307, LR: 1.14e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0365, LR: 8.12e-04\n",
      "Epoch 4/5 — Train Loss: 0.0514\n",
      "Epoch 4 — Val Loss: 0.1059, Val F1: 0.9694 (Acc: 0.9695, P: 0.9709, R: 0.9679, F1: 0.9694, ROC: 0.9949, PR: 0.9957)\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0461, LR: 6.43e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0240, LR: 3.87e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0830, LR: 1.91e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0218, LR: 6.11e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0643, LR: 3.05e-06\n",
      "Epoch 5/5 — Train Loss: 0.0429\n",
      "Epoch 5 — Val Loss: 0.1139, Val F1: 0.9694 (Acc: 0.9695, P: 0.9699, R: 0.9689, F1: 0.9694, ROC: 0.9946, PR: 0.9953)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0946\n",
      "\n",
      "Training finished. Total time: 32.96s. Model size: 1034693.30 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9685\n",
      "  - Precision: 0.9727\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9683\n",
      "  - Roc_auc: 0.9946\n",
      "  - Pr_auc: 0.9955\n",
      "  - Val_loss: 0.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:04:09,177] Trial 89 finished with value: 0.9682939104177152 and parameters: {'max_learning_rate': 0.0038535216342476474, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.5, 'weight_decay': 5.9010470975694065e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9683\n",
      "Selected hidden_dims: [128, 32] (index 10)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=32, max_learning_rate=0.001758238179434871, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=4.508309257595244e-05, embedding_dim=64, hidden_dims=[128, 32], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/63, Train Loss: 0.6807, LR: 7.08e-05\n",
      "Epoch 1, Batch 13/63, Train Loss: 0.6796, LR: 1.62e-04\n",
      "Epoch 1, Batch 26/63, Train Loss: 0.6654, LR: 3.94e-04\n",
      "Epoch 1, Batch 39/63, Train Loss: 0.5158, LR: 7.25e-04\n",
      "Epoch 1, Batch 52/63, Train Loss: 0.3200, LR: 1.09e-03\n",
      "Epoch 1/5 — Train Loss: 0.5685\n",
      "Epoch 1 — Val Loss: 0.2142, Val F1: 0.9325 (Acc: 0.9304, P: 0.9048, R: 0.9619, F1: 0.9325, ROC: 0.9765, PR: 0.9717)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/63, Train Loss: 0.4142, LR: 1.38e-03\n",
      "Epoch 2, Batch 13/63, Train Loss: 0.0242, LR: 1.63e-03\n",
      "Epoch 2, Batch 26/63, Train Loss: 0.2679, LR: 1.75e-03\n",
      "Epoch 2, Batch 39/63, Train Loss: 0.0936, LR: 1.75e-03\n",
      "Epoch 2, Batch 52/63, Train Loss: 0.0934, LR: 1.71e-03\n",
      "Epoch 2/5 — Train Loss: 0.1465\n",
      "Epoch 2 — Val Loss: 0.1192, Val F1: 0.9598 (Acc: 0.9595, P: 0.9508, R: 0.9689, F1: 0.9598, ROC: 0.9925, PR: 0.9924)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/63, Train Loss: 0.0254, LR: 1.66e-03\n",
      "Epoch 3, Batch 13/63, Train Loss: 0.0218, LR: 1.57e-03\n",
      "Epoch 3, Batch 26/63, Train Loss: 0.1453, LR: 1.46e-03\n",
      "Epoch 3, Batch 39/63, Train Loss: 0.0135, LR: 1.33e-03\n",
      "Epoch 3, Batch 52/63, Train Loss: 0.0389, LR: 1.18e-03\n",
      "Epoch 3/5 — Train Loss: 0.0646\n",
      "Epoch 3 — Val Loss: 0.1014, Val F1: 0.9658 (Acc: 0.9660, P: 0.9688, R: 0.9629, F1: 0.9658, ROC: 0.9945, PR: 0.9948)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/63, Train Loss: 0.0264, LR: 1.05e-03\n",
      "Epoch 4, Batch 13/63, Train Loss: 0.0069, LR: 8.89e-04\n",
      "Epoch 4, Batch 26/63, Train Loss: 0.1635, LR: 7.26e-04\n",
      "Epoch 4, Batch 39/63, Train Loss: 0.0085, LR: 5.70e-04\n",
      "Epoch 4, Batch 52/63, Train Loss: 0.0308, LR: 4.23e-04\n",
      "Epoch 4/5 — Train Loss: 0.0309\n",
      "Epoch 4 — Val Loss: 0.1097, Val F1: 0.9669 (Acc: 0.9670, P: 0.9688, R: 0.9649, F1: 0.9669, ROC: 0.9947, PR: 0.9952)\n",
      "Epoch 5, Batch 0/63, Train Loss: 0.0900, LR: 3.12e-04\n",
      "Epoch 5, Batch 13/63, Train Loss: 0.0465, LR: 1.98e-04\n",
      "Epoch 5, Batch 26/63, Train Loss: 0.0115, LR: 1.07e-04\n",
      "Epoch 5, Batch 39/63, Train Loss: 0.0037, LR: 4.28e-05\n",
      "Epoch 5, Batch 52/63, Train Loss: 0.0426, LR: 7.22e-06\n",
      "Epoch 5/5 — Train Loss: 0.0216\n",
      "Epoch 5 — Val Loss: 0.1121, Val F1: 0.9668 (Acc: 0.9670, P: 0.9698, R: 0.9639, F1: 0.9668, ROC: 0.9946, PR: 0.9950)\n",
      "Early stopping triggered after 5 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.1014\n",
      "\n",
      "Training finished. Total time: 44.06s. Model size: 1034907.12 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9660\n",
      "  - Precision: 0.9688\n",
      "  - Recall: 0.9629\n",
      "  - F1: 0.9658\n",
      "  - Roc_auc: 0.9945\n",
      "  - Pr_auc: 0.9948\n",
      "  - Val_loss: 0.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:05:05,108] Trial 90 finished with value: 0.9658291457286432 and parameters: {'max_learning_rate': 0.001758238179434871, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 10, 'dropout': 0.4, 'weight_decay': 4.508309257595244e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9658\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.006721419632990078, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=3.452450003802786e-05, embedding_dim=64, hidden_dims=[64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6865, LR: 2.76e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6275, LR: 7.19e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4443, LR: 1.76e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3376, LR: 3.17e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2083, LR: 4.65e-03\n",
      "Epoch 1/5 — Train Loss: 0.4370\n",
      "Epoch 1 — Val Loss: 0.1921, Val F1: 0.9299 (Acc: 0.9259, P: 0.8822, R: 0.9830, F1: 0.9299, ROC: 0.9855, PR: 0.9796)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.3243, LR: 5.41e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1174, LR: 6.37e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0506, LR: 6.72e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1487, LR: 6.66e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0596, LR: 6.47e-03\n",
      "Epoch 2/5 — Train Loss: 0.1086\n",
      "Epoch 2 — Val Loss: 0.0991, Val F1: 0.9692 (Acc: 0.9690, P: 0.9625, R: 0.9760, F1: 0.9692, ROC: 0.9955, PR: 0.9949)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0232, LR: 6.30e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0071, LR: 5.93e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0025, LR: 5.46e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0176, LR: 4.90e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0299, LR: 4.29e-03\n",
      "Epoch 3/5 — Train Loss: 0.0412\n",
      "Epoch 3 — Val Loss: 0.0992, Val F1: 0.9744 (Acc: 0.9745, P: 0.9778, R: 0.9709, F1: 0.9744, ROC: 0.9965, PR: 0.9961)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0209, LR: 3.92e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0143, LR: 3.27e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0294, LR: 2.61e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0091, LR: 1.99e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0045, LR: 1.42e-03\n",
      "Epoch 4/5 — Train Loss: 0.0145\n",
      "Epoch 4 — Val Loss: 0.1268, Val F1: 0.9740 (Acc: 0.9740, P: 0.9730, R: 0.9749, F1: 0.9740, ROC: 0.9956, PR: 0.9959)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0991\n",
      "\n",
      "Training finished. Total time: 28.44s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9690\n",
      "  - Precision: 0.9625\n",
      "  - Recall: 0.9760\n",
      "  - F1: 0.9692\n",
      "  - Roc_auc: 0.9955\n",
      "  - Pr_auc: 0.9949\n",
      "  - Val_loss: 0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:05:45,562] Trial 91 finished with value: 0.9691542288557214 and parameters: {'max_learning_rate': 0.006721419632990078, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 3.452450003802786e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9692\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.008400803752633726, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00012099894437758282, embedding_dim=64, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6983, LR: 3.45e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.5821, LR: 8.99e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3965, LR: 2.20e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2606, LR: 3.96e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1309, LR: 5.82e-03\n",
      "Epoch 1/5 — Train Loss: 0.3543\n",
      "Epoch 1 — Val Loss: 0.3820, Val F1: 0.8599 (Acc: 0.8764, P: 0.9908, R: 0.7595, F1: 0.8599, ROC: 0.9865, PR: 0.9826)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.3814, LR: 6.76e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1609, LR: 7.97e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.2439, LR: 8.40e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2616, LR: 8.32e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0828, LR: 8.08e-03\n",
      "Epoch 2/5 — Train Loss: 0.1137\n",
      "Epoch 2 — Val Loss: 0.0761, Val F1: 0.9699 (Acc: 0.9700, P: 0.9718, R: 0.9679, F1: 0.9699, ROC: 0.9963, PR: 0.9962)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0240, LR: 7.88e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0147, LR: 7.41e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0096, LR: 6.82e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0143, LR: 6.13e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0208, LR: 5.36e-03\n",
      "Epoch 3/5 — Train Loss: 0.0236\n",
      "Epoch 3 — Val Loss: 0.1300, Val F1: 0.9711 (Acc: 0.9715, P: 0.9816, R: 0.9609, F1: 0.9711, ROC: 0.9945, PR: 0.9952)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0035, LR: 4.90e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0015, LR: 4.08e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0005, LR: 3.27e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0086, LR: 2.48e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0048, LR: 1.77e-03\n",
      "Epoch 4/5 — Train Loss: 0.0129\n",
      "Epoch 4 — Val Loss: 0.0859, Val F1: 0.9709 (Acc: 0.9710, P: 0.9738, R: 0.9679, F1: 0.9709, ROC: 0.9958, PR: 0.9964)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0761\n",
      "\n",
      "Training finished. Total time: 28.50s. Model size: 1035117.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9718\n",
      "  - Recall: 0.9679\n",
      "  - F1: 0.9699\n",
      "  - Roc_auc: 0.9963\n",
      "  - Pr_auc: 0.9962\n",
      "  - Val_loss: 0.0761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:06:25,840] Trial 92 finished with value: 0.9698795180722891 and parameters: {'max_learning_rate': 0.008400803752633726, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 0.00012099894437758282}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9699\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005467859065651327, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0001396283886226041, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 2.25e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6381, LR: 5.85e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4337, LR: 1.43e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2173, LR: 2.58e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3103, LR: 3.79e-03\n",
      "Epoch 1/5 — Train Loss: 0.4234\n",
      "Epoch 1 — Val Loss: 0.1422, Val F1: 0.9474 (Acc: 0.9469, P: 0.9381, R: 0.9569, F1: 0.9474, ROC: 0.9888, PR: 0.9837)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0753, LR: 4.40e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1263, LR: 5.19e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1117, LR: 5.47e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0703, LR: 5.42e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1097, LR: 5.26e-03\n",
      "Epoch 2/5 — Train Loss: 0.1159\n",
      "Epoch 2 — Val Loss: 0.1004, Val F1: 0.9666 (Acc: 0.9670, P: 0.9755, R: 0.9579, F1: 0.9666, ROC: 0.9942, PR: 0.9934)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0489, LR: 5.13e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0267, LR: 4.82e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0092, LR: 4.44e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0270, LR: 3.99e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0987, LR: 3.49e-03\n",
      "Epoch 3/5 — Train Loss: 0.0408\n",
      "Epoch 3 — Val Loss: 0.0971, Val F1: 0.9718 (Acc: 0.9720, P: 0.9767, R: 0.9669, F1: 0.9718, ROC: 0.9954, PR: 0.9954)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0142, LR: 3.19e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0127, LR: 2.66e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0097, LR: 2.13e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0020, LR: 1.62e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0003, LR: 1.15e-03\n",
      "Epoch 4/5 — Train Loss: 0.0147\n",
      "Epoch 4 — Val Loss: 0.0938, Val F1: 0.9729 (Acc: 0.9730, P: 0.9748, R: 0.9709, F1: 0.9729, ROC: 0.9955, PR: 0.9957)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0015, LR: 9.12e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0013, LR: 5.50e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0462, LR: 2.71e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0014, LR: 8.67e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0025, LR: 4.32e-06\n",
      "Epoch 5/5 — Train Loss: 0.0084\n",
      "Epoch 5 — Val Loss: 0.0953, Val F1: 0.9745 (Acc: 0.9745, P: 0.9740, R: 0.9749, F1: 0.9745, ROC: 0.9955, PR: 0.9957)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0938\n",
      "\n",
      "Training finished. Total time: 33.07s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9730\n",
      "  - Precision: 0.9748\n",
      "  - Recall: 0.9709\n",
      "  - F1: 0.9729\n",
      "  - Roc_auc: 0.9955\n",
      "  - Pr_auc: 0.9957\n",
      "  - Val_loss: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:07:10,901] Trial 93 finished with value: 0.9728915662650602 and parameters: {'max_learning_rate': 0.005467859065651327, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 0.0001396283886226041}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9729\n",
      "Selected hidden_dims: [32] (index 1)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.00972732297110542, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00015342733643080027, embedding_dim=64, hidden_dims=[32], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6895, LR: 4.00e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6345, LR: 1.04e-03\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.3647, LR: 2.55e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2606, LR: 4.59e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.1960, LR: 6.74e-03\n",
      "Epoch 1/5 — Train Loss: 0.4123\n",
      "Epoch 1 — Val Loss: 0.1593, Val F1: 0.9555 (Acc: 0.9565, P: 0.9760, R: 0.9359, F1: 0.9555, ROC: 0.9890, PR: 0.9852)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1053, LR: 7.83e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0281, LR: 9.23e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1087, LR: 9.73e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1093, LR: 9.63e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1012, LR: 9.36e-03\n",
      "Epoch 2/5 — Train Loss: 0.1029\n",
      "Epoch 2 — Val Loss: 0.0907, Val F1: 0.9703 (Acc: 0.9705, P: 0.9747, R: 0.9659, F1: 0.9703, ROC: 0.9953, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0471, LR: 9.12e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0523, LR: 8.58e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0260, LR: 7.90e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0419, LR: 7.10e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0473, LR: 6.21e-03\n",
      "Epoch 3/5 — Train Loss: 0.0391\n",
      "Epoch 3 — Val Loss: 0.1085, Val F1: 0.9699 (Acc: 0.9700, P: 0.9709, R: 0.9689, F1: 0.9699, ROC: 0.9948, PR: 0.9950)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0209, LR: 5.68e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0053, LR: 4.73e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0038, LR: 3.78e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0509, LR: 2.88e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0043, LR: 2.05e-03\n",
      "Epoch 4/5 — Train Loss: 0.0159\n",
      "Epoch 4 — Val Loss: 0.1176, Val F1: 0.9719 (Acc: 0.9720, P: 0.9729, R: 0.9709, F1: 0.9719, ROC: 0.9953, PR: 0.9957)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.0907\n",
      "\n",
      "Training finished. Total time: 28.44s. Model size: 1034721.55 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9705\n",
      "  - Precision: 0.9747\n",
      "  - Recall: 0.9659\n",
      "  - F1: 0.9703\n",
      "  - Roc_auc: 0.9953\n",
      "  - Pr_auc: 0.9955\n",
      "  - Val_loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:07:51,721] Trial 94 finished with value: 0.9703069954705587 and parameters: {'max_learning_rate': 0.00972732297110542, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.5, 'weight_decay': 0.00015342733643080027}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9703\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.005663552268980759, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.0002258971929384003, embedding_dim=64, hidden_dims=[128], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6918, LR: 2.33e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6359, LR: 6.06e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.4217, LR: 1.48e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.2089, LR: 2.67e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3199, LR: 3.92e-03\n",
      "Epoch 1/5 — Train Loss: 0.4197\n",
      "Epoch 1 — Val Loss: 0.1428, Val F1: 0.9478 (Acc: 0.9474, P: 0.9399, R: 0.9559, F1: 0.9478, ROC: 0.9888, PR: 0.9836)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.0755, LR: 4.56e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1312, LR: 5.37e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1174, LR: 5.66e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0743, LR: 5.61e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1042, LR: 5.45e-03\n",
      "Epoch 2/5 — Train Loss: 0.1174\n",
      "Epoch 2 — Val Loss: 0.1039, Val F1: 0.9676 (Acc: 0.9680, P: 0.9785, R: 0.9569, F1: 0.9676, ROC: 0.9934, PR: 0.9931)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0470, LR: 5.31e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0230, LR: 5.00e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0101, LR: 4.60e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0239, LR: 4.13e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0872, LR: 3.62e-03\n",
      "Epoch 3/5 — Train Loss: 0.0414\n",
      "Epoch 3 — Val Loss: 0.1046, Val F1: 0.9734 (Acc: 0.9735, P: 0.9749, R: 0.9719, F1: 0.9734, ROC: 0.9947, PR: 0.9951)\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0071, LR: 3.31e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0145, LR: 2.75e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0095, LR: 2.20e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0014, LR: 1.68e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0002, LR: 1.19e-03\n",
      "Epoch 4/5 — Train Loss: 0.0140\n",
      "Epoch 4 — Val Loss: 0.1068, Val F1: 0.9735 (Acc: 0.9735, P: 0.9720, R: 0.9749, F1: 0.9735, ROC: 0.9953, PR: 0.9953)\n",
      "Early stopping triggered after 4 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 2 with Val Loss: 0.1039\n",
      "\n",
      "Training finished. Total time: 28.58s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 2:\n",
      "  - Accuracy: 0.9680\n",
      "  - Precision: 0.9785\n",
      "  - Recall: 0.9569\n",
      "  - F1: 0.9676\n",
      "  - Roc_auc: 0.9934\n",
      "  - Pr_auc: 0.9931\n",
      "  - Val_loss: 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:08:32,245] Trial 95 finished with value: 0.9675785207700102 and parameters: {'max_learning_rate': 0.005663552268980759, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 0.0002258971929384003}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9676\n",
      "Selected hidden_dims: [256] (index 4)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0048056907860473405, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00010212491689205413, embedding_dim=128, hidden_dims=[256], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6980, LR: 1.97e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.5720, LR: 5.14e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.2474, LR: 1.26e-03\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.1832, LR: 2.27e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2287, LR: 3.33e-03\n",
      "Epoch 1/5 — Train Loss: 0.3760\n",
      "Epoch 1 — Val Loss: 0.1142, Val F1: 0.9615 (Acc: 0.9610, P: 0.9466, R: 0.9770, F1: 0.9615, ROC: 0.9923, PR: 0.9884)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1226, LR: 3.87e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.0783, LR: 4.56e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1484, LR: 4.81e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.0973, LR: 4.76e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.0585, LR: 4.62e-03\n",
      "Epoch 2/5 — Train Loss: 0.0753\n",
      "Epoch 2 — Val Loss: 0.1197, Val F1: 0.9727 (Acc: 0.9725, P: 0.9654, R: 0.9800, F1: 0.9727, ROC: 0.9945, PR: 0.9936)\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0460, LR: 4.51e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0267, LR: 4.24e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0356, LR: 3.90e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.1179, LR: 3.51e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0041, LR: 3.07e-03\n",
      "Epoch 3/5 — Train Loss: 0.0259\n",
      "Epoch 3 — Val Loss: 0.1332, Val F1: 0.9556 (Acc: 0.9570, P: 0.9861, R: 0.9269, F1: 0.9556, ROC: 0.9952, PR: 0.9952)\n",
      "Early stopping triggered after 3 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 1 with Val Loss: 0.1142\n",
      "\n",
      "Training finished. Total time: 60.49s. Model size: 2070431.49 KB\n",
      "Best model (by val_loss) obtained at epoch 1:\n",
      "  - Accuracy: 0.9610\n",
      "  - Precision: 0.9466\n",
      "  - Recall: 0.9770\n",
      "  - F1: 0.9615\n",
      "  - Roc_auc: 0.9923\n",
      "  - Pr_auc: 0.9884\n",
      "  - Val_loss: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:09:47,502] Trial 96 finished with value: 0.9615384615384616 and parameters: {'max_learning_rate': 0.0048056907860473405, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 0.00010212491689205413}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9615\n",
      "Selected hidden_dims: [128] (index 3)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.002662825394026344, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=0.00014267692261990333, embedding_dim=64, hidden_dims=[128], dropout=0.4, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6957, LR: 1.09e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6721, LR: 2.85e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5766, LR: 6.97e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3501, LR: 1.26e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.3242, LR: 1.84e-03\n",
      "Epoch 1/5 — Train Loss: 0.5019\n",
      "Epoch 1 — Val Loss: 0.1964, Val F1: 0.9412 (Acc: 0.9404, P: 0.9279, R: 0.9549, F1: 0.9412, ROC: 0.9839, PR: 0.9784)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.1770, LR: 2.14e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1641, LR: 2.53e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.1288, LR: 2.66e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1301, LR: 2.64e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1406, LR: 2.56e-03\n",
      "Epoch 2/5 — Train Loss: 0.1331\n",
      "Epoch 2 — Val Loss: 0.1186, Val F1: 0.9657 (Acc: 0.9660, P: 0.9735, R: 0.9579, F1: 0.9657, ROC: 0.9927, PR: 0.9902)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0600, LR: 2.50e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0452, LR: 2.35e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0243, LR: 2.16e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0513, LR: 1.94e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.1159, LR: 1.70e-03\n",
      "Epoch 3/5 — Train Loss: 0.0566\n",
      "Epoch 3 — Val Loss: 0.0969, Val F1: 0.9688 (Acc: 0.9690, P: 0.9737, R: 0.9639, F1: 0.9688, ROC: 0.9945, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0269, LR: 1.55e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0280, LR: 1.29e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0194, LR: 1.04e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0073, LR: 7.88e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0014, LR: 5.61e-04\n",
      "Epoch 4/5 — Train Loss: 0.0285\n",
      "Epoch 4 — Val Loss: 0.0962, Val F1: 0.9698 (Acc: 0.9700, P: 0.9757, R: 0.9639, F1: 0.9698, ROC: 0.9949, PR: 0.9949)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0042, LR: 4.44e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0048, LR: 2.68e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0734, LR: 1.32e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0127, LR: 4.22e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0085, LR: 2.11e-06\n",
      "Epoch 5/5 — Train Loss: 0.0194\n",
      "Epoch 5 — Val Loss: 0.0973, Val F1: 0.9709 (Acc: 0.9710, P: 0.9738, R: 0.9679, F1: 0.9709, ROC: 0.9949, PR: 0.9950)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0962\n",
      "\n",
      "Training finished. Total time: 33.29s. Model size: 1034891.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9700\n",
      "  - Precision: 0.9757\n",
      "  - Recall: 0.9639\n",
      "  - F1: 0.9698\n",
      "  - Roc_auc: 0.9949\n",
      "  - Pr_auc: 0.9949\n",
      "  - Val_loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:10:33,160] Trial 97 finished with value: 0.969758064516129 and parameters: {'max_learning_rate': 0.002662825394026344, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.4, 'weight_decay': 0.00014267692261990333}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9698\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.0033999359061936403, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=8.272428599497174e-05, embedding_dim=64, hidden_dims=[64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6865, LR: 1.40e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6595, LR: 3.64e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5842, LR: 8.90e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3567, LR: 1.60e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2379, LR: 2.35e-03\n",
      "Epoch 1/5 — Train Loss: 0.5034\n",
      "Epoch 1 — Val Loss: 0.2072, Val F1: 0.9346 (Acc: 0.9329, P: 0.9106, R: 0.9599, F1: 0.9346, ROC: 0.9789, PR: 0.9730)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2543, LR: 2.74e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1685, LR: 3.22e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0631, LR: 3.40e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.1980, LR: 3.37e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1469, LR: 3.27e-03\n",
      "Epoch 2/5 — Train Loss: 0.1405\n",
      "Epoch 2 — Val Loss: 0.1068, Val F1: 0.9609 (Acc: 0.9605, P: 0.9483, R: 0.9739, F1: 0.9609, ROC: 0.9932, PR: 0.9897)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0646, LR: 3.19e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0235, LR: 3.00e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0127, LR: 2.76e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0537, LR: 2.48e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0375, LR: 2.17e-03\n",
      "Epoch 3/5 — Train Loss: 0.0671\n",
      "Epoch 3 — Val Loss: 0.0965, Val F1: 0.9706 (Acc: 0.9710, P: 0.9835, R: 0.9579, F1: 0.9706, ROC: 0.9948, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0272, LR: 1.98e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0328, LR: 1.65e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0333, LR: 1.32e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0119, LR: 1.01e-03\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0102, LR: 7.16e-04\n",
      "Epoch 4/5 — Train Loss: 0.0330\n",
      "Epoch 4 — Val Loss: 0.0885, Val F1: 0.9724 (Acc: 0.9725, P: 0.9748, R: 0.9699, F1: 0.9724, ROC: 0.9953, PR: 0.9951)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0255, LR: 5.67e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0080, LR: 3.42e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0189, LR: 1.68e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0552, LR: 5.39e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0325, LR: 2.69e-06\n",
      "Epoch 5/5 — Train Loss: 0.0244\n",
      "Epoch 5 — Val Loss: 0.0897, Val F1: 0.9707 (Acc: 0.9710, P: 0.9786, R: 0.9629, F1: 0.9707, ROC: 0.9952, PR: 0.9948)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0885\n",
      "\n",
      "Training finished. Total time: 33.11s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9725\n",
      "  - Precision: 0.9748\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9724\n",
      "  - Roc_auc: 0.9953\n",
      "  - Pr_auc: 0.9951\n",
      "  - Val_loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:11:18,487] Trial 98 finished with value: 0.9723756906077348 and parameters: {'max_learning_rate': 0.0033999359061936403, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 8.272428599497174e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9724\n",
      "Selected hidden_dims: [64] (index 2)\n",
      "\n",
      "--- Optuna Trial ---\n",
      "Suggested Hyperparams: NNHyperparams(batch_size=64, max_learning_rate=0.003279620690106178, epochs=5, early_stopping=True, patience=2, optimizer='adamw', weight_decay=8.308178047031056e-05, embedding_dim=64, hidden_dims=[64], dropout=0.5, seq_pooling='mean', n_classes=2, label_col='is_malware', dataloader_num_workers=2, dataloader_pin_memory=True, dataloader_persistent_workers=True, grad_scaler_max_norm=1.0)\n",
      "Using device: cuda\n",
      "Using f1 as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.5\n",
      "Training set size: 1997, Validation set size: 1998\n",
      "Training set class distribution: {0: 1000, 1: 997}\n",
      "Validation set class distribution: {0: 1000, 1: 998}\n",
      "Using class weights: [0.9985     1.00150451]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/32, Train Loss: 0.6865, LR: 1.35e-04\n",
      "Epoch 1, Batch 7/32, Train Loss: 0.6606, LR: 3.51e-04\n",
      "Epoch 1, Batch 14/32, Train Loss: 0.5888, LR: 8.58e-04\n",
      "Epoch 1, Batch 21/32, Train Loss: 0.3669, LR: 1.55e-03\n",
      "Epoch 1, Batch 28/32, Train Loss: 0.2459, LR: 2.27e-03\n",
      "Epoch 1/5 — Train Loss: 0.5065\n",
      "Epoch 1 — Val Loss: 0.2125, Val F1: 0.9320 (Acc: 0.9299, P: 0.9047, R: 0.9609, F1: 0.9320, ROC: 0.9765, PR: 0.9703)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/32, Train Loss: 0.2599, LR: 2.64e-03\n",
      "Epoch 2, Batch 7/32, Train Loss: 0.1713, LR: 3.11e-03\n",
      "Epoch 2, Batch 14/32, Train Loss: 0.0620, LR: 3.28e-03\n",
      "Epoch 2, Batch 21/32, Train Loss: 0.2035, LR: 3.25e-03\n",
      "Epoch 2, Batch 28/32, Train Loss: 0.1626, LR: 3.15e-03\n",
      "Epoch 2/5 — Train Loss: 0.1421\n",
      "Epoch 2 — Val Loss: 0.1152, Val F1: 0.9576 (Acc: 0.9570, P: 0.9419, R: 0.9739, F1: 0.9576, ROC: 0.9927, PR: 0.9895)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/32, Train Loss: 0.0703, LR: 3.08e-03\n",
      "Epoch 3, Batch 7/32, Train Loss: 0.0284, LR: 2.89e-03\n",
      "Epoch 3, Batch 14/32, Train Loss: 0.0140, LR: 2.66e-03\n",
      "Epoch 3, Batch 21/32, Train Loss: 0.0590, LR: 2.39e-03\n",
      "Epoch 3, Batch 28/32, Train Loss: 0.0389, LR: 2.09e-03\n",
      "Epoch 3/5 — Train Loss: 0.0687\n",
      "Epoch 3 — Val Loss: 0.0922, Val F1: 0.9706 (Acc: 0.9710, P: 0.9835, R: 0.9579, F1: 0.9706, ROC: 0.9951, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/32, Train Loss: 0.0269, LR: 1.91e-03\n",
      "Epoch 4, Batch 7/32, Train Loss: 0.0348, LR: 1.59e-03\n",
      "Epoch 4, Batch 14/32, Train Loss: 0.0306, LR: 1.27e-03\n",
      "Epoch 4, Batch 21/32, Train Loss: 0.0120, LR: 9.70e-04\n",
      "Epoch 4, Batch 28/32, Train Loss: 0.0108, LR: 6.91e-04\n",
      "Epoch 4/5 — Train Loss: 0.0348\n",
      "Epoch 4 — Val Loss: 0.0894, Val F1: 0.9724 (Acc: 0.9725, P: 0.9748, R: 0.9699, F1: 0.9724, ROC: 0.9953, PR: 0.9952)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/32, Train Loss: 0.0261, LR: 5.47e-04\n",
      "Epoch 5, Batch 7/32, Train Loss: 0.0084, LR: 3.30e-04\n",
      "Epoch 5, Batch 14/32, Train Loss: 0.0193, LR: 1.62e-04\n",
      "Epoch 5, Batch 21/32, Train Loss: 0.0594, LR: 5.20e-05\n",
      "Epoch 5, Batch 28/32, Train Loss: 0.0341, LR: 2.59e-06\n",
      "Epoch 5/5 — Train Loss: 0.0254\n",
      "Epoch 5 — Val Loss: 0.0901, Val F1: 0.9728 (Acc: 0.9730, P: 0.9797, R: 0.9659, F1: 0.9728, ROC: 0.9952, PR: 0.9949)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0894\n",
      "\n",
      "Training finished. Total time: 33.12s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9725\n",
      "  - Precision: 0.9748\n",
      "  - Recall: 0.9699\n",
      "  - F1: 0.9724\n",
      "  - Roc_auc: 0.9953\n",
      "  - Pr_auc: 0.9952\n",
      "  - Val_loss: 0.0894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-22 15:12:04,295] Trial 99 finished with value: 0.9723756906077348 and parameters: {'max_learning_rate': 0.003279620690106178, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 8.308178047031056e-05}. Best is trial 80 with value: 0.9734335839598998.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial finished. Validation Recall: 0.9724\n",
      "\n",
      "--- Optuna Study Complete ---\n",
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value (F1 Score): 0.9734\n",
      "  Params: \n",
      "    max_learning_rate: 0.006311264200084833\n",
      "    batch_size: 64\n",
      "    embedding_dim: 64\n",
      "    hidden_dims_idx: 3\n",
      "    dropout: 0.5\n",
      "    weight_decay: 8.413267202596088e-05\n",
      "\n",
      "All trials and their hyperparameters:\n",
      "Trial 0: Value = 0.9674465920651069, Params = {'max_learning_rate': 0.0023856730313390243, 'batch_size': 16, 'embedding_dim': 128, 'hidden_dims_idx': 10, 'dropout': 0.4, 'weight_decay': 1.6634066787303807e-05}\n",
      "Trial 1: Value = 0.8289085545722714, Params = {'max_learning_rate': 3.0173055455242765e-05, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 14, 'dropout': 0.30000000000000004, 'weight_decay': 0.0003004062167267393}\n",
      "Trial 2: Value = 0.9685785536159601, Params = {'max_learning_rate': 0.00047686427118995696, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 14, 'dropout': 0.1, 'weight_decay': 0.0007098155083968054}\n",
      "Trial 3: Value = 0.9277166108185735, Params = {'max_learning_rate': 8.640717728312954e-05, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 2, 'dropout': 0.4, 'weight_decay': 4.8868621856571994e-05}\n",
      "Trial 4: Value = 0.962037962037962, Params = {'max_learning_rate': 0.0005493676823427794, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 14, 'dropout': 0.2, 'weight_decay': 3.054951462634546e-05}\n",
      "Trial 5: Value = 0.8018528049408131, Params = {'max_learning_rate': 3.72307572305381e-05, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.2, 'weight_decay': 9.980271361663464e-06}\n",
      "Trial 6: Value = 0.965, Params = {'max_learning_rate': 0.00024161654753634412, 'batch_size': 32, 'embedding_dim': 256, 'hidden_dims_idx': 2, 'dropout': 0.4, 'weight_decay': 2.361905972968227e-06}\n",
      "Trial 7: Value = 0.968968968968969, Params = {'max_learning_rate': 0.00463248659727382, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 0.0002460523448470818}\n",
      "Trial 8: Value = 0.7702407002188184, Params = {'max_learning_rate': 3.597758807424261e-05, 'batch_size': 16, 'embedding_dim': 128, 'hidden_dims_idx': 14, 'dropout': 0.2, 'weight_decay': 1.5254536321490948e-05}\n",
      "Trial 9: Value = 0.9194536033914272, Params = {'max_learning_rate': 0.00019903972619363417, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 13, 'dropout': 0.2, 'weight_decay': 1.2916797988710483e-06}\n",
      "Trial 10: Value = 0.9687814702920443, Params = {'max_learning_rate': 0.009474260570458054, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 0.00014281990984921708}\n",
      "Trial 11: Value = 0.9612870789341378, Params = {'max_learning_rate': 0.009614878948685204, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 7, 'dropout': 0.5, 'weight_decay': 0.00015674563930015588}\n",
      "Trial 12: Value = 0.9695740365111561, Params = {'max_learning_rate': 0.008975360627093466, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 0.00011953356837977742}\n",
      "Trial 13: Value = 0.966144517433047, Params = {'max_learning_rate': 0.002218128701578755, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 0.0007959473978236647}\n",
      "Trial 14: Value = 0.968937875751503, Params = {'max_learning_rate': 0.0025714977363574146, 'batch_size': 32, 'embedding_dim': 128, 'hidden_dims_idx': 9, 'dropout': 0.5, 'weight_decay': 9.412029297691989e-05}\n",
      "Trial 15: Value = 0.9714285714285714, Params = {'max_learning_rate': 0.004140090545887836, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 0.00030671695223794833}\n",
      "Trial 16: Value = 0.9683257918552036, Params = {'max_learning_rate': 0.0010462263883440192, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.4, 'weight_decay': 0.0004167913462931006}\n",
      "Trial 17: Value = 0.6664440734557596, Params = {'max_learning_rate': 1.2927548094328915e-05, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 9, 'dropout': 0.30000000000000004, 'weight_decay': 9.428790194913002e-05}\n",
      "Trial 18: Value = 0.9678068410462777, Params = {'max_learning_rate': 0.004749449410493503, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 4.878047869259928e-05}\n",
      "Trial 19: Value = 0.9684526790185278, Params = {'max_learning_rate': 0.001166643397544032, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 5.847394899470475e-06}\n",
      "Trial 20: Value = 0.96996996996997, Params = {'max_learning_rate': 0.004855607694347289, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.4, 'weight_decay': 0.00037698615185622356}\n",
      "Trial 21: Value = 0.9695121951219512, Params = {'max_learning_rate': 0.0052173042925733664, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.4, 'weight_decay': 0.00028864678014902686}\n",
      "Trial 22: Value = 0.9606377678126558, Params = {'max_learning_rate': 0.0013746221777638922, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.4, 'weight_decay': 0.0005069913565025937}\n",
      "Trial 23: Value = 0.9728370221327968, Params = {'max_learning_rate': 0.005856428094809981, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 0.00016062404609637696}\n",
      "Trial 24: Value = 0.9707661290322581, Params = {'max_learning_rate': 0.0038913719133630937, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.30000000000000004, 'weight_decay': 0.00019478758771012758}\n",
      "Trial 25: Value = 0.9698189134808853, Params = {'max_learning_rate': 0.0028066157056636713, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.30000000000000004, 'weight_decay': 0.0002029163347206826}\n",
      "Trial 26: Value = 0.9717457114026236, Params = {'max_learning_rate': 0.0016145541448908181, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.30000000000000004, 'weight_decay': 0.000978234595442972}\n",
      "Trial 27: Value = 0.9663823381836427, Params = {'max_learning_rate': 0.000717485636560264, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.1, 'weight_decay': 0.000965204756403488}\n",
      "Trial 28: Value = 0.9681657402728651, Params = {'max_learning_rate': 0.00163149087413567, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 5.622740174265438e-05}\n",
      "Trial 29: Value = 0.9712266532054518, Params = {'max_learning_rate': 0.001863101980913933, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 8, 'dropout': 0.4, 'weight_decay': 0.0005585386420247639}\n",
      "Trial 30: Value = 0.9667003027245207, Params = {'max_learning_rate': 0.0008743174015609711, 'batch_size': 16, 'embedding_dim': 64, 'hidden_dims_idx': 11, 'dropout': 0.30000000000000004, 'weight_decay': 0.0009120220055117417}\n",
      "Trial 31: Value = 0.9693004529441369, Params = {'max_learning_rate': 0.0018514500975375955, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 8, 'dropout': 0.4, 'weight_decay': 0.0005340591213530987}\n",
      "Trial 32: Value = 0.9705284552845529, Params = {'max_learning_rate': 0.003485002473217171, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 11, 'dropout': 0.4, 'weight_decay': 0.000531261972037709}\n",
      "Trial 33: Value = 0.9597644749754661, Params = {'max_learning_rate': 0.005867103470513595, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 5, 'dropout': 0.30000000000000004, 'weight_decay': 0.0006241065370661097}\n",
      "Trial 34: Value = 0.9704556835252879, Params = {'max_learning_rate': 0.0005252620660706986, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 0.0003153548458680616}\n",
      "Trial 35: Value = 0.9620512820512821, Params = {'max_learning_rate': 0.0067740946004487875, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 0.0009923518634051248}\n",
      "Trial 36: Value = 0.9647532729103726, Params = {'max_learning_rate': 0.0003129349723344516, 'batch_size': 16, 'embedding_dim': 64, 'hidden_dims_idx': 8, 'dropout': 0.2, 'weight_decay': 0.0003687749224284969}\n",
      "Trial 37: Value = 0.9478303266699171, Params = {'max_learning_rate': 0.00013682155455055448, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 2, 'dropout': 0.30000000000000004, 'weight_decay': 7.288760580314762e-05}\n",
      "Trial 38: Value = 0.9711099847947289, Params = {'max_learning_rate': 0.002771202386714621, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 3.096098115678274e-05}\n",
      "Trial 39: Value = 0.9703368526897939, Params = {'max_learning_rate': 0.0017962176894353544, 'batch_size': 16, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 0.00026043267834772787}\n",
      "Trial 40: Value = 0.9698189134808853, Params = {'max_learning_rate': 0.0008264216554763365, 'batch_size': 64, 'embedding_dim': 256, 'hidden_dims_idx': 8, 'dropout': 0.5, 'weight_decay': 0.0006483336727608591}\n",
      "Trial 41: Value = 0.9706477732793523, Params = {'max_learning_rate': 0.002800823033426711, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 2.5232938155273707e-05}\n",
      "Trial 42: Value = 0.9718875502008032, Params = {'max_learning_rate': 0.003323361277491239, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 1.9175574886776315e-05}\n",
      "Trial 43: Value = 0.970912738214644, Params = {'max_learning_rate': 0.0034715859703401287, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.2, 'weight_decay': 8.822125767359051e-06}\n",
      "Trial 44: Value = 0.9717741935483871, Params = {'max_learning_rate': 0.007057379850224284, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.2, 'weight_decay': 3.681290285793012e-06}\n",
      "Trial 45: Value = 0.9708542713567839, Params = {'max_learning_rate': 0.007499416744701274, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.2, 'weight_decay': 3.179465984234056e-06}\n",
      "Trial 46: Value = 0.9704383282364933, Params = {'max_learning_rate': 0.006739027934069543, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 1.5441575789240153e-05}\n",
      "Trial 47: Value = 0.9701568032372281, Params = {'max_learning_rate': 0.003829252053986063, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.2, 'weight_decay': 1.3887739393895064e-06}\n",
      "Trial 48: Value = 0.8674223755544603, Params = {'max_learning_rate': 7.659257759498833e-05, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.1, 'weight_decay': 1.0955839445386013e-05}\n",
      "Trial 49: Value = 0.968068930562595, Params = {'max_learning_rate': 0.009653989451099665, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.2, 'weight_decay': 5.000122699844908e-06}\n",
      "Trial 50: Value = 0.9686552072800809, Params = {'max_learning_rate': 0.007549771670678614, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.1, 'weight_decay': 2.1697883347776256e-05}\n",
      "Trial 51: Value = 0.9714285714285714, Params = {'max_learning_rate': 0.0013281427489252125, 'batch_size': 16, 'embedding_dim': 256, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 2.266944820555747e-06}\n",
      "Trial 52: Value = 0.9717741935483871, Params = {'max_learning_rate': 0.002324635205605679, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 1.8681822334832825e-06}\n",
      "Trial 53: Value = 0.9673202614379085, Params = {'max_learning_rate': 0.005021819508804257, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.2, 'weight_decay': 1.0758615799743215e-06}\n",
      "Trial 54: Value = 0.9677744209466264, Params = {'max_learning_rate': 0.00237264866231627, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.30000000000000004, 'weight_decay': 1.866092646435174e-06}\n",
      "Trial 55: Value = 0.971342383107089, Params = {'max_learning_rate': 0.004350249077303315, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 3.8407113101477e-06}\n",
      "Trial 56: Value = 0.9645885286783042, Params = {'max_learning_rate': 0.003383042351743511, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.2, 'weight_decay': 0.00013189627394376267}\n",
      "Trial 57: Value = 0.9705882352941176, Params = {'max_learning_rate': 0.005674547319844819, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 0, 'dropout': 0.30000000000000004, 'weight_decay': 4.043860907800924e-05}\n",
      "Trial 58: Value = 0.9668008048289738, Params = {'max_learning_rate': 0.0020158600955377044, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.2, 'weight_decay': 5.7300513877587005e-06}\n",
      "Trial 59: Value = 0.9703069954705587, Params = {'max_learning_rate': 0.0014379201746909933, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 1.6400262607564408e-06}\n",
      "Trial 60: Value = 0.9718875502008032, Params = {'max_learning_rate': 0.0029766576498514823, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 0.00018061845437668714}\n",
      "Trial 61: Value = 0.9713135379969804, Params = {'max_learning_rate': 0.0031249881086333493, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 9.797624711192913e-05}\n",
      "Trial 62: Value = 0.9673530889000502, Params = {'max_learning_rate': 0.0024628396305713613, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.30000000000000004, 'weight_decay': 0.00020065710101465958}\n",
      "Trial 63: Value = 0.9713135379969804, Params = {'max_learning_rate': 0.0041869033102684, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.30000000000000004, 'weight_decay': 3.0223907628695964e-06}\n",
      "Trial 64: Value = 0.9653092006033183, Params = {'max_learning_rate': 0.0010720989362068222, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.4, 'weight_decay': 0.00017046401180989928}\n",
      "Trial 65: Value = 0.7901639344262295, Params = {'max_learning_rate': 1.1632998764279112e-05, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.30000000000000004, 'weight_decay': 6.769225483674067e-05}\n",
      "Trial 66: Value = 0.965925925925926, Params = {'max_learning_rate': 0.005845987426525882, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.4, 'weight_decay': 7.73613136733225e-06}\n",
      "Trial 67: Value = 0.9593830334190231, Params = {'max_learning_rate': 0.007869747342425501, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 9, 'dropout': 0.30000000000000004, 'weight_decay': 0.00010779531381111566}\n",
      "Trial 68: Value = 0.9656887120835406, Params = {'max_learning_rate': 0.004690617671725093, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 7, 'dropout': 0.2, 'weight_decay': 0.00040944037963854555}\n",
      "Trial 69: Value = 0.9530864197530864, Params = {'max_learning_rate': 0.0004345252238696999, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.1, 'weight_decay': 0.0002579497262152991}\n",
      "Trial 70: Value = 0.9728370221327968, Params = {'max_learning_rate': 0.002381087409215055, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.4, 'weight_decay': 4.1252075198582384e-05}\n",
      "Trial 71: Value = 0.9733802109492717, Params = {'max_learning_rate': 0.0021826284394301206, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 4.3224939159096505e-05}\n",
      "Trial 72: Value = 0.9718875502008032, Params = {'max_learning_rate': 0.002224671363017776, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 3.958859596707406e-05}\n",
      "Trial 73: Value = 0.9569520039584364, Params = {'max_learning_rate': 0.0021359966394775567, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 6, 'dropout': 0.5, 'weight_decay': 2.3536115793976603e-05}\n",
      "Trial 74: Value = 0.9702770780856423, Params = {'max_learning_rate': 0.0030351319771814867, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 4.979288879054223e-05}\n",
      "Trial 75: Value = 0.9712556732223904, Params = {'max_learning_rate': 0.0023623514241845928, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 3.939736612736251e-05}\n",
      "Trial 76: Value = 0.967741935483871, Params = {'max_learning_rate': 0.0015003779118791976, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 13, 'dropout': 0.5, 'weight_decay': 1.1934910208205549e-05}\n",
      "Trial 77: Value = 0.8863636363636364, Params = {'max_learning_rate': 2.2199402095439714e-05, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 6.704692944992521e-05}\n",
      "Trial 78: Value = 0.970912738214644, Params = {'max_learning_rate': 0.0012111910174994387, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 3.592750383629086e-05}\n",
      "Trial 79: Value = 0.9633350075339026, Params = {'max_learning_rate': 0.0008367180243799377, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 5, 'dropout': 0.5, 'weight_decay': 1.8562334653201786e-05}\n",
      "Trial 80: Value = 0.9734335839598998, Params = {'max_learning_rate': 0.006311264200084833, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 8.413267202596088e-05}\n",
      "Trial 81: Value = 0.9712266532054518, Params = {'max_learning_rate': 0.0062338028367451195, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 2.8138484113782066e-05}\n",
      "Trial 82: Value = 0.9701789264413518, Params = {'max_learning_rate': 0.008371098494573922, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 5.282023956047794e-05}\n",
      "Trial 83: Value = 0.9693621295831241, Params = {'max_learning_rate': 0.0036641223825818665, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 8.568563130131614e-05}\n",
      "Trial 84: Value = 0.9728915662650602, Params = {'max_learning_rate': 0.0049924552122237766, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 7.976990608893044e-05}\n",
      "Trial 85: Value = 0.9722081859525012, Params = {'max_learning_rate': 0.005149598527004532, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.5, 'weight_decay': 0.00012174638608686812}\n",
      "Trial 86: Value = 0.9706477732793523, Params = {'max_learning_rate': 0.005169115428450399, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.5, 'weight_decay': 8.02622298471298e-05}\n",
      "Trial 87: Value = 0.9649298597194389, Params = {'max_learning_rate': 0.004239308070358591, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.5, 'weight_decay': 0.00011963457479574425}\n",
      "Trial 88: Value = 0.9708542713567839, Params = {'max_learning_rate': 0.0030205050841267886, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 0.0001700339922872021}\n",
      "Trial 89: Value = 0.9682939104177152, Params = {'max_learning_rate': 0.0038535216342476474, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 0, 'dropout': 0.5, 'weight_decay': 5.9010470975694065e-05}\n",
      "Trial 90: Value = 0.9658291457286432, Params = {'max_learning_rate': 0.001758238179434871, 'batch_size': 32, 'embedding_dim': 64, 'hidden_dims_idx': 10, 'dropout': 0.4, 'weight_decay': 4.508309257595244e-05}\n",
      "Trial 91: Value = 0.9691542288557214, Params = {'max_learning_rate': 0.006721419632990078, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 3.452450003802786e-05}\n",
      "Trial 92: Value = 0.9698795180722891, Params = {'max_learning_rate': 0.008400803752633726, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 0.00012099894437758282}\n",
      "Trial 93: Value = 0.9728915662650602, Params = {'max_learning_rate': 0.005467859065651327, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 0.0001396283886226041}\n",
      "Trial 94: Value = 0.9703069954705587, Params = {'max_learning_rate': 0.00972732297110542, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 1, 'dropout': 0.5, 'weight_decay': 0.00015342733643080027}\n",
      "Trial 95: Value = 0.9675785207700102, Params = {'max_learning_rate': 0.005663552268980759, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.5, 'weight_decay': 0.0002258971929384003}\n",
      "Trial 96: Value = 0.9615384615384616, Params = {'max_learning_rate': 0.0048056907860473405, 'batch_size': 64, 'embedding_dim': 128, 'hidden_dims_idx': 4, 'dropout': 0.5, 'weight_decay': 0.00010212491689205413}\n",
      "Trial 97: Value = 0.969758064516129, Params = {'max_learning_rate': 0.002662825394026344, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 3, 'dropout': 0.4, 'weight_decay': 0.00014267692261990333}\n",
      "Trial 98: Value = 0.9723756906077348, Params = {'max_learning_rate': 0.0033999359061936403, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 8.272428599497174e-05}\n",
      "Trial 99: Value = 0.9723756906077348, Params = {'max_learning_rate': 0.003279620690106178, 'batch_size': 64, 'embedding_dim': 64, 'hidden_dims_idx': 2, 'dropout': 0.5, 'weight_decay': 8.308178047031056e-05}\n",
      "\n",
      "Trials df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_dropout</th>\n",
       "      <th>params_embedding_dim</th>\n",
       "      <th>params_hidden_dims_idx</th>\n",
       "      <th>params_max_learning_rate</th>\n",
       "      <th>params_weight_decay</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.967447</td>\n",
       "      <td>2025-06-22 10:21:52.275166</td>\n",
       "      <td>2025-06-22 10:23:35.920028</td>\n",
       "      <td>0 days 00:01:43.644862</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>2025-06-22 10:23:35.920028</td>\n",
       "      <td>2025-06-22 10:24:30.653731</td>\n",
       "      <td>0 days 00:00:54.733703</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.968579</td>\n",
       "      <td>2025-06-22 10:24:30.653731</td>\n",
       "      <td>2025-06-22 10:40:31.917986</td>\n",
       "      <td>0 days 00:16:01.264255</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>256</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.927717</td>\n",
       "      <td>2025-06-22 10:40:31.918986</td>\n",
       "      <td>2025-06-22 10:41:50.316013</td>\n",
       "      <td>0 days 00:01:18.397027</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.962038</td>\n",
       "      <td>2025-06-22 10:41:50.317013</td>\n",
       "      <td>2025-06-22 10:48:57.538700</td>\n",
       "      <td>0 days 00:07:07.221687</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>256</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.967579</td>\n",
       "      <td>2025-06-22 15:07:51.722563</td>\n",
       "      <td>2025-06-22 15:08:32.244461</td>\n",
       "      <td>0 days 00:00:40.521898</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>2025-06-22 15:08:32.245964</td>\n",
       "      <td>2025-06-22 15:09:47.502461</td>\n",
       "      <td>0 days 00:01:15.256497</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.969758</td>\n",
       "      <td>2025-06-22 15:09:47.503461</td>\n",
       "      <td>2025-06-22 15:10:33.159978</td>\n",
       "      <td>0 days 00:00:45.656517</td>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.972376</td>\n",
       "      <td>2025-06-22 15:10:33.160982</td>\n",
       "      <td>2025-06-22 15:11:18.486789</td>\n",
       "      <td>0 days 00:00:45.325807</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.972376</td>\n",
       "      <td>2025-06-22 15:11:18.487789</td>\n",
       "      <td>2025-06-22 15:12:04.295043</td>\n",
       "      <td>0 days 00:00:45.807254</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.967447 2025-06-22 10:21:52.275166 2025-06-22 10:23:35.920028   \n",
       "1        1  0.828909 2025-06-22 10:23:35.920028 2025-06-22 10:24:30.653731   \n",
       "2        2  0.968579 2025-06-22 10:24:30.653731 2025-06-22 10:40:31.917986   \n",
       "3        3  0.927717 2025-06-22 10:40:31.918986 2025-06-22 10:41:50.316013   \n",
       "4        4  0.962038 2025-06-22 10:41:50.317013 2025-06-22 10:48:57.538700   \n",
       "..     ...       ...                        ...                        ...   \n",
       "95      95  0.967579 2025-06-22 15:07:51.722563 2025-06-22 15:08:32.244461   \n",
       "96      96  0.961538 2025-06-22 15:08:32.245964 2025-06-22 15:09:47.502461   \n",
       "97      97  0.969758 2025-06-22 15:09:47.503461 2025-06-22 15:10:33.159978   \n",
       "98      98  0.972376 2025-06-22 15:10:33.160982 2025-06-22 15:11:18.486789   \n",
       "99      99  0.972376 2025-06-22 15:11:18.487789 2025-06-22 15:12:04.295043   \n",
       "\n",
       "                 duration  params_batch_size  params_dropout  \\\n",
       "0  0 days 00:01:43.644862                 16             0.4   \n",
       "1  0 days 00:00:54.733703                 32             0.3   \n",
       "2  0 days 00:16:01.264255                 16             0.1   \n",
       "3  0 days 00:01:18.397027                 32             0.4   \n",
       "4  0 days 00:07:07.221687                 64             0.2   \n",
       "..                    ...                ...             ...   \n",
       "95 0 days 00:00:40.521898                 64             0.5   \n",
       "96 0 days 00:01:15.256497                 64             0.5   \n",
       "97 0 days 00:00:45.656517                 64             0.4   \n",
       "98 0 days 00:00:45.325807                 64             0.5   \n",
       "99 0 days 00:00:45.807254                 64             0.5   \n",
       "\n",
       "    params_embedding_dim  params_hidden_dims_idx  params_max_learning_rate  \\\n",
       "0                    128                      10                  0.002386   \n",
       "1                     64                      14                  0.000030   \n",
       "2                    256                      14                  0.000477   \n",
       "3                    128                       2                  0.000086   \n",
       "4                    256                      14                  0.000549   \n",
       "..                   ...                     ...                       ...   \n",
       "95                    64                       3                  0.005664   \n",
       "96                   128                       4                  0.004806   \n",
       "97                    64                       3                  0.002663   \n",
       "98                    64                       2                  0.003400   \n",
       "99                    64                       2                  0.003280   \n",
       "\n",
       "    params_weight_decay     state  \n",
       "0              0.000017  COMPLETE  \n",
       "1              0.000300  COMPLETE  \n",
       "2              0.000710  COMPLETE  \n",
       "3              0.000049  COMPLETE  \n",
       "4              0.000031  COMPLETE  \n",
       "..                  ...       ...  \n",
       "95             0.000226  COMPLETE  \n",
       "96             0.000102  COMPLETE  \n",
       "97             0.000143  COMPLETE  \n",
       "98             0.000083  COMPLETE  \n",
       "99             0.000083  COMPLETE  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best NNHyperparams based on Optuna search:\n",
      "NNHyperparams(batch_size=64,\n",
      "              max_learning_rate=0.006311264200084833,\n",
      "              epochs=20,\n",
      "              early_stopping=True,\n",
      "              patience=5,\n",
      "              optimizer='adamw',\n",
      "              weight_decay=8.413267202596088e-05,\n",
      "              embedding_dim=64,\n",
      "              hidden_dims=(128,),\n",
      "              dropout=0.5,\n",
      "              seq_pooling='mean',\n",
      "              n_classes=2,\n",
      "              label_col='is_malware',\n",
      "              dataloader_num_workers=0,\n",
      "              dataloader_pin_memory=True,\n",
      "              dataloader_persistent_workers=False,\n",
      "              grad_scaler_max_norm=1.0)\n"
     ]
    }
   ],
   "source": [
    "# Create a study object. Define the direction of optimization.\n",
    "# For metrics like F1, Recall, Precision, Accuracy, ROC AUC, PR AUC, you want to \"maximize\".\n",
    "# If you were optimizing loss, you would use \"minimize\".\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"debrim_nn_hyperopt\")\n",
    "\n",
    "# Start the optimization. n_trials is the number of different hyperparameter sets to try.\n",
    "# Start with a small number (e.g., 10-20) to test, then increase for a more thorough search.\n",
    "n_trials = 100\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"\\n--- Optuna Study Complete ---\")\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"  Value (F1 Score): {best_trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# You can now use best_trial.params to configure your NNHyperparams\n",
    "# for a final training run or for cross-validation.\n",
    "best_hyperparams_dict = best_trial.params\n",
    "\n",
    "hidden_dims_one_layer = [(16,), (32,), (64,), (128,), (256,)]\n",
    "hidden_dims_two_layers = [\n",
    "    (256, 128),\n",
    "    (256, 64),\n",
    "    (256, 32),\n",
    "    (256, 16),\n",
    "    (128, 64),\n",
    "    (128, 32),\n",
    "    (128, 16),\n",
    "    (64, 32),\n",
    "    (64, 16),\n",
    "    (32, 16),\n",
    "]\n",
    "hiddem_dims_possible = hidden_dims_one_layer + hidden_dims_two_layers\n",
    "\n",
    "# Extract all of the trials and their hyperparameters and show them\n",
    "print(\"\\nAll trials and their hyperparameters:\")\n",
    "all_trials = study.trials\n",
    "for trial in all_trials:\n",
    "    print(f\"Trial {trial.number}: Value = {trial.value}, Params = {trial.params}\")\n",
    "\n",
    "print(\"\\nTrials df:\")\n",
    "all_trails_df = study.trials_dataframe()\n",
    "all_trails_df.to_csv(\"dataset/optuna_trials_debrim_nn.csv\", index=False)\n",
    "display(all_trails_df)\n",
    "\n",
    "final_nn_hyperparams = NNHyperparams(\n",
    "    batch_size=best_hyperparams_dict[\"batch_size\"],\n",
    "    max_learning_rate=best_hyperparams_dict[\"max_learning_rate\"],\n",
    "    epochs=20,\n",
    "    early_stopping=True,\n",
    "    patience=5,\n",
    "    optimizer=\"adamw\",\n",
    "    weight_decay=best_hyperparams_dict[\"weight_decay\"],\n",
    "    embedding_dim=best_hyperparams_dict[\"embedding_dim\"],\n",
    "    hidden_dims=hiddem_dims_possible[best_hyperparams_dict[\"hidden_dims_idx\"]],\n",
    "    dropout=best_hyperparams_dict[\"dropout\"],\n",
    "    seq_pooling=\"mean\",\n",
    "    label_col=\"is_malware\",\n",
    "    n_classes=2,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_persistent_workers=False,\n",
    "    grad_scaler_max_norm=1.0,\n",
    ")\n",
    "\n",
    "print(\"\\nBest NNHyperparams based on Optuna search:\")\n",
    "pp.pprint(final_nn_hyperparams)\n",
    "\n",
    "# Now you can use final_nn_hyperparams to train your model, perhaps with cross_val_train_nn_model\n",
    "# nn_results, best_nn_model = cross_val_train_nn_model(\n",
    "#     df=df, # Use your full preprocessed DataFrame\n",
    "#     vocab_dict=vocab_dict,\n",
    "#     sequence_cols=SEQUENCE_COLS,\n",
    "#     scalar_cols=SCALAR_COLS,\n",
    "#     char_cols=CHAR_COLS,\n",
    "#     vector_cols=VECTOR_COLS,\n",
    "#     vector_dims=VECTOR_DIMS,\n",
    "#     hyperparams=final_nn_hyperparams, # Use the tuned hyperparameters\n",
    "#     n_folds=5, # Example: 5 folds for final evaluation\n",
    "#     n_repetitions=1,\n",
    "#     scoring_metric=\"f1\", # Or your preferred final metric\n",
    "#     device=device,\n",
    "#     random_seed=42,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa2a06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_dropout</th>\n",
       "      <th>params_embedding_dim</th>\n",
       "      <th>params_hidden_dims_idx</th>\n",
       "      <th>params_max_learning_rate</th>\n",
       "      <th>params_weight_decay</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>0.973434</td>\n",
       "      <td>2025-06-22 14:56:51.007751</td>\n",
       "      <td>2025-06-22 14:57:34.772150</td>\n",
       "      <td>0 days 00:00:43.764399</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>0.973380</td>\n",
       "      <td>2025-06-22 14:49:34.676567</td>\n",
       "      <td>2025-06-22 14:50:18.841917</td>\n",
       "      <td>0 days 00:00:44.165350</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>0.972892</td>\n",
       "      <td>2025-06-22 14:59:41.690610</td>\n",
       "      <td>2025-06-22 15:00:25.458343</td>\n",
       "      <td>0 days 00:00:43.767733</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>0.972892</td>\n",
       "      <td>2025-06-22 15:06:25.841823</td>\n",
       "      <td>2025-06-22 15:07:10.901604</td>\n",
       "      <td>0 days 00:00:45.059781</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.972837</td>\n",
       "      <td>2025-06-22 11:23:19.814748</td>\n",
       "      <td>2025-06-22 11:24:05.650193</td>\n",
       "      <td>0 days 00:00:45.835445</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.828909</td>\n",
       "      <td>2025-06-22 10:23:35.920028</td>\n",
       "      <td>2025-06-22 10:24:30.653731</td>\n",
       "      <td>0 days 00:00:54.733703</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.801853</td>\n",
       "      <td>2025-06-22 10:48:57.538700</td>\n",
       "      <td>2025-06-22 10:49:52.828404</td>\n",
       "      <td>0 days 00:00:55.289704</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0.790164</td>\n",
       "      <td>2025-06-22 14:44:44.527855</td>\n",
       "      <td>2025-06-22 14:45:37.711430</td>\n",
       "      <td>0 days 00:00:53.183575</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>2025-06-22 11:06:11.765708</td>\n",
       "      <td>2025-06-22 11:08:17.447119</td>\n",
       "      <td>0 days 00:02:05.681411</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.666444</td>\n",
       "      <td>2025-06-22 11:18:49.624445</td>\n",
       "      <td>2025-06-22 11:19:35.703182</td>\n",
       "      <td>0 days 00:00:46.078737</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "80      80  0.973434 2025-06-22 14:56:51.007751 2025-06-22 14:57:34.772150   \n",
       "71      71  0.973380 2025-06-22 14:49:34.676567 2025-06-22 14:50:18.841917   \n",
       "84      84  0.972892 2025-06-22 14:59:41.690610 2025-06-22 15:00:25.458343   \n",
       "93      93  0.972892 2025-06-22 15:06:25.841823 2025-06-22 15:07:10.901604   \n",
       "23      23  0.972837 2025-06-22 11:23:19.814748 2025-06-22 11:24:05.650193   \n",
       "..     ...       ...                        ...                        ...   \n",
       "1        1  0.828909 2025-06-22 10:23:35.920028 2025-06-22 10:24:30.653731   \n",
       "5        5  0.801853 2025-06-22 10:48:57.538700 2025-06-22 10:49:52.828404   \n",
       "65      65  0.790164 2025-06-22 14:44:44.527855 2025-06-22 14:45:37.711430   \n",
       "8        8  0.770241 2025-06-22 11:06:11.765708 2025-06-22 11:08:17.447119   \n",
       "17      17  0.666444 2025-06-22 11:18:49.624445 2025-06-22 11:19:35.703182   \n",
       "\n",
       "                 duration  params_batch_size  params_dropout  \\\n",
       "80 0 days 00:00:43.764399                 64             0.5   \n",
       "71 0 days 00:00:44.165350                 64             0.5   \n",
       "84 0 days 00:00:43.767733                 64             0.5   \n",
       "93 0 days 00:00:45.059781                 64             0.5   \n",
       "23 0 days 00:00:45.835445                 64             0.5   \n",
       "..                    ...                ...             ...   \n",
       "1  0 days 00:00:54.733703                 32             0.3   \n",
       "5  0 days 00:00:55.289704                 32             0.2   \n",
       "65 0 days 00:00:53.183575                 32             0.3   \n",
       "8  0 days 00:02:05.681411                 16             0.2   \n",
       "17 0 days 00:00:46.078737                 64             0.3   \n",
       "\n",
       "    params_embedding_dim  params_hidden_dims_idx  params_max_learning_rate  \\\n",
       "80                    64                       3                  0.006311   \n",
       "71                    64                       4                  0.002183   \n",
       "84                    64                       4                  0.004992   \n",
       "93                    64                       3                  0.005468   \n",
       "23                    64                       3                  0.005856   \n",
       "..                   ...                     ...                       ...   \n",
       "1                     64                      14                  0.000030   \n",
       "5                     64                       0                  0.000037   \n",
       "65                    64                       4                  0.000012   \n",
       "8                    128                      14                  0.000036   \n",
       "17                    64                       9                  0.000013   \n",
       "\n",
       "    params_weight_decay     state  \n",
       "80             0.000084  COMPLETE  \n",
       "71             0.000043  COMPLETE  \n",
       "84             0.000080  COMPLETE  \n",
       "93             0.000140  COMPLETE  \n",
       "23             0.000161  COMPLETE  \n",
       "..                  ...       ...  \n",
       "1              0.000300  COMPLETE  \n",
       "5              0.000010  COMPLETE  \n",
       "65             0.000068  COMPLETE  \n",
       "8              0.000015  COMPLETE  \n",
       "17             0.000094  COMPLETE  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trails_df.sort_values(\n",
    "    by=[\"value\", \"number\"], ascending=[False, True], inplace=True\n",
    ")\n",
    "\n",
    "all_trails_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
