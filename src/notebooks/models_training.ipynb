{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efac910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\", \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afc8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pathlib import Path\n",
    "from src.utils.preprocessing_utils import load_dataset\n",
    "\n",
    "from src.prototypes.torch_apk_analysis_model import (\n",
    "    get_best_available_device,\n",
    "    cross_val_train_nn_model,\n",
    "    train_nn_model,\n",
    "    extract_embeddings,\n",
    "    evaluate_model_on_test_set,\n",
    "    NNHyperparams,\n",
    ")\n",
    "\n",
    "from src.prototypes.torch_apk_analysis_model_io import (\n",
    "    save_model_with_metadata,\n",
    "    load_apk_analysis_model_from_version,\n",
    "    load_apk_feature_embedder_from_version,\n",
    "    load_apk_analysis_model_metadata,\n",
    ")\n",
    "\n",
    "from src.prototypes.ml_model import MLHyperparams, train_classical_models_cv\n",
    "from src.prototypes.ml_model_io import save_ml_models_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425a7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading last preprocessed dataset...\n",
      "Using CUDA device: NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_COLS = [\n",
    "    \"activities_list\",\n",
    "    \"services_list\",\n",
    "    \"receivers_list\",\n",
    "    \"permissions_list\",\n",
    "    \"api_calls_list\",\n",
    "]\n",
    "\n",
    "CHAR_COLS = [\"fuzzy_hash\"]\n",
    "VECTOR_COLS = [\"opcode_counts\"]\n",
    "SCALAR_COLS = [\"file_size\"]\n",
    "VECTOR_DIMS = {\"opcode_counts\": 768}\n",
    "\n",
    "PROJECT_ROOT = Path().cwd().parent.parent\n",
    "PATH_TO_DATASET_DIR = PROJECT_ROOT / \"dataset\"\n",
    "PATH_TO_SAVE_NN_MODEL = PROJECT_ROOT / \"model_artifacts\" / \"nn_models\"\n",
    "PATH_TO_SAVE_ML_MODEL = PROJECT_ROOT / \"model_artifacts\" / \"ml_models\"\n",
    "\n",
    "# Load dataset\n",
    "df, vocab_dict = load_dataset(\n",
    "    PATH_TO_DATASET_DIR,\n",
    "    SEQUENCE_COLS,\n",
    "    CHAR_COLS,\n",
    "    VECTOR_COLS,\n",
    "    SCALAR_COLS,\n",
    "    VECTOR_DIMS,\n",
    "    load_fresh=False,\n",
    "    sample_size=None,\n",
    ")\n",
    "\n",
    "df, df_test = train_test_split(\n",
    "    df, test_size=0.1, random_state=42, stratify=df[\"is_malware\"]\n",
    ")\n",
    "\n",
    "device = get_best_available_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84426bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17974 entries, 2247 to 5263\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   file_size         17974 non-null  int64 \n",
      " 1   fuzzy_hash        17974 non-null  object\n",
      " 2   activities_list   17974 non-null  object\n",
      " 3   services_list     17974 non-null  object\n",
      " 4   receivers_list    17974 non-null  object\n",
      " 5   permissions_list  17974 non-null  object\n",
      " 6   api_calls_list    17974 non-null  object\n",
      " 7   opcode_counts     17974 non-null  object\n",
      " 8   is_malware        17974 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_size</th>\n",
       "      <th>fuzzy_hash</th>\n",
       "      <th>activities_list</th>\n",
       "      <th>services_list</th>\n",
       "      <th>receivers_list</th>\n",
       "      <th>permissions_list</th>\n",
       "      <th>api_calls_list</th>\n",
       "      <th>opcode_counts</th>\n",
       "      <th>is_malware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>6909752</td>\n",
       "      <td>[37, 65, 42, 15, 29, 33, 35, 38, 11, 28, 62, 4...</td>\n",
       "      <td>[19048, 19079, 19053, 19081, 19052, 508, 45, 1...</td>\n",
       "      <td>[20, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[2204, 2200, 18, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[69, 27, 6, 25, 3, 19, 22, 61, 14, 9, 24, 1001...</td>\n",
       "      <td>[78, 122, 2465, 119, 106, 7158, 1202, 705, 383...</td>\n",
       "      <td>[0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>9660703</td>\n",
       "      <td>[22, 8, 25, 21, 23, 25, 17, 56, 20, 45, 3, 10,...</td>\n",
       "      <td>[139512, 3799, 34, 139502, 139528, 18, 139522,...</td>\n",
       "      <td>[23, 12423, 12421, 12422, 30, 20, 6, 26, 0, 0,...</td>\n",
       "      <td>[9139, 5, 18, 3, 67, 17, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[15, 39, 11, 26, 78, 4, 2755, 5, 64, 6, 3, 9, ...</td>\n",
       "      <td>[105950, 63567, 187729, 3877, 3934, 3891, 7551...</td>\n",
       "      <td>[628.0, 7051.0, 4476.0, 0.0, 289.0, 550.0, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8381</th>\n",
       "      <td>7014287</td>\n",
       "      <td>[37, 14, 16, 40, 19, 33, 46, 52, 5, 61, 3, 51,...</td>\n",
       "      <td>[73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 8...</td>\n",
       "      <td>[129, 120, 104, 115, 108, 60, 102, 61, 96, 62,...</td>\n",
       "      <td>[62, 45, 55, 58, 54, 63, 57, 56, 53, 61, 49, 5...</td>\n",
       "      <td>[163, 43, 143, 70, 159, 84, 86, 118, 117, 4, 1...</td>\n",
       "      <td>[32224, 32071, 18370, 27218, 23182, 24664, 263...</td>\n",
       "      <td>[933.0, 10440.0, 690.0, 0.0, 304.0, 204.0, 0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>5863124</td>\n",
       "      <td>[66, 29, 4, 42, 34, 45, 20, 38, 29, 66, 14, 15...</td>\n",
       "      <td>[37, 9, 308, 224756, 315, 224757, 12, 52, 7, 2...</td>\n",
       "      <td>[139, 32, 151, 146, 35, 55, 29, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[29, 156, 39, 31, 100, 26, 40, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[42, 22, 11, 19, 14, 6, 100, 15, 10, 46, 13, 2...</td>\n",
       "      <td>[78, 122, 2465, 119, 106, 7158, 1202, 705, 383...</td>\n",
       "      <td>[0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18394</th>\n",
       "      <td>8197050</td>\n",
       "      <td>[60, 62, 12, 30, 37, 58, 13, 38, 48, 30, 3, 55...</td>\n",
       "      <td>[6, 10, 4, 586, 44, 3, 42, 41, 6293, 43, 555, ...</td>\n",
       "      <td>[9, 12, 8, 6, 13, 5, 10, 11, 3, 4, 0, 0, 0, 0,...</td>\n",
       "      <td>[94, 11, 5, 10, 13, 7, 8, 4, 12, 43, 22, 6, 21...</td>\n",
       "      <td>[33, 57, 71, 55, 23, 72, 20, 56, 5, 3, 58, 44,...</td>\n",
       "      <td>[2972, 4510, 6430, 5098, 1606, 1889, 3252, 216...</td>\n",
       "      <td>[330.0, 2802.0, 4177.0, 0.0, 1029.0, 788.0, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_size                                         fuzzy_hash  \\\n",
       "2247     6909752  [37, 65, 42, 15, 29, 33, 35, 38, 11, 28, 62, 4...   \n",
       "5698     9660703  [22, 8, 25, 21, 23, 25, 17, 56, 20, 45, 3, 10,...   \n",
       "8381     7014287  [37, 14, 16, 40, 19, 33, 46, 52, 5, 61, 3, 51,...   \n",
       "1682     5863124  [66, 29, 4, 42, 34, 45, 20, 38, 29, 66, 14, 15...   \n",
       "18394    8197050  [60, 62, 12, 30, 37, 58, 13, 38, 48, 30, 3, 55...   \n",
       "\n",
       "                                         activities_list  \\\n",
       "2247   [19048, 19079, 19053, 19081, 19052, 508, 45, 1...   \n",
       "5698   [139512, 3799, 34, 139502, 139528, 18, 139522,...   \n",
       "8381   [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 8...   \n",
       "1682   [37, 9, 308, 224756, 315, 224757, 12, 52, 7, 2...   \n",
       "18394  [6, 10, 4, 586, 44, 3, 42, 41, 6293, 43, 555, ...   \n",
       "\n",
       "                                           services_list  \\\n",
       "2247   [20, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "5698   [23, 12423, 12421, 12422, 30, 20, 6, 26, 0, 0,...   \n",
       "8381   [129, 120, 104, 115, 108, 60, 102, 61, 96, 62,...   \n",
       "1682   [139, 32, 151, 146, 35, 55, 29, 0, 0, 0, 0, 0,...   \n",
       "18394  [9, 12, 8, 6, 13, 5, 10, 11, 3, 4, 0, 0, 0, 0,...   \n",
       "\n",
       "                                          receivers_list  \\\n",
       "2247   [2204, 2200, 18, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "5698   [9139, 5, 18, 3, 67, 17, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8381   [62, 45, 55, 58, 54, 63, 57, 56, 53, 61, 49, 5...   \n",
       "1682   [29, 156, 39, 31, 100, 26, 40, 0, 0, 0, 0, 0, ...   \n",
       "18394  [94, 11, 5, 10, 13, 7, 8, 4, 12, 43, 22, 6, 21...   \n",
       "\n",
       "                                        permissions_list  \\\n",
       "2247   [69, 27, 6, 25, 3, 19, 22, 61, 14, 9, 24, 1001...   \n",
       "5698   [15, 39, 11, 26, 78, 4, 2755, 5, 64, 6, 3, 9, ...   \n",
       "8381   [163, 43, 143, 70, 159, 84, 86, 118, 117, 4, 1...   \n",
       "1682   [42, 22, 11, 19, 14, 6, 100, 15, 10, 46, 13, 2...   \n",
       "18394  [33, 57, 71, 55, 23, 72, 20, 56, 5, 3, 58, 44,...   \n",
       "\n",
       "                                          api_calls_list  \\\n",
       "2247   [78, 122, 2465, 119, 106, 7158, 1202, 705, 383...   \n",
       "5698   [105950, 63567, 187729, 3877, 3934, 3891, 7551...   \n",
       "8381   [32224, 32071, 18370, 27218, 23182, 24664, 263...   \n",
       "1682   [78, 122, 2465, 119, 106, 7158, 1202, 705, 383...   \n",
       "18394  [2972, 4510, 6430, 5098, 1606, 1889, 3252, 216...   \n",
       "\n",
       "                                           opcode_counts  is_malware  \n",
       "2247   [0.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 0.0, ...           1  \n",
       "5698   [628.0, 7051.0, 4476.0, 0.0, 289.0, 550.0, 0.0...           1  \n",
       "8381   [933.0, 10440.0, 690.0, 0.0, 304.0, 204.0, 0.0...           1  \n",
       "1682   [0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...           1  \n",
       "18394  [330.0, 2802.0, 4177.0, 0.0, 1029.0, 788.0, 0....           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e1501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_hyperparams = NNHyperparams(\n",
    "    batch_size=64,\n",
    "    max_learning_rate=1e-3,\n",
    "    epochs=5,\n",
    "    early_stopping=True,\n",
    "    patience=5,\n",
    "    optimizer=\"adamw\",\n",
    "    weight_decay=1e-5,\n",
    "    embedding_dim=64,\n",
    "    hidden_dims=[64],\n",
    "    dropout=0.5,\n",
    "    seq_pooling=\"mean\",\n",
    "    n_classes=2,\n",
    "    label_col=\"is_malware\",\n",
    "    dataloader_num_workers=2,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_persistent_workers=True,\n",
    "    grad_scaler_max_norm=1.0,\n",
    ")\n",
    "\n",
    "# nn_hyperparams = NNHyperparams(\n",
    "#     batch_size=16,\n",
    "#     max_learning_rate=5e-3,\n",
    "#     epochs=20,\n",
    "#     early_stopping=True,\n",
    "#     patience=5,\n",
    "#     optimizer=\"adamw\",\n",
    "#     weight_decay=5e-4,\n",
    "#     embedding_dim=256,\n",
    "#     hidden_dims=[256, 16],\n",
    "#     dropout=0.2,\n",
    "#     seq_pooling=\"mean\",\n",
    "#     n_classes=2,\n",
    "#     label_col=\"is_malware\",\n",
    "#     dataloader_num_workers=2,\n",
    "#     dataloader_pin_memory=True,\n",
    "#     dataloader_persistent_workers=True,\n",
    "#     grad_scaler_max_norm=1.0,\n",
    "# )\n",
    "\n",
    "# nn_hyperparams = NNHyperparams(\n",
    "#     batch_size=64,\n",
    "#     max_learning_rate=6e-3,\n",
    "#     epochs=20,\n",
    "#     early_stopping=True,\n",
    "#     patience=5,\n",
    "#     optimizer=\"adamw\",\n",
    "#     weight_decay=8e-4,\n",
    "#     embedding_dim=64,\n",
    "#     hidden_dims=[128],\n",
    "#     dropout=0.5,\n",
    "#     seq_pooling=\"mean\",\n",
    "#     n_classes=2,\n",
    "#     label_col=\"is_malware\",\n",
    "#     dataloader_num_workers=2,\n",
    "#     dataloader_pin_memory=True,\n",
    "#     dataloader_persistent_workers=True,\n",
    "#     grad_scaler_max_norm=1.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499b3aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Performing internal train/validation split with ratio: 0.8\n",
      "Training set size: 14379, Validation set size: 3595\n",
      "Training set class distribution: {0: 7200, 1: 7179}\n",
      "Validation set class distribution: {0: 1800, 1: 1795}\n",
      "Using class weights: [0.99854167 1.0014626 ]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/225, Train Loss: 0.7019, LR: 4.00e-05\n",
      "Epoch 1, Batch 46/225, Train Loss: 0.6538, LR: 8.55e-05\n",
      "Epoch 1, Batch 92/225, Train Loss: 0.3682, LR: 2.10e-04\n",
      "Epoch 1, Batch 138/225, Train Loss: 0.1779, LR: 3.91e-04\n",
      "Epoch 1, Batch 184/225, Train Loss: 0.1810, LR: 5.95e-04\n",
      "Epoch 1/5 — Train Loss: 0.3745\n",
      "Epoch 1 — Val Loss: 0.0869, Val Recall: 0.9660 (Acc: 0.9694, P: 0.9725, R: 0.9660, F1: 0.9693, ROC: 0.9957, PR: 0.9958)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/225, Train Loss: 0.1040, LR: 7.66e-04\n",
      "Epoch 2, Batch 46/225, Train Loss: 0.0870, LR: 9.16e-04\n",
      "Epoch 2, Batch 92/225, Train Loss: 0.1161, LR: 9.93e-04\n",
      "Epoch 2, Batch 138/225, Train Loss: 0.0170, LR: 9.97e-04\n",
      "Epoch 2, Batch 184/225, Train Loss: 0.0963, LR: 9.79e-04\n",
      "Epoch 2/5 — Train Loss: 0.0757\n",
      "Epoch 2 — Val Loss: 0.0587, Val Recall: 0.9872 (Acc: 0.9794, P: 0.9720, R: 0.9872, F1: 0.9795, ROC: 0.9978, PR: 0.9979)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/225, Train Loss: 0.0107, LR: 9.49e-04\n",
      "Epoch 3, Batch 46/225, Train Loss: 0.0566, LR: 9.01e-04\n",
      "Epoch 3, Batch 92/225, Train Loss: 0.0079, LR: 8.40e-04\n",
      "Epoch 3, Batch 138/225, Train Loss: 0.0169, LR: 7.67e-04\n",
      "Epoch 3, Batch 184/225, Train Loss: 0.0414, LR: 6.85e-04\n",
      "Epoch 3/5 — Train Loss: 0.0440\n",
      "Epoch 3 — Val Loss: 0.0467, Val Recall: 0.9844 (Acc: 0.9839, P: 0.9833, R: 0.9844, F1: 0.9839, ROC: 0.9985, PR: 0.9985)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/225, Train Loss: 0.0027, LR: 6.07e-04\n",
      "Epoch 4, Batch 46/225, Train Loss: 0.0643, LR: 5.16e-04\n",
      "Epoch 4, Batch 92/225, Train Loss: 0.0268, LR: 4.25e-04\n",
      "Epoch 4, Batch 138/225, Train Loss: 0.0767, LR: 3.36e-04\n",
      "Epoch 4, Batch 184/225, Train Loss: 0.0126, LR: 2.53e-04\n",
      "Epoch 4/5 — Train Loss: 0.0304\n",
      "Epoch 4 — Val Loss: 0.0430, Val Recall: 0.9838 (Acc: 0.9833, P: 0.9827, R: 0.9838, F1: 0.9833, ROC: 0.9987, PR: 0.9987)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/225, Train Loss: 0.0025, LR: 1.85e-04\n",
      "Epoch 5, Batch 46/225, Train Loss: 0.0086, LR: 1.20e-04\n",
      "Epoch 5, Batch 92/225, Train Loss: 0.0279, LR: 6.67e-05\n",
      "Epoch 5, Batch 138/225, Train Loss: 0.0534, LR: 2.85e-05\n",
      "Epoch 5, Batch 184/225, Train Loss: 0.0670, LR: 6.04e-06\n",
      "Epoch 5/5 — Train Loss: 0.0244\n",
      "Epoch 5 — Val Loss: 0.0434, Val Recall: 0.9861 (Acc: 0.9841, P: 0.9822, R: 0.9861, F1: 0.9842, ROC: 0.9987, PR: 0.9987)\n",
      "Loaded best model from epoch 4 with Val Loss: 0.0430\n",
      "\n",
      "Training finished. Total time: 107.44s. Model size: 1034778.51 KB\n",
      "Best model (by val_loss) obtained at epoch 4:\n",
      "  - Accuracy: 0.9833\n",
      "  - Precision: 0.9827\n",
      "  - Recall: 0.9838\n",
      "  - F1: 0.9833\n",
      "  - Roc_auc: 0.9987\n",
      "  - Pr_auc: 0.9987\n",
      "  - Val_loss: 0.0430\n"
     ]
    }
   ],
   "source": [
    "nn_model, nn_results, fitted_scalers = train_nn_model(\n",
    "    df=df,\n",
    "    vocab_dict=vocab_dict,\n",
    "    sequence_cols=SEQUENCE_COLS,\n",
    "    scalar_cols=SCALAR_COLS,\n",
    "    char_cols=CHAR_COLS,\n",
    "    vector_cols=VECTOR_COLS,\n",
    "    vector_dims=VECTOR_DIMS,\n",
    "    hyperparams=nn_hyperparams,\n",
    "    scoring_metric=\"recall\",\n",
    "    train_split_ratio=0.8,\n",
    "    device=device,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cross-Validation Training ---\n",
      "Using device: cuda\n",
      "Primary scoring metric for best model selection: RECALL\n",
      "Number of folds: 2, Number of repetitions: 5\n",
      "\n",
      "--- Repetition 1/5, Fold 1/2 (Overall Fold 1) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.7189, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6579, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6288, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.5994, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.4822, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.5991\n",
      "Epoch 1 — Val Loss: 0.4067, Val Recall: 0.8999 (Acc: 0.8753, P: 0.8573, R: 0.8999, F1: 0.8781, ROC: 0.9423, PR: 0.9381)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.4056, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.4011, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2760, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.1471, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1475, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2475\n",
      "Epoch 2 — Val Loss: 0.1352, Val Recall: 0.9588 (Acc: 0.9604, P: 0.9618, R: 0.9588, F1: 0.9603, ROC: 0.9905, PR: 0.9846)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1067, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1064, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.2516, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.1853, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0624, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1114\n",
      "Epoch 3 — Val Loss: 0.0817, Val Recall: 0.9777 (Acc: 0.9735, P: 0.9695, R: 0.9777, F1: 0.9736, ROC: 0.9955, PR: 0.9935)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0803, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.1104, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0696, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.1341, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.1040, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0736\n",
      "Epoch 4 — Val Loss: 0.0622, Val Recall: 0.9831 (Acc: 0.9820, P: 0.9809, R: 0.9831, F1: 0.9820, ROC: 0.9973, PR: 0.9963)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0162, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0666, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0237, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0283, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.1039, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0507\n",
      "Epoch 5 — Val Loss: 0.0592, Val Recall: 0.9884 (Acc: 0.9834, P: 0.9786, R: 0.9884, F1: 0.9835, ROC: 0.9977, PR: 0.9973)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0251, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0438, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0252, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0332, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0252, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0336\n",
      "Epoch 6 — Val Loss: 0.0597, Val Recall: 0.9786 (Acc: 0.9823, P: 0.9859, R: 0.9786, F1: 0.9822, ROC: 0.9978, PR: 0.9976)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0428, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0027, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.1157, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0673, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0633, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0242\n",
      "Epoch 7 — Val Loss: 0.0581, Val Recall: 0.9764 (Acc: 0.9830, P: 0.9894, R: 0.9764, F1: 0.9828, ROC: 0.9980, PR: 0.9978)\n",
      "  New best model (by val_loss) saved at epoch 7.\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0074, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0069, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0052, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0102, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0135, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0158\n",
      "Epoch 8 — Val Loss: 0.0634, Val Recall: 0.9833 (Acc: 0.9838, P: 0.9842, R: 0.9833, F1: 0.9837, ROC: 0.9981, PR: 0.9979)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0059, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0107, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0008, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0023, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0054, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0100\n",
      "Epoch 9 — Val Loss: 0.0685, Val Recall: 0.9831 (Acc: 0.9843, P: 0.9855, R: 0.9831, F1: 0.9843, ROC: 0.9978, PR: 0.9977)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0177, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0011, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0077, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0005, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0029, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0069\n",
      "Epoch 10 — Val Loss: 0.0715, Val Recall: 0.9819 (Acc: 0.9841, P: 0.9861, R: 0.9819, F1: 0.9840, ROC: 0.9978, PR: 0.9976)\n",
      "Epoch 11, Batch 0/141, Train Loss: 0.0008, LR: 8.10e-04\n",
      "Epoch 11, Batch 29/141, Train Loss: 0.0032, LR: 7.92e-04\n",
      "Epoch 11, Batch 58/141, Train Loss: 0.0132, LR: 7.73e-04\n",
      "Epoch 11, Batch 87/141, Train Loss: 0.0018, LR: 7.53e-04\n",
      "Epoch 11, Batch 116/141, Train Loss: 0.0006, LR: 7.33e-04\n",
      "Epoch 11/20 — Train Loss: 0.0046\n",
      "Epoch 11 — Val Loss: 0.0747, Val Recall: 0.9846 (Acc: 0.9836, P: 0.9827, R: 0.9846, F1: 0.9836, ROC: 0.9979, PR: 0.9979)\n",
      "Epoch 12, Batch 0/141, Train Loss: 0.0039, LR: 7.16e-04\n",
      "Epoch 12, Batch 29/141, Train Loss: 0.0003, LR: 6.94e-04\n",
      "Epoch 12, Batch 58/141, Train Loss: 0.0019, LR: 6.73e-04\n",
      "Epoch 12, Batch 87/141, Train Loss: 0.0032, LR: 6.51e-04\n",
      "Epoch 12, Batch 116/141, Train Loss: 0.0027, LR: 6.29e-04\n",
      "Epoch 12/20 — Train Loss: 0.0033\n",
      "Epoch 12 — Val Loss: 0.0774, Val Recall: 0.9828 (Acc: 0.9836, P: 0.9844, R: 0.9828, F1: 0.9836, ROC: 0.9978, PR: 0.9977)\n",
      "Early stopping triggered after 12 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 7 with Val Loss: 0.0581\n",
      "\n",
      "Training finished. Total time: 245.18s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 7:\n",
      "  - Accuracy: 0.9830\n",
      "  - Precision: 0.9894\n",
      "  - Recall: 0.9764\n",
      "  - F1: 0.9828\n",
      "  - Roc_auc: 0.9980\n",
      "  - Pr_auc: 0.9978\n",
      "  - Val_loss: 0.0581\n",
      "Fold 1 finished. Val Recall: 0.9764 (from best model by val_loss within fold)\n",
      "  *** New overall best model found based on RECALL across folds! Score: 0.9764 ***\n",
      "\n",
      "--- Repetition 1/5, Fold 2/2 (Overall Fold 2) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.6967, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6744, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6379, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.6114, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.5196, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.6104\n",
      "Epoch 1 — Val Loss: 0.4189, Val Recall: 0.8897 (Acc: 0.8658, P: 0.8488, R: 0.8897, F1: 0.8688, ROC: 0.9412, PR: 0.9330)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.4411, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3233, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2351, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.2238, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1446, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2497\n",
      "Epoch 2 — Val Loss: 0.1344, Val Recall: 0.9623 (Acc: 0.9490, P: 0.9373, R: 0.9623, F1: 0.9496, ROC: 0.9895, PR: 0.9882)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1160, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1922, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.1867, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.1007, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0358, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1082\n",
      "Epoch 3 — Val Loss: 0.0932, Val Recall: 0.9757 (Acc: 0.9686, P: 0.9620, R: 0.9757, F1: 0.9688, ROC: 0.9937, PR: 0.9921)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0553, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.1059, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.1202, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.1786, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0575, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0648\n",
      "Epoch 4 — Val Loss: 0.0758, Val Recall: 0.9811 (Acc: 0.9749, P: 0.9690, R: 0.9811, F1: 0.9750, ROC: 0.9959, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0409, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0370, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0665, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0941, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0551, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0463\n",
      "Epoch 5 — Val Loss: 0.0716, Val Recall: 0.9848 (Acc: 0.9767, P: 0.9691, R: 0.9848, F1: 0.9769, ROC: 0.9966, PR: 0.9962)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0142, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0083, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0764, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0194, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0082, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0305\n",
      "Epoch 6 — Val Loss: 0.0644, Val Recall: 0.9811 (Acc: 0.9797, P: 0.9784, R: 0.9811, F1: 0.9797, ROC: 0.9969, PR: 0.9966)\n",
      "  New best model (by val_loss) saved at epoch 6.\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0059, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0114, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0093, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0130, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0051, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0178\n",
      "Epoch 7 — Val Loss: 0.0707, Val Recall: 0.9837 (Acc: 0.9790, P: 0.9744, R: 0.9837, F1: 0.9790, ROC: 0.9970, PR: 0.9967)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0019, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0566, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0129, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0633, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0156, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0112\n",
      "Epoch 8 — Val Loss: 0.0709, Val Recall: 0.9802 (Acc: 0.9793, P: 0.9784, R: 0.9802, F1: 0.9793, ROC: 0.9971, PR: 0.9969)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0030, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0035, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0006, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0041, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0215, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0074\n",
      "Epoch 9 — Val Loss: 0.0761, Val Recall: 0.9819 (Acc: 0.9794, P: 0.9769, R: 0.9819, F1: 0.9794, ROC: 0.9968, PR: 0.9966)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0034, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0014, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0015, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0014, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0193, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0057\n",
      "Epoch 10 — Val Loss: 0.0790, Val Recall: 0.9791 (Acc: 0.9792, P: 0.9793, R: 0.9791, F1: 0.9792, ROC: 0.9969, PR: 0.9966)\n",
      "Epoch 11, Batch 0/141, Train Loss: 0.0029, LR: 8.10e-04\n",
      "Epoch 11, Batch 29/141, Train Loss: 0.0010, LR: 7.92e-04\n",
      "Epoch 11, Batch 58/141, Train Loss: 0.0020, LR: 7.73e-04\n",
      "Epoch 11, Batch 87/141, Train Loss: 0.0022, LR: 7.53e-04\n",
      "Epoch 11, Batch 116/141, Train Loss: 0.0010, LR: 7.33e-04\n",
      "Epoch 11/20 — Train Loss: 0.0036\n",
      "Epoch 11 — Val Loss: 0.0879, Val Recall: 0.9844 (Acc: 0.9791, P: 0.9740, R: 0.9844, F1: 0.9792, ROC: 0.9965, PR: 0.9963)\n",
      "Early stopping triggered after 11 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 6 with Val Loss: 0.0644\n",
      "\n",
      "Training finished. Total time: 226.25s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 6:\n",
      "  - Accuracy: 0.9797\n",
      "  - Precision: 0.9784\n",
      "  - Recall: 0.9811\n",
      "  - F1: 0.9797\n",
      "  - Roc_auc: 0.9969\n",
      "  - Pr_auc: 0.9966\n",
      "  - Val_loss: 0.0644\n",
      "Fold 2 finished. Val Recall: 0.9811 (from best model by val_loss within fold)\n",
      "  *** New overall best model found based on RECALL across folds! Score: 0.9811 ***\n",
      "\n",
      "--- Repetition 2/5, Fold 1/2 (Overall Fold 3) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.7344, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6783, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6412, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.6159, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.5146, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.5974\n",
      "Epoch 1 — Val Loss: 0.4009, Val Recall: 0.9008 (Acc: 0.8621, P: 0.8358, R: 0.9008, F1: 0.8671, ROC: 0.9364, PR: 0.9278)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.4588, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3707, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2157, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.2083, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1324, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2421\n",
      "Epoch 2 — Val Loss: 0.1391, Val Recall: 0.9744 (Acc: 0.9522, P: 0.9328, R: 0.9744, F1: 0.9531, ROC: 0.9910, PR: 0.9890)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1105, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.0836, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.0766, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.0563, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0768, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1018\n",
      "Epoch 3 — Val Loss: 0.1073, Val Recall: 0.9744 (Acc: 0.9687, P: 0.9634, R: 0.9744, F1: 0.9689, ROC: 0.9946, PR: 0.9939)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0891, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0337, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0775, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.0058, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0437, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0659\n",
      "Epoch 4 — Val Loss: 0.1031, Val Recall: 0.9846 (Acc: 0.9745, P: 0.9651, R: 0.9846, F1: 0.9747, ROC: 0.9960, PR: 0.9954)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0779, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0585, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.1028, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.1397, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0208, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0467\n",
      "Epoch 5 — Val Loss: 0.0952, Val Recall: 0.9717 (Acc: 0.9783, P: 0.9846, R: 0.9717, F1: 0.9781, ROC: 0.9967, PR: 0.9962)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0394, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.1085, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0242, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0625, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0418, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0324\n",
      "Epoch 6 — Val Loss: 0.1010, Val Recall: 0.9808 (Acc: 0.9802, P: 0.9795, R: 0.9808, F1: 0.9802, ROC: 0.9970, PR: 0.9968)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0390, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0073, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0042, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0080, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0284, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0219\n",
      "Epoch 7 — Val Loss: 0.1110, Val Recall: 0.9784 (Acc: 0.9813, P: 0.9841, R: 0.9784, F1: 0.9812, ROC: 0.9969, PR: 0.9970)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0283, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0117, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0018, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0024, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0019, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0163\n",
      "Epoch 8 — Val Loss: 0.1027, Val Recall: 0.9768 (Acc: 0.9797, P: 0.9825, R: 0.9768, F1: 0.9797, ROC: 0.9969, PR: 0.9971)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0097, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0111, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0056, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0138, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0083, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0082\n",
      "Epoch 9 — Val Loss: 0.1095, Val Recall: 0.9784 (Acc: 0.9809, P: 0.9832, R: 0.9784, F1: 0.9808, ROC: 0.9967, PR: 0.9968)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0343, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0031, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0038, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0028, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0008, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0059\n",
      "Epoch 10 — Val Loss: 0.1232, Val Recall: 0.9808 (Acc: 0.9804, P: 0.9800, R: 0.9808, F1: 0.9804, ROC: 0.9965, PR: 0.9967)\n",
      "Early stopping triggered after 10 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0952\n",
      "\n",
      "Training finished. Total time: 205.62s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9783\n",
      "  - Precision: 0.9846\n",
      "  - Recall: 0.9717\n",
      "  - F1: 0.9781\n",
      "  - Roc_auc: 0.9967\n",
      "  - Pr_auc: 0.9962\n",
      "  - Val_loss: 0.0952\n",
      "Fold 3 finished. Val Recall: 0.9717 (from best model by val_loss within fold)\n",
      "\n",
      "--- Repetition 2/5, Fold 2/2 (Overall Fold 4) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.6980, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6759, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6495, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.5918, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.5042, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.5979\n",
      "Epoch 1 — Val Loss: 0.3908, Val Recall: 0.8750 (Acc: 0.8709, P: 0.8676, R: 0.8750, F1: 0.8713, ROC: 0.9433, PR: 0.9388)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.3858, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3223, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2354, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.2071, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1466, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2446\n",
      "Epoch 2 — Val Loss: 0.1270, Val Recall: 0.9641 (Acc: 0.9579, P: 0.9522, R: 0.9641, F1: 0.9581, ROC: 0.9904, PR: 0.9891)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1281, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1113, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.0664, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.1014, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.1690, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1053\n",
      "Epoch 3 — Val Loss: 0.0812, Val Recall: 0.9748 (Acc: 0.9724, P: 0.9701, R: 0.9748, F1: 0.9724, ROC: 0.9954, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0879, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0841, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0375, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.0728, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0550, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0727\n",
      "Epoch 4 — Val Loss: 0.0665, Val Recall: 0.9833 (Acc: 0.9791, P: 0.9750, R: 0.9833, F1: 0.9791, ROC: 0.9969, PR: 0.9970)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0076, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0781, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.1013, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0376, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0385, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0465\n",
      "Epoch 5 — Val Loss: 0.0620, Val Recall: 0.9869 (Acc: 0.9801, P: 0.9736, R: 0.9869, F1: 0.9802, ROC: 0.9974, PR: 0.9973)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0088, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0129, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0277, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0107, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0733, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0321\n",
      "Epoch 6 — Val Loss: 0.0580, Val Recall: 0.9869 (Acc: 0.9816, P: 0.9766, R: 0.9869, F1: 0.9817, ROC: 0.9979, PR: 0.9980)\n",
      "  New best model (by val_loss) saved at epoch 6.\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0096, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0269, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0271, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0592, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0054, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0195\n",
      "Epoch 7 — Val Loss: 0.0641, Val Recall: 0.9739 (Acc: 0.9806, P: 0.9871, R: 0.9739, F1: 0.9805, ROC: 0.9977, PR: 0.9979)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0059, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0039, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0030, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0019, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0063, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0128\n",
      "Epoch 8 — Val Loss: 0.0635, Val Recall: 0.9777 (Acc: 0.9815, P: 0.9852, R: 0.9777, F1: 0.9814, ROC: 0.9977, PR: 0.9978)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0038, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0080, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0017, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0038, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0033, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0071\n",
      "Epoch 9 — Val Loss: 0.0680, Val Recall: 0.9813 (Acc: 0.9819, P: 0.9824, R: 0.9813, F1: 0.9818, ROC: 0.9978, PR: 0.9979)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0058, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0018, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0011, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0594, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0033, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0045\n",
      "Epoch 10 — Val Loss: 0.0740, Val Recall: 0.9848 (Acc: 0.9821, P: 0.9794, R: 0.9848, F1: 0.9821, ROC: 0.9974, PR: 0.9974)\n",
      "Epoch 11, Batch 0/141, Train Loss: 0.0076, LR: 8.10e-04\n",
      "Epoch 11, Batch 29/141, Train Loss: 0.0056, LR: 7.92e-04\n",
      "Epoch 11, Batch 58/141, Train Loss: 0.0004, LR: 7.73e-04\n",
      "Epoch 11, Batch 87/141, Train Loss: 0.0060, LR: 7.53e-04\n",
      "Epoch 11, Batch 116/141, Train Loss: 0.0025, LR: 7.33e-04\n",
      "Epoch 11/20 — Train Loss: 0.0033\n",
      "Epoch 11 — Val Loss: 0.0798, Val Recall: 0.9826 (Acc: 0.9815, P: 0.9804, R: 0.9826, F1: 0.9815, ROC: 0.9972, PR: 0.9972)\n",
      "Early stopping triggered after 11 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 6 with Val Loss: 0.0580\n",
      "\n",
      "Training finished. Total time: 226.93s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 6:\n",
      "  - Accuracy: 0.9816\n",
      "  - Precision: 0.9766\n",
      "  - Recall: 0.9869\n",
      "  - F1: 0.9817\n",
      "  - Roc_auc: 0.9979\n",
      "  - Pr_auc: 0.9980\n",
      "  - Val_loss: 0.0580\n",
      "Fold 4 finished. Val Recall: 0.9869 (from best model by val_loss within fold)\n",
      "  *** New overall best model found based on RECALL across folds! Score: 0.9869 ***\n",
      "\n",
      "--- Repetition 3/5, Fold 1/2 (Overall Fold 5) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.7122, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6606, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6625, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.5702, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.4946, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.5844\n",
      "Epoch 1 — Val Loss: 0.3877, Val Recall: 0.8645 (Acc: 0.8521, P: 0.8433, R: 0.8645, F1: 0.8537, ROC: 0.9330, PR: 0.9266)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.4143, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3780, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2042, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.1257, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1763, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2434\n",
      "Epoch 2 — Val Loss: 0.1356, Val Recall: 0.9646 (Acc: 0.9549, P: 0.9462, R: 0.9646, F1: 0.9553, ROC: 0.9890, PR: 0.9856)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1414, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1045, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.1452, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.1143, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0914, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1128\n",
      "Epoch 3 — Val Loss: 0.1039, Val Recall: 0.9808 (Acc: 0.9636, P: 0.9481, R: 0.9808, F1: 0.9642, ROC: 0.9941, PR: 0.9925)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.2071, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0584, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0688, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.0318, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0877, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0707\n",
      "Epoch 4 — Val Loss: 0.0774, Val Recall: 0.9793 (Acc: 0.9753, P: 0.9715, R: 0.9793, F1: 0.9754, ROC: 0.9958, PR: 0.9955)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0253, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.1693, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0401, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0084, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0193, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0466\n",
      "Epoch 5 — Val Loss: 0.0676, Val Recall: 0.9782 (Acc: 0.9793, P: 0.9803, R: 0.9782, F1: 0.9793, ROC: 0.9968, PR: 0.9971)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0619, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0398, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0233, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0150, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0112, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0357\n",
      "Epoch 6 — Val Loss: 0.0742, Val Recall: 0.9860 (Acc: 0.9799, P: 0.9740, R: 0.9860, F1: 0.9800, ROC: 0.9969, PR: 0.9973)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0082, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0043, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.1007, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0119, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0129, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0208\n",
      "Epoch 7 — Val Loss: 0.0756, Val Recall: 0.9837 (Acc: 0.9815, P: 0.9794, R: 0.9837, F1: 0.9815, ROC: 0.9971, PR: 0.9974)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0419, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0047, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0141, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0080, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0089, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0150\n",
      "Epoch 8 — Val Loss: 0.0782, Val Recall: 0.9853 (Acc: 0.9812, P: 0.9772, R: 0.9853, F1: 0.9812, ROC: 0.9971, PR: 0.9974)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0277, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0091, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0041, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0037, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0020, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0095\n",
      "Epoch 9 — Val Loss: 0.0974, Val Recall: 0.9860 (Acc: 0.9796, P: 0.9736, R: 0.9860, F1: 0.9797, ROC: 0.9962, PR: 0.9966)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0301, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0233, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0136, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0048, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0006, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0065\n",
      "Epoch 10 — Val Loss: 0.0978, Val Recall: 0.9846 (Acc: 0.9807, P: 0.9770, R: 0.9846, F1: 0.9808, ROC: 0.9967, PR: 0.9971)\n",
      "Early stopping triggered after 10 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0676\n",
      "\n",
      "Training finished. Total time: 206.81s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9793\n",
      "  - Precision: 0.9803\n",
      "  - Recall: 0.9782\n",
      "  - F1: 0.9793\n",
      "  - Roc_auc: 0.9968\n",
      "  - Pr_auc: 0.9971\n",
      "  - Val_loss: 0.0676\n",
      "Fold 5 finished. Val Recall: 0.9782 (from best model by val_loss within fold)\n",
      "\n",
      "--- Repetition 3/5, Fold 2/2 (Overall Fold 6) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.6842, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6716, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6400, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.6111, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.5367, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.6011\n",
      "Epoch 1 — Val Loss: 0.4081, Val Recall: 0.8881 (Acc: 0.8743, P: 0.8639, R: 0.8881, F1: 0.8758, ROC: 0.9474, PR: 0.9465)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.4731, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.4220, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2021, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.2017, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1684, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2566\n",
      "Epoch 2 — Val Loss: 0.1338, Val Recall: 0.9474 (Acc: 0.9577, P: 0.9672, R: 0.9474, F1: 0.9572, ROC: 0.9918, PR: 0.9902)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1335, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.0912, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.0714, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.1095, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0863, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1022\n",
      "Epoch 3 — Val Loss: 0.0805, Val Recall: 0.9791 (Acc: 0.9747, P: 0.9706, R: 0.9791, F1: 0.9748, ROC: 0.9959, PR: 0.9943)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0962, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0567, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0249, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.0150, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0348, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0669\n",
      "Epoch 4 — Val Loss: 0.0843, Val Recall: 0.9621 (Acc: 0.9743, P: 0.9861, R: 0.9621, F1: 0.9739, ROC: 0.9964, PR: 0.9952)\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0644, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0207, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0637, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0215, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0650, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0502\n",
      "Epoch 5 — Val Loss: 0.0642, Val Recall: 0.9795 (Acc: 0.9806, P: 0.9817, R: 0.9795, F1: 0.9806, ROC: 0.9975, PR: 0.9972)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0172, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0134, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0022, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0242, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0836, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0317\n",
      "Epoch 6 — Val Loss: 0.0661, Val Recall: 0.9815 (Acc: 0.9795, P: 0.9776, R: 0.9815, F1: 0.9795, ROC: 0.9977, PR: 0.9976)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0361, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0318, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0018, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0036, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0049, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0197\n",
      "Epoch 7 — Val Loss: 0.0677, Val Recall: 0.9793 (Acc: 0.9803, P: 0.9812, R: 0.9793, F1: 0.9803, ROC: 0.9979, PR: 0.9978)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0483, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0111, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0175, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0390, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0375, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0133\n",
      "Epoch 8 — Val Loss: 0.0677, Val Recall: 0.9755 (Acc: 0.9815, P: 0.9874, R: 0.9755, F1: 0.9814, ROC: 0.9981, PR: 0.9981)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0499, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0007, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0106, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0024, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0084, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0085\n",
      "Epoch 9 — Val Loss: 0.0722, Val Recall: 0.9764 (Acc: 0.9815, P: 0.9865, R: 0.9764, F1: 0.9814, ROC: 0.9981, PR: 0.9980)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0120, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0066, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0023, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0013, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0006, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0049\n",
      "Epoch 10 — Val Loss: 0.0744, Val Recall: 0.9791 (Acc: 0.9824, P: 0.9856, R: 0.9791, F1: 0.9823, ROC: 0.9981, PR: 0.9981)\n",
      "Early stopping triggered after 10 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0642\n",
      "\n",
      "Training finished. Total time: 201.55s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9806\n",
      "  - Precision: 0.9817\n",
      "  - Recall: 0.9795\n",
      "  - F1: 0.9806\n",
      "  - Roc_auc: 0.9975\n",
      "  - Pr_auc: 0.9972\n",
      "  - Val_loss: 0.0642\n",
      "Fold 6 finished. Val Recall: 0.9795 (from best model by val_loss within fold)\n",
      "\n",
      "--- Repetition 4/5, Fold 1/2 (Overall Fold 7) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.6948, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6513, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6283, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.6138, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.5221, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.6080\n",
      "Epoch 1 — Val Loss: 0.4190, Val Recall: 0.8681 (Acc: 0.8772, P: 0.8838, R: 0.8681, F1: 0.8759, ROC: 0.9505, PR: 0.9467)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.5196, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3235, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.3654, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.1709, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1417, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2563\n",
      "Epoch 2 — Val Loss: 0.1233, Val Recall: 0.9699 (Acc: 0.9625, P: 0.9556, R: 0.9699, F1: 0.9627, ROC: 0.9916, PR: 0.9879)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1104, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.0736, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.1102, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.0672, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.1286, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1074\n",
      "Epoch 3 — Val Loss: 0.0962, Val Recall: 0.9779 (Acc: 0.9732, P: 0.9687, R: 0.9779, F1: 0.9733, ROC: 0.9957, PR: 0.9943)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0875, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.1168, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.1368, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.2066, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0266, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0678\n",
      "Epoch 4 — Val Loss: 0.0998, Val Recall: 0.9793 (Acc: 0.9777, P: 0.9762, R: 0.9793, F1: 0.9777, ROC: 0.9969, PR: 0.9960)\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0640, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0164, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0289, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0627, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0196, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0486\n",
      "Epoch 5 — Val Loss: 0.1254, Val Recall: 0.9708 (Acc: 0.9786, P: 0.9862, R: 0.9708, F1: 0.9784, ROC: 0.9973, PR: 0.9965)\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0221, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0297, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0168, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0052, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0258, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0351\n",
      "Epoch 6 — Val Loss: 0.1196, Val Recall: 0.9793 (Acc: 0.9821, P: 0.9848, R: 0.9793, F1: 0.9820, ROC: 0.9979, PR: 0.9977)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0086, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0145, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0292, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0050, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0066, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0235\n",
      "Epoch 7 — Val Loss: 0.1238, Val Recall: 0.9728 (Acc: 0.9804, P: 0.9878, R: 0.9728, F1: 0.9802, ROC: 0.9977, PR: 0.9977)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0019, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0266, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0405, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0030, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0050, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0178\n",
      "Epoch 8 — Val Loss: 0.1270, Val Recall: 0.9762 (Acc: 0.9822, P: 0.9880, R: 0.9762, F1: 0.9821, ROC: 0.9979, PR: 0.9979)\n",
      "Early stopping triggered after 8 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 3 with Val Loss: 0.0962\n",
      "\n",
      "Training finished. Total time: 162.09s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 3:\n",
      "  - Accuracy: 0.9732\n",
      "  - Precision: 0.9687\n",
      "  - Recall: 0.9779\n",
      "  - F1: 0.9733\n",
      "  - Roc_auc: 0.9957\n",
      "  - Pr_auc: 0.9943\n",
      "  - Val_loss: 0.0962\n",
      "Fold 7 finished. Val Recall: 0.9779 (from best model by val_loss within fold)\n",
      "\n",
      "--- Repetition 4/5, Fold 2/2 (Overall Fold 8) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.6730, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6589, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6049, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.5550, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.4649, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.5716\n",
      "Epoch 1 — Val Loss: 0.3862, Val Recall: 0.9073 (Acc: 0.8718, P: 0.8469, R: 0.9073, F1: 0.8760, ROC: 0.9377, PR: 0.9325)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.3938, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.2833, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2379, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.1938, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1145, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2370\n",
      "Epoch 2 — Val Loss: 0.1441, Val Recall: 0.9739 (Acc: 0.9475, P: 0.9249, R: 0.9739, F1: 0.9488, ROC: 0.9896, PR: 0.9861)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1190, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1962, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.0811, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.0619, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.1202, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1029\n",
      "Epoch 3 — Val Loss: 0.0937, Val Recall: 0.9677 (Acc: 0.9696, P: 0.9714, R: 0.9677, F1: 0.9695, ROC: 0.9942, PR: 0.9926)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0684, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0348, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0375, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.0182, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0745, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0646\n",
      "Epoch 4 — Val Loss: 0.0892, Val Recall: 0.9753 (Acc: 0.9728, P: 0.9705, R: 0.9753, F1: 0.9729, ROC: 0.9943, PR: 0.9937)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0509, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0317, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0426, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0512, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0148, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0458\n",
      "Epoch 5 — Val Loss: 0.0691, Val Recall: 0.9777 (Acc: 0.9795, P: 0.9812, R: 0.9777, F1: 0.9795, ROC: 0.9969, PR: 0.9973)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0234, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0225, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0445, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0355, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0369, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0315\n",
      "Epoch 6 — Val Loss: 0.0709, Val Recall: 0.9770 (Acc: 0.9799, P: 0.9825, R: 0.9770, F1: 0.9798, ROC: 0.9970, PR: 0.9974)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0082, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0031, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0225, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0088, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0091, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0197\n",
      "Epoch 7 — Val Loss: 0.0680, Val Recall: 0.9764 (Acc: 0.9799, P: 0.9832, R: 0.9764, F1: 0.9798, ROC: 0.9972, PR: 0.9975)\n",
      "  New best model (by val_loss) saved at epoch 7.\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0161, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0011, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0051, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0027, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0124, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0107\n",
      "Epoch 8 — Val Loss: 0.0758, Val Recall: 0.9757 (Acc: 0.9794, P: 0.9829, R: 0.9757, F1: 0.9793, ROC: 0.9972, PR: 0.9974)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0014, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0067, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0024, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0062, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0696, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0080\n",
      "Epoch 9 — Val Loss: 0.0779, Val Recall: 0.9831 (Acc: 0.9811, P: 0.9791, R: 0.9831, F1: 0.9811, ROC: 0.9972, PR: 0.9976)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0007, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0059, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0030, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0027, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0026, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0043\n",
      "Epoch 10 — Val Loss: 0.0864, Val Recall: 0.9806 (Acc: 0.9799, P: 0.9791, R: 0.9806, F1: 0.9798, ROC: 0.9968, PR: 0.9971)\n",
      "Epoch 11, Batch 0/141, Train Loss: 0.0008, LR: 8.10e-04\n",
      "Epoch 11, Batch 29/141, Train Loss: 0.0040, LR: 7.92e-04\n",
      "Epoch 11, Batch 58/141, Train Loss: 0.0019, LR: 7.73e-04\n",
      "Epoch 11, Batch 87/141, Train Loss: 0.0041, LR: 7.53e-04\n",
      "Epoch 11, Batch 116/141, Train Loss: 0.0008, LR: 7.33e-04\n",
      "Epoch 11/20 — Train Loss: 0.0029\n",
      "Epoch 11 — Val Loss: 0.0918, Val Recall: 0.9799 (Acc: 0.9796, P: 0.9793, R: 0.9799, F1: 0.9796, ROC: 0.9968, PR: 0.9971)\n",
      "Epoch 12, Batch 0/141, Train Loss: 0.0015, LR: 7.16e-04\n",
      "Epoch 12, Batch 29/141, Train Loss: 0.0008, LR: 6.94e-04\n",
      "Epoch 12, Batch 58/141, Train Loss: 0.0025, LR: 6.73e-04\n",
      "Epoch 12, Batch 87/141, Train Loss: 0.0013, LR: 6.51e-04\n",
      "Epoch 12, Batch 116/141, Train Loss: 0.0019, LR: 6.29e-04\n",
      "Epoch 12/20 — Train Loss: 0.0019\n",
      "Epoch 12 — Val Loss: 0.0994, Val Recall: 0.9750 (Acc: 0.9795, P: 0.9838, R: 0.9750, F1: 0.9794, ROC: 0.9968, PR: 0.9970)\n",
      "Early stopping triggered after 12 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 7 with Val Loss: 0.0680\n",
      "\n",
      "Training finished. Total time: 237.59s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 7:\n",
      "  - Accuracy: 0.9799\n",
      "  - Precision: 0.9832\n",
      "  - Recall: 0.9764\n",
      "  - F1: 0.9798\n",
      "  - Roc_auc: 0.9972\n",
      "  - Pr_auc: 0.9975\n",
      "  - Val_loss: 0.0680\n",
      "Fold 8 finished. Val Recall: 0.9764 (from best model by val_loss within fold)\n",
      "\n",
      "--- Repetition 5/5, Fold 1/2 (Overall Fold 9) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.7155, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6554, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6636, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.5950, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.5127, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.6024\n",
      "Epoch 1 — Val Loss: 0.3988, Val Recall: 0.8674 (Acc: 0.8636, P: 0.8605, R: 0.8674, F1: 0.8639, ROC: 0.9391, PR: 0.9338)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.4169, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3654, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.3351, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.1566, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1932, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2437\n",
      "Epoch 2 — Val Loss: 0.1369, Val Recall: 0.9686 (Acc: 0.9517, P: 0.9368, R: 0.9686, F1: 0.9524, ROC: 0.9888, PR: 0.9891)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.2107, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1099, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.1421, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.0493, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0442, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1033\n",
      "Epoch 3 — Val Loss: 0.0851, Val Recall: 0.9697 (Acc: 0.9700, P: 0.9701, R: 0.9697, F1: 0.9699, ROC: 0.9950, PR: 0.9944)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.1886, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0621, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.1392, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.1097, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0147, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0652\n",
      "Epoch 4 — Val Loss: 0.0736, Val Recall: 0.9788 (Acc: 0.9766, P: 0.9745, R: 0.9788, F1: 0.9767, ROC: 0.9959, PR: 0.9952)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0142, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0268, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.0329, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0102, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0763, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0449\n",
      "Epoch 5 — Val Loss: 0.0694, Val Recall: 0.9815 (Acc: 0.9801, P: 0.9787, R: 0.9815, F1: 0.9801, ROC: 0.9964, PR: 0.9962)\n",
      "  New best model (by val_loss) saved at epoch 5.\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0261, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0135, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0267, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0148, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.1053, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0305\n",
      "Epoch 6 — Val Loss: 0.0715, Val Recall: 0.9775 (Acc: 0.9807, P: 0.9838, R: 0.9775, F1: 0.9807, ROC: 0.9966, PR: 0.9966)\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0073, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0125, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0226, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0770, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0018, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0185\n",
      "Epoch 7 — Val Loss: 0.0765, Val Recall: 0.9802 (Acc: 0.9797, P: 0.9793, R: 0.9802, F1: 0.9797, ROC: 0.9964, PR: 0.9964)\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0125, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0105, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0020, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0076, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0073, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0117\n",
      "Epoch 8 — Val Loss: 0.0782, Val Recall: 0.9831 (Acc: 0.9806, P: 0.9783, R: 0.9831, F1: 0.9807, ROC: 0.9966, PR: 0.9968)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0163, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0011, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0015, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0015, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0071, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0071\n",
      "Epoch 9 — Val Loss: 0.0891, Val Recall: 0.9748 (Acc: 0.9797, P: 0.9845, R: 0.9748, F1: 0.9796, ROC: 0.9965, PR: 0.9966)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0014, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0033, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0011, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0078, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0046, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0040\n",
      "Epoch 10 — Val Loss: 0.0976, Val Recall: 0.9804 (Acc: 0.9812, P: 0.9819, R: 0.9804, F1: 0.9812, ROC: 0.9963, PR: 0.9965)\n",
      "Early stopping triggered after 10 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 5 with Val Loss: 0.0694\n",
      "\n",
      "Training finished. Total time: 199.91s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 5:\n",
      "  - Accuracy: 0.9801\n",
      "  - Precision: 0.9787\n",
      "  - Recall: 0.9815\n",
      "  - F1: 0.9801\n",
      "  - Roc_auc: 0.9964\n",
      "  - Pr_auc: 0.9962\n",
      "  - Val_loss: 0.0694\n",
      "Fold 9 finished. Val Recall: 0.9815 (from best model by val_loss within fold)\n",
      "\n",
      "--- Repetition 5/5, Fold 2/2 (Overall Fold 10) ---\n",
      "Using device: cuda\n",
      "Using recall as the primary scoring metric for validation.\n",
      "Using explicitly provided training and validation DataFrames.\n",
      "Training set size: 8987, Validation set size: 8987\n",
      "Training set class distribution: {0: 4500, 1: 4487}\n",
      "Validation set class distribution: {0: 4500, 1: 4487}\n",
      "Using class weights: [0.99855556 1.00144863]\n",
      "Starting training...\n",
      "Epoch 1, Batch 0/141, Train Loss: 0.6953, LR: 4.00e-05\n",
      "Epoch 1, Batch 29/141, Train Loss: 0.6598, LR: 4.30e-05\n",
      "Epoch 1, Batch 58/141, Train Loss: 0.6414, LR: 5.15e-05\n",
      "Epoch 1, Batch 87/141, Train Loss: 0.6009, LR: 6.55e-05\n",
      "Epoch 1, Batch 116/141, Train Loss: 0.4640, LR: 8.47e-05\n",
      "Epoch 1/20 — Train Loss: 0.5910\n",
      "Epoch 1 — Val Loss: 0.3839, Val Recall: 0.9008 (Acc: 0.8691, P: 0.8468, R: 0.9008, F1: 0.8730, ROC: 0.9392, PR: 0.9330)\n",
      "  New best model (by val_loss) saved at epoch 1.\n",
      "Epoch 2, Batch 0/141, Train Loss: 0.3516, LR: 1.05e-04\n",
      "Epoch 2, Batch 29/141, Train Loss: 0.3863, LR: 1.34e-04\n",
      "Epoch 2, Batch 58/141, Train Loss: 0.2286, LR: 1.67e-04\n",
      "Epoch 2, Batch 87/141, Train Loss: 0.1975, LR: 2.04e-04\n",
      "Epoch 2, Batch 116/141, Train Loss: 0.1564, LR: 2.44e-04\n",
      "Epoch 2/20 — Train Loss: 0.2417\n",
      "Epoch 2 — Val Loss: 0.1483, Val Recall: 0.9681 (Acc: 0.9618, P: 0.9560, R: 0.9681, F1: 0.9620, ROC: 0.9901, PR: 0.9844)\n",
      "  New best model (by val_loss) saved at epoch 2.\n",
      "Epoch 3, Batch 0/141, Train Loss: 0.1026, LR: 2.82e-04\n",
      "Epoch 3, Batch 29/141, Train Loss: 0.1414, LR: 3.28e-04\n",
      "Epoch 3, Batch 58/141, Train Loss: 0.0433, LR: 3.77e-04\n",
      "Epoch 3, Batch 87/141, Train Loss: 0.1029, LR: 4.27e-04\n",
      "Epoch 3, Batch 116/141, Train Loss: 0.0342, LR: 4.78e-04\n",
      "Epoch 3/20 — Train Loss: 0.1071\n",
      "Epoch 3 — Val Loss: 0.1145, Val Recall: 0.9692 (Acc: 0.9736, P: 0.9777, R: 0.9692, F1: 0.9735, ROC: 0.9946, PR: 0.9920)\n",
      "  New best model (by val_loss) saved at epoch 3.\n",
      "Epoch 4, Batch 0/141, Train Loss: 0.0325, LR: 5.23e-04\n",
      "Epoch 4, Batch 29/141, Train Loss: 0.0769, LR: 5.74e-04\n",
      "Epoch 4, Batch 58/141, Train Loss: 0.0944, LR: 6.25e-04\n",
      "Epoch 4, Batch 87/141, Train Loss: 0.0267, LR: 6.75e-04\n",
      "Epoch 4, Batch 116/141, Train Loss: 0.0602, LR: 7.23e-04\n",
      "Epoch 4/20 — Train Loss: 0.0748\n",
      "Epoch 4 — Val Loss: 0.1007, Val Recall: 0.9762 (Acc: 0.9792, P: 0.9821, R: 0.9762, F1: 0.9791, ROC: 0.9957, PR: 0.9938)\n",
      "  New best model (by val_loss) saved at epoch 4.\n",
      "Epoch 5, Batch 0/141, Train Loss: 0.0793, LR: 7.63e-04\n",
      "Epoch 5, Batch 29/141, Train Loss: 0.0551, LR: 8.06e-04\n",
      "Epoch 5, Batch 58/141, Train Loss: 0.1129, LR: 8.46e-04\n",
      "Epoch 5, Batch 87/141, Train Loss: 0.0376, LR: 8.82e-04\n",
      "Epoch 5, Batch 116/141, Train Loss: 0.0258, LR: 9.14e-04\n",
      "Epoch 5/20 — Train Loss: 0.0522\n",
      "Epoch 5 — Val Loss: 0.1029, Val Recall: 0.9661 (Acc: 0.9749, P: 0.9832, R: 0.9661, F1: 0.9746, ROC: 0.9961, PR: 0.9945)\n",
      "Epoch 6, Batch 0/141, Train Loss: 0.0405, LR: 9.37e-04\n",
      "Epoch 6, Batch 29/141, Train Loss: 0.0567, LR: 9.60e-04\n",
      "Epoch 6, Batch 58/141, Train Loss: 0.0434, LR: 9.78e-04\n",
      "Epoch 6, Batch 87/141, Train Loss: 0.0341, LR: 9.91e-04\n",
      "Epoch 6, Batch 116/141, Train Loss: 0.0474, LR: 9.98e-04\n",
      "Epoch 6/20 — Train Loss: 0.0374\n",
      "Epoch 6 — Val Loss: 0.0947, Val Recall: 0.9900 (Acc: 0.9842, P: 0.9786, R: 0.9900, F1: 0.9843, ROC: 0.9966, PR: 0.9958)\n",
      "  New best model (by val_loss) saved at epoch 6.\n",
      "Epoch 7, Batch 0/141, Train Loss: 0.0112, LR: 1.00e-03\n",
      "Epoch 7, Batch 29/141, Train Loss: 0.0062, LR: 9.99e-04\n",
      "Epoch 7, Batch 58/141, Train Loss: 0.0400, LR: 9.98e-04\n",
      "Epoch 7, Batch 87/141, Train Loss: 0.0088, LR: 9.95e-04\n",
      "Epoch 7, Batch 116/141, Train Loss: 0.0259, LR: 9.91e-04\n",
      "Epoch 7/20 — Train Loss: 0.0223\n",
      "Epoch 7 — Val Loss: 0.0909, Val Recall: 0.9828 (Acc: 0.9828, P: 0.9826, R: 0.9828, F1: 0.9827, ROC: 0.9971, PR: 0.9966)\n",
      "  New best model (by val_loss) saved at epoch 7.\n",
      "Epoch 8, Batch 0/141, Train Loss: 0.0039, LR: 9.87e-04\n",
      "Epoch 8, Batch 29/141, Train Loss: 0.0081, LR: 9.81e-04\n",
      "Epoch 8, Batch 58/141, Train Loss: 0.0042, LR: 9.75e-04\n",
      "Epoch 8, Batch 87/141, Train Loss: 0.0056, LR: 9.67e-04\n",
      "Epoch 8, Batch 116/141, Train Loss: 0.0748, LR: 9.58e-04\n",
      "Epoch 8/20 — Train Loss: 0.0172\n",
      "Epoch 8 — Val Loss: 0.0933, Val Recall: 0.9848 (Acc: 0.9831, P: 0.9813, R: 0.9848, F1: 0.9831, ROC: 0.9972, PR: 0.9968)\n",
      "Epoch 9, Batch 0/141, Train Loss: 0.0041, LR: 9.50e-04\n",
      "Epoch 9, Batch 29/141, Train Loss: 0.0038, LR: 9.39e-04\n",
      "Epoch 9, Batch 58/141, Train Loss: 0.0057, LR: 9.28e-04\n",
      "Epoch 9, Batch 87/141, Train Loss: 0.0045, LR: 9.15e-04\n",
      "Epoch 9, Batch 116/141, Train Loss: 0.0013, LR: 9.02e-04\n",
      "Epoch 9/20 — Train Loss: 0.0105\n",
      "Epoch 9 — Val Loss: 0.1009, Val Recall: 0.9851 (Acc: 0.9824, P: 0.9798, R: 0.9851, F1: 0.9824, ROC: 0.9972, PR: 0.9970)\n",
      "Epoch 10, Batch 0/141, Train Loss: 0.0506, LR: 8.90e-04\n",
      "Epoch 10, Batch 29/141, Train Loss: 0.0058, LR: 8.75e-04\n",
      "Epoch 10, Batch 58/141, Train Loss: 0.0181, LR: 8.59e-04\n",
      "Epoch 10, Batch 87/141, Train Loss: 0.0019, LR: 8.43e-04\n",
      "Epoch 10, Batch 116/141, Train Loss: 0.0008, LR: 8.26e-04\n",
      "Epoch 10/20 — Train Loss: 0.0071\n",
      "Epoch 10 — Val Loss: 0.1060, Val Recall: 0.9862 (Acc: 0.9829, P: 0.9796, R: 0.9862, F1: 0.9829, ROC: 0.9970, PR: 0.9969)\n",
      "Epoch 11, Batch 0/141, Train Loss: 0.0035, LR: 8.10e-04\n",
      "Epoch 11, Batch 29/141, Train Loss: 0.0118, LR: 7.92e-04\n",
      "Epoch 11, Batch 58/141, Train Loss: 0.0008, LR: 7.73e-04\n",
      "Epoch 11, Batch 87/141, Train Loss: 0.0026, LR: 7.53e-04\n",
      "Epoch 11, Batch 116/141, Train Loss: 0.0008, LR: 7.33e-04\n",
      "Epoch 11/20 — Train Loss: 0.0044\n",
      "Epoch 11 — Val Loss: 0.1133, Val Recall: 0.9869 (Acc: 0.9815, P: 0.9764, R: 0.9869, F1: 0.9816, ROC: 0.9968, PR: 0.9967)\n",
      "Epoch 12, Batch 0/141, Train Loss: 0.0188, LR: 7.16e-04\n",
      "Epoch 12, Batch 29/141, Train Loss: 0.0006, LR: 6.94e-04\n",
      "Epoch 12, Batch 58/141, Train Loss: 0.0003, LR: 6.73e-04\n",
      "Epoch 12, Batch 87/141, Train Loss: 0.0079, LR: 6.51e-04\n",
      "Epoch 12, Batch 116/141, Train Loss: 0.0025, LR: 6.29e-04\n",
      "Epoch 12/20 — Train Loss: 0.0031\n",
      "Epoch 12 — Val Loss: 0.1169, Val Recall: 0.9840 (Acc: 0.9819, P: 0.9798, R: 0.9840, F1: 0.9819, ROC: 0.9970, PR: 0.9969)\n",
      "Early stopping triggered after 12 epochs due to no improvement in validation loss.\n",
      "Loaded best model from epoch 7 with Val Loss: 0.0909\n",
      "\n",
      "Training finished. Total time: 238.29s. Model size: 1034778.05 KB\n",
      "Best model (by val_loss) obtained at epoch 7:\n",
      "  - Accuracy: 0.9828\n",
      "  - Precision: 0.9826\n",
      "  - Recall: 0.9828\n",
      "  - F1: 0.9827\n",
      "  - Roc_auc: 0.9971\n",
      "  - Pr_auc: 0.9966\n",
      "  - Val_loss: 0.0909\n",
      "Fold 10 finished. Val Recall: 0.9828 (from best model by val_loss within fold)\n",
      "\n",
      "--- Overall Cross-Validation Summary ---\n",
      "Mean accuracy: 0.9798\n",
      "Std accuracy: 0.0026\n",
      "Mean precision: 0.9804\n",
      "Std precision: 0.0052\n",
      "Mean recall: 0.9792\n",
      "Std recall: 0.0039\n",
      "Mean f1: 0.9798\n",
      "Std f1: 0.0026\n",
      "Mean roc auc: 0.9970\n",
      "Std roc auc: 0.0007\n",
      "Mean pr auc: 0.9967\n",
      "Std pr auc: 0.0010\n",
      "Mean val loss: 0.0732\n",
      "Std val loss: 0.0142\n",
      "Mean model size: 1034778.0518\n",
      "Std model size: 0.0000\n",
      "Mean training time: 215.0232\n",
      "Std training time: 23.6538\n",
      "Best model across all folds (based on RECALL on validation set of its fold): Rep 2, Fold 2 (Overall Fold 4) with score 0.9869\n",
      "Loading the overall best model state...\n"
     ]
    }
   ],
   "source": [
    "nn_model, nn_results, fitted_scalers = cross_val_train_nn_model(\n",
    "    df=df,\n",
    "    vocab_dict=vocab_dict,\n",
    "    sequence_cols=SEQUENCE_COLS,\n",
    "    scalar_cols=SCALAR_COLS,\n",
    "    char_cols=CHAR_COLS,\n",
    "    vector_cols=VECTOR_COLS,\n",
    "    vector_dims=VECTOR_DIMS,\n",
    "    hyperparams=nn_hyperparams,\n",
    "    n_folds=2,\n",
    "    n_repetitions=5,\n",
    "    scoring_metric=\"recall\",\n",
    "    device=device,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83184c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalers saved to c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\nn_models\\20250625_201221\\scalers.joblib\n",
      "Model and artifacts saved to c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\nn_models\\20250625_201221\n"
     ]
    }
   ],
   "source": [
    "save_paths = save_model_with_metadata(\n",
    "    model=nn_model,\n",
    "    vocab_dict=vocab_dict,\n",
    "    hyperparams=nn_hyperparams,\n",
    "    results=nn_results,\n",
    "    scalers=fitted_scalers,\n",
    "    save_dir=PATH_TO_SAVE_NN_MODEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5421c88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce RTX 4070 SUPER\n",
      "Loading latest model version: 20250625_201221\n",
      "Scalers loaded from c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\nn_models\\20250625_201221\\scalers.joblib\n",
      "Model loaded from c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\nn_models\\20250625_201221\n",
      "Using CUDA device: NVIDIA GeForce RTX 4070 SUPER\n",
      "--- Evaluating on Test Set ---\n",
      "\n",
      "--- Test Set Evaluation Metrics ---\n",
      "  Inference Time: 6.46 seconds\n",
      "  Accuracy: 0.9800\n",
      "  Precision binary: 0.9819\n",
      "  Recall binary: 0.9780\n",
      "  F1 binary: 0.9799\n",
      "  Precision weighted: 0.9800\n",
      "  Recall weighted: 0.9800\n",
      "  F1 weighted: 0.9800\n",
      "  Confusion Matrix:\n",
      "[[982  18]\n",
      " [ 22 976]]\n",
      "  Inference time: 6.4558\n",
      "  Roc auc: 0.9982\n",
      "  Pr auc: 0.9982\n",
      "---------------------------------\n",
      "Test set evaluation results:\n",
      "{'accuracy': 0.97997997997998,\n",
      " 'classification_report': {'0': {'f1-score': 0.9800399201596807,\n",
      "                                 'precision': 0.9780876494023905,\n",
      "                                 'recall': 0.982,\n",
      "                                 'support': 1000.0},\n",
      "                           '1': {'f1-score': 0.9799196787148594,\n",
      "                                 'precision': 0.9818913480885312,\n",
      "                                 'recall': 0.9779559118236473,\n",
      "                                 'support': 998.0},\n",
      "                           'accuracy': 0.97997997997998,\n",
      "                           'macro avg': {'f1-score': 0.9799797994372701,\n",
      "                                         'precision': 0.9799894987454608,\n",
      "                                         'recall': 0.9799779559118236,\n",
      "                                         'support': 1998.0},\n",
      "                           'weighted avg': {'f1-score': 0.9799798596181734,\n",
      "                                            'precision': 0.9799875949923647,\n",
      "                                            'recall': 0.97997997997998,\n",
      "                                            'support': 1998.0}},\n",
      " 'confusion_matrix': [[982, 18], [22, 976]],\n",
      " 'f1_binary': 0.9799196787148594,\n",
      " 'f1_weighted': 0.9799798596181734,\n",
      " 'inference_time': 6.455803394317627,\n",
      " 'pr_auc': 0.998229184522645,\n",
      " 'precision_binary': 0.9818913480885312,\n",
      " 'precision_weighted': 0.9799875949923647,\n",
      " 'recall_binary': 0.9779559118236473,\n",
      " 'recall_weighted': 0.97997997997998,\n",
      " 'roc_auc': 0.998188376753507}\n"
     ]
    }
   ],
   "source": [
    "nn_model, _, fitted_scalers, _ = load_apk_analysis_model_from_version(\n",
    "    base_dir=PATH_TO_SAVE_NN_MODEL,\n",
    ")\n",
    "\n",
    "results = evaluate_model_on_test_set(\n",
    "    model=nn_model,\n",
    "    df_test=df_test,\n",
    "    scalers=fitted_scalers,\n",
    "    sequence_cols=SEQUENCE_COLS,\n",
    "    scalar_cols=SCALAR_COLS,\n",
    "    char_cols=CHAR_COLS,\n",
    "    vector_cols=VECTOR_COLS,\n",
    "    hyperparams=nn_hyperparams,\n",
    ")\n",
    "\n",
    "print(\"Test set evaluation results:\")\n",
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64783c0a",
   "metadata": {},
   "source": [
    "# ML MODELS TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ddf73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce RTX 4070 SUPER\n",
      "Loading latest model version: 20250625_201221\n",
      "Scalers loaded from c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\nn_models\\20250625_201221\\scalers.joblib (for context, though embedder doesn't use them directly)\n",
      "Embedder loaded from c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\nn_models\\20250625_201221\n",
      "Loading latest model version: 20250625_201221\n",
      "Recall Score: 0.9811699164345404\n"
     ]
    }
   ],
   "source": [
    "# Load the latest model version\n",
    "# model, vocab_dict, used_scalers, metadata = load_apk_analysis_model_from_version(\n",
    "#     base_dir=PATH_TO_SAVE_NN_MODEL,\n",
    "# )\n",
    "\n",
    "# Load just the embedder from the latest version\n",
    "embedder, vocab_dict, used_scalers, metadata = load_apk_feature_embedder_from_version(\n",
    "    base_dir=PATH_TO_SAVE_NN_MODEL,\n",
    ")\n",
    "\n",
    "# Load just metadata to check performance metrics\n",
    "metadata = load_apk_analysis_model_metadata(base_dir=PATH_TO_SAVE_NN_MODEL)\n",
    "print(f\"Recall Score: {metadata['summary_metrics'].get('mean_recall', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b149bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 5 models with 5 x 2-fold cross-validation...\n",
      "\n",
      "=== Repetition 1/5, Fold 1/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9868, P: 0.9868, R: 0.9868, F1: 0.9868, ROC: 0.9991, PR: 0.9992, Size=1317.7KB, Time=8.15s\n",
      "  ★ New best RandomForest model: recall=0.9868\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9893, P: 0.9893, R: 0.9893, F1: 0.9893, ROC: 0.9994, PR: 0.9994, Size=219.2KB, Time=1.09s\n",
      "  ★ New best XGBoost model: recall=0.9893\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9726, P: 0.9727, R: 0.9726, F1: 0.9726, ROC: 0.9888, PR: 0.9898, Size=15833.2KB, Time=0.00s\n",
      "  ★ New best KNN model: recall=0.9726\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9836, P: 0.9836, R: 0.9836, F1: 0.9836, ROC: 0.9978, PR: 0.9978, Size=1066.5KB, Time=0.39s\n",
      "  ★ New best SVM model: recall=0.9836\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9873, P: 0.9873, R: 0.9873, F1: 0.9873, ROC: 0.9988, PR: 0.9988, Size=4.2KB, Time=0.32s\n",
      "  ★ New best LogisticRegression model: recall=0.9873\n",
      "\n",
      "=== Repetition 1/5, Fold 2/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9838, P: 0.9838, R: 0.9838, F1: 0.9838, ROC: 0.9986, PR: 0.9987, Size=1194.4KB, Time=8.22s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9871, P: 0.9871, R: 0.9871, F1: 0.9871, ROC: 0.9991, PR: 0.9992, Size=212.6KB, Time=1.01s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9716, P: 0.9718, R: 0.9716, F1: 0.9716, ROC: 0.9870, PR: 0.9884, Size=15833.2KB, Time=0.00s\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9838, P: 0.9838, R: 0.9838, F1: 0.9838, ROC: 0.9978, PR: 0.9980, Size=1151.2KB, Time=0.45s\n",
      "  ★ New best SVM model: recall=0.9838\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9854, P: 0.9854, R: 0.9854, F1: 0.9854, ROC: 0.9987, PR: 0.9988, Size=4.2KB, Time=0.36s\n",
      "\n",
      "=== Repetition 2/5, Fold 1/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9842, P: 0.9842, R: 0.9842, F1: 0.9842, ROC: 0.9988, PR: 0.9988, Size=1231.0KB, Time=8.14s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9882, P: 0.9882, R: 0.9882, F1: 0.9882, ROC: 0.9992, PR: 0.9992, Size=214.0KB, Time=1.16s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9727, P: 0.9729, R: 0.9727, F1: 0.9727, ROC: 0.9870, PR: 0.9885, Size=15833.2KB, Time=0.00s\n",
      "  ★ New best KNN model: recall=0.9727\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9845, P: 0.9845, R: 0.9845, F1: 0.9845, ROC: 0.9981, PR: 0.9980, Size=1112.4KB, Time=0.42s\n",
      "  ★ New best SVM model: recall=0.9845\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9876, P: 0.9877, R: 0.9876, F1: 0.9876, ROC: 0.9989, PR: 0.9988, Size=4.2KB, Time=0.36s\n",
      "  ★ New best LogisticRegression model: recall=0.9876\n",
      "\n",
      "=== Repetition 2/5, Fold 2/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9861, P: 0.9861, R: 0.9861, F1: 0.9861, ROC: 0.9989, PR: 0.9989, Size=1311.8KB, Time=8.15s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9884, P: 0.9884, R: 0.9884, F1: 0.9884, ROC: 0.9992, PR: 0.9992, Size=215.0KB, Time=1.01s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9727, P: 0.9728, R: 0.9727, F1: 0.9727, ROC: 0.9884, PR: 0.9895, Size=15833.2KB, Time=0.00s\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9801, P: 0.9801, R: 0.9801, F1: 0.9801, ROC: 0.9976, PR: 0.9975, Size=1087.7KB, Time=0.42s\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9845, P: 0.9845, R: 0.9845, F1: 0.9845, ROC: 0.9985, PR: 0.9985, Size=4.2KB, Time=0.42s\n",
      "\n",
      "=== Repetition 3/5, Fold 1/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9846, P: 0.9847, R: 0.9846, F1: 0.9846, ROC: 0.9989, PR: 0.9989, Size=1207.0KB, Time=8.39s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9874, P: 0.9874, R: 0.9874, F1: 0.9874, ROC: 0.9994, PR: 0.9994, Size=211.2KB, Time=1.04s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9735, P: 0.9736, R: 0.9735, F1: 0.9735, ROC: 0.9899, PR: 0.9906, Size=15833.2KB, Time=0.00s\n",
      "  ★ New best KNN model: recall=0.9735\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9844, P: 0.9844, R: 0.9844, F1: 0.9844, ROC: 0.9980, PR: 0.9981, Size=1165.3KB, Time=0.48s\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9863, P: 0.9863, R: 0.9863, F1: 0.9863, ROC: 0.9989, PR: 0.9989, Size=4.2KB, Time=0.33s\n",
      "\n",
      "=== Repetition 3/5, Fold 2/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9869, P: 0.9869, R: 0.9869, F1: 0.9869, ROC: 0.9988, PR: 0.9988, Size=1282.1KB, Time=8.07s\n",
      "  ★ New best RandomForest model: recall=0.9869\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9879, P: 0.9879, R: 0.9879, F1: 0.9879, ROC: 0.9992, PR: 0.9993, Size=213.0KB, Time=0.94s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9705, P: 0.9706, R: 0.9705, F1: 0.9705, ROC: 0.9874, PR: 0.9885, Size=15833.2KB, Time=0.01s\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9819, P: 0.9819, R: 0.9819, F1: 0.9819, ROC: 0.9978, PR: 0.9977, Size=1006.6KB, Time=0.33s\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9840, P: 0.9840, R: 0.9840, F1: 0.9840, ROC: 0.9983, PR: 0.9983, Size=4.2KB, Time=0.40s\n",
      "\n",
      "=== Repetition 4/5, Fold 1/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9850, P: 0.9850, R: 0.9850, F1: 0.9850, ROC: 0.9989, PR: 0.9989, Size=1275.0KB, Time=8.03s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9876, P: 0.9877, R: 0.9876, F1: 0.9876, ROC: 0.9993, PR: 0.9993, Size=219.3KB, Time=0.95s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9722, P: 0.9722, R: 0.9722, F1: 0.9722, ROC: 0.9886, PR: 0.9899, Size=15833.2KB, Time=0.00s\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9829, P: 0.9829, R: 0.9829, F1: 0.9829, ROC: 0.9981, PR: 0.9980, Size=1137.1KB, Time=0.44s\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9859, P: 0.9859, R: 0.9859, F1: 0.9859, ROC: 0.9988, PR: 0.9987, Size=4.2KB, Time=0.34s\n",
      "\n",
      "=== Repetition 4/5, Fold 2/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9851, P: 0.9851, R: 0.9851, F1: 0.9851, ROC: 0.9987, PR: 0.9988, Size=1265.2KB, Time=8.10s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9882, P: 0.9882, R: 0.9882, F1: 0.9882, ROC: 0.9991, PR: 0.9991, Size=211.5KB, Time=0.95s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9705, P: 0.9709, R: 0.9705, F1: 0.9705, ROC: 0.9883, PR: 0.9890, Size=15833.2KB, Time=0.00s\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9843, P: 0.9843, R: 0.9843, F1: 0.9843, ROC: 0.9982, PR: 0.9983, Size=1052.4KB, Time=0.37s\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9866, P: 0.9866, R: 0.9866, F1: 0.9866, ROC: 0.9986, PR: 0.9987, Size=4.2KB, Time=0.37s\n",
      "\n",
      "=== Repetition 5/5, Fold 1/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9832, P: 0.9832, R: 0.9832, F1: 0.9832, ROC: 0.9985, PR: 0.9985, Size=1229.5KB, Time=7.99s\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9865, P: 0.9865, R: 0.9865, F1: 0.9865, ROC: 0.9991, PR: 0.9991, Size=209.6KB, Time=0.98s\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9731, P: 0.9731, R: 0.9731, F1: 0.9731, ROC: 0.9896, PR: 0.9904, Size=15833.2KB, Time=0.00s\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9833, P: 0.9833, R: 0.9833, F1: 0.9833, ROC: 0.9981, PR: 0.9979, Size=1084.2KB, Time=0.44s\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9865, P: 0.9865, R: 0.9865, F1: 0.9865, ROC: 0.9986, PR: 0.9986, Size=4.2KB, Time=0.36s\n",
      "\n",
      "=== Repetition 5/5, Fold 2/2 ===\n",
      "Class distribution:\n",
      "  Class 0: 4500 train, 4500 test\n",
      "  Class 1: 4487 train, 4487 test\n",
      "Training RandomForest...\n",
      "  RandomForest: Acc=0.9880, P: 0.9880, R: 0.9880, F1: 0.9880, ROC: 0.9991, PR: 0.9992, Size=1341.0KB, Time=8.13s\n",
      "  ★ New best RandomForest model: recall=0.9880\n",
      "Training XGBoost...\n",
      "  XGBoost: Acc=0.9901, P: 0.9901, R: 0.9901, F1: 0.9901, ROC: 0.9994, PR: 0.9994, Size=221.3KB, Time=0.97s\n",
      "  ★ New best XGBoost model: recall=0.9901\n",
      "Training KNN...\n",
      "  KNN: Acc=0.9737, P: 0.9739, R: 0.9737, F1: 0.9737, ROC: 0.9888, PR: 0.9898, Size=15833.2KB, Time=0.00s\n",
      "  ★ New best KNN model: recall=0.9737\n",
      "Training SVM...\n",
      "[LibSVM]  SVM: Acc=0.9848, P: 0.9848, R: 0.9848, F1: 0.9848, ROC: 0.9985, PR: 0.9985, Size=1144.1KB, Time=0.44s\n",
      "  ★ New best SVM model: recall=0.9848\n",
      "Training LogisticRegression...\n",
      "  LogisticRegression: Acc=0.9866, P: 0.9866, R: 0.9866, F1: 0.9866, ROC: 0.9989, PR: 0.9989, Size=4.2KB, Time=0.34s\n",
      "\n",
      "=== RandomForest Summary ===\n",
      "Mean RECALL: 0.9854 ± 0.0014\n",
      "Best RECALL: 0.9880\n",
      "Mean Size: 1265.5KB\n",
      "Mean Training Time: 8.14s\n",
      "\n",
      "=== XGBoost Summary ===\n",
      "Mean RECALL: 0.9881 ± 0.0010\n",
      "Best RECALL: 0.9901\n",
      "Mean Size: 214.7KB\n",
      "Mean Training Time: 1.01s\n",
      "\n",
      "=== KNN Summary ===\n",
      "Mean RECALL: 0.9723 ± 0.0011\n",
      "Best RECALL: 0.9737\n",
      "Mean Size: 15833.2KB\n",
      "Mean Training Time: 0.00s\n",
      "\n",
      "=== SVM Summary ===\n",
      "Mean RECALL: 0.9834 ± 0.0014\n",
      "Best RECALL: 0.9848\n",
      "Mean Size: 1100.7KB\n",
      "Mean Training Time: 0.42s\n",
      "\n",
      "=== LogisticRegression Summary ===\n",
      "Mean RECALL: 0.9861 ± 0.0011\n",
      "Best RECALL: 0.9876\n",
      "Mean Size: 4.2KB\n",
      "Mean Training Time: 0.36s\n",
      "\n",
      "Best models saved for each model type.\n",
      "Saved 5 model(s) to c:\\Users\\david\\Desktop\\Clase\\TFG\\tfg_24_25\\model_artifacts\\ml_models\\20250626_211448\n",
      "  - RandomForest\n",
      "  - XGBoost\n",
      "  - KNN\n",
      "  - SVM\n",
      "  - LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# Train classical ML models on embeddings from the nn model\n",
    "X, y = extract_embeddings(\n",
    "    model=embedder,\n",
    "    df=df,\n",
    "    scalers=used_scalers,\n",
    "    sequence_cols=SEQUENCE_COLS,\n",
    "    scalar_cols=SCALAR_COLS,\n",
    "    char_cols=CHAR_COLS,\n",
    "    vector_cols=VECTOR_COLS,\n",
    "    device=device,\n",
    "    label_col=\"is_malware\",\n",
    ")\n",
    "\n",
    "ml_hyperparams_dict = {\n",
    "    \"RandomForest\": MLHyperparams(\n",
    "        model_type=\"random_forest\",\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": MLHyperparams(\n",
    "        model_type=\"xgboost\",\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"KNN\": MLHyperparams(\n",
    "        model_type=\"knn\",\n",
    "        n_neighbors=5,\n",
    "        weights=\"uniform\",\n",
    "    ),\n",
    "    \"SVM\": MLHyperparams(\n",
    "        model_type=\"svm\",\n",
    "        C=1.0,\n",
    "        kernel=\"linear\",\n",
    "        probability=False,\n",
    "        random_state=42,\n",
    "        verbose=True,\n",
    "    ),\n",
    "    \"LogisticRegression\": MLHyperparams(\n",
    "        model_type=\"logistic_regression\",\n",
    "        C=1.0,\n",
    "        solver=\"liblinear\",\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "ml_results, ml_best_models = train_classical_models_cv(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    hyperparams_dict=ml_hyperparams_dict,\n",
    "    n_folds=2,\n",
    "    n_repetitions=5,\n",
    "    scoring_metric=\"recall\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Save the ML models\n",
    "ml_saved_paths = save_ml_models_with_metadata(\n",
    "    models=ml_best_models, results=ml_results, save_dir=PATH_TO_SAVE_ML_MODEL\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
