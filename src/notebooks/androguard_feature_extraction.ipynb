{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import androguard\n",
    "import androguard.misc\n",
    "import androguard.util\n",
    "import ppdeep\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac62b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path().cwd().parent.parent\n",
    "PATH_TO_APK = PROJECT_ROOT / \"apks\" / \"0a0a78000e418ea28fa02e8c162c43396db6141ef8fe876db4027fef04bed663.apk\"\n",
    "\n",
    "apk_fuzzy_hash = ppdeep.hash_from_file(PATH_TO_APK)\n",
    "\n",
    "\n",
    "hash_1 = apk_fuzzy_hash.split(\":\")[1]\n",
    "\n",
    "print(f\"APK Fuzzy Hash: {apk_fuzzy_hash}, Hash: {hash_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf20fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the APK file\n",
    "\n",
    "androguard.util.set_log(\"CRITICAL\")\n",
    "\n",
    "a, d, dx = androguard.misc.AnalyzeAPK(str(PATH_TO_APK))\n",
    "\n",
    "# Get size of the APK file\n",
    "apk_size = os.path.getsize(PATH_TO_APK)\n",
    "\n",
    "apk_fuzzy_hash = ppdeep.hash_from_file(PATH_TO_APK)\n",
    "\n",
    "# Get permissions, activities, services, and receivers\n",
    "activities = a.get_activities()\n",
    "services = a.get_services()\n",
    "receivers = a.get_receivers()\n",
    "permissions = a.get_permissions()\n",
    "\n",
    "display(activities)\n",
    "display(services)\n",
    "display(receivers)\n",
    "display(permissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36391836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of methods and classes\n",
    "def extract_api_calls(dx):\n",
    "    \"\"\"Extract unique API calls from the APK\"\"\"\n",
    "    api_calls = set()\n",
    "\n",
    "    # Iterate through all classes\n",
    "    for cls in dx.get_classes():\n",
    "        # Iterate through all methods in the class\n",
    "        for method in cls.get_methods():\n",
    "            # Get external method calls\n",
    "            for _, call, _ in method.get_xref_to():\n",
    "                if call.is_external():\n",
    "                    # Format: package_name.class_name.method_name\n",
    "                    api_call = f\"{call.get_class_name()[1:-1]}.{call.name}\"\n",
    "                    api_calls.add(api_call)\n",
    "\n",
    "    return sorted(list(api_calls))\n",
    "\n",
    "\n",
    "api_calls = extract_api_calls(dx)\n",
    "print(f\"Total number of unique API calls: {len(api_calls)}\")\n",
    "print(\"Sample API calls:\")\n",
    "for call in api_calls:\n",
    "    print(f\"  - {call}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dbffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all opcodes from bytecode using dx object\n",
    "def extract_opcodes(dx):\n",
    "    # Opcode list: https://source.android.com/docs/core/runtime/dalvik-bytecode#instructions\n",
    "    opcodes_results = {\n",
    "        \"opcodes\": [None] * 768,  # Opcode values (0-255 + extended opcodes)\n",
    "        \"mnemonics\": [None] * 768,  # Mnemonic names\n",
    "        \"counts\": [0] * 768,  # Frequency counts\n",
    "    }\n",
    "\n",
    "    class_count = 0\n",
    "    method_count = 0\n",
    "    instruction_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    # Iterate through all classes\n",
    "    for cls in dx.get_classes():\n",
    "        class_count += 1\n",
    "        # Iterate through all methods in the class\n",
    "        for method in cls.get_methods():\n",
    "            method_count += 1\n",
    "            if method.is_external():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Get method implementation\n",
    "                m = method.get_method()\n",
    "                if m.get_code():\n",
    "                    # Extract opcodes from instructions\n",
    "                    for instruction in m.get_code().get_bc().get_instructions():\n",
    "                        instruction_count += 1\n",
    "                        opcode = instruction.get_op_value()\n",
    "                        mnemonic = instruction.get_name()\n",
    "\n",
    "                        # Store in the arrays at the correct position\n",
    "                        if 0 <= opcode < 256:  # Ensure opcode is in valid range\n",
    "                            opcodes_results[\"opcodes\"][opcode] = opcode\n",
    "                            opcodes_results[\"mnemonics\"][opcode] = mnemonic\n",
    "                            opcodes_results[\"counts\"][opcode] += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                if error_count < 5:  # Only print first few errors\n",
    "                    print(f\"Error in method {method.name}: {str(e)}\")\n",
    "\n",
    "    print(\n",
    "        f\"Processed {class_count} classes, {method_count} methods and {instruction_count} instructions\"\n",
    "    )\n",
    "    print(f\"Encountered {error_count} errors\")\n",
    "\n",
    "    # Calculate the total number of opcodes used\n",
    "    opcodes_used = sum(1 for opcode in opcodes_results[\"opcodes\"] if opcode is not None)\n",
    "    print(f\"Number of different opcodes used: {opcodes_used} out of 256 possible\")\n",
    "\n",
    "    return opcodes_results\n",
    "\n",
    "\n",
    "# Use the refactored function with dx\n",
    "opcodes_results = extract_opcodes(dx)\n",
    "\n",
    "# Print some statistics from the results\n",
    "used_opcodes = [i for i, op in enumerate(opcodes_results[\"opcodes\"]) if op is not None]\n",
    "total_instructions = sum(opcodes_results[\"counts\"])\n",
    "\n",
    "print(f\"\\nOpcode usage information:\")\n",
    "print(f\"Opcodes used: {len(used_opcodes)} out of 256\")\n",
    "print(f\"Total instructions: {total_instructions}\")\n",
    "\n",
    "print(\"\\nTop 10 most frequent opcodes:\")\n",
    "# Create tuples of (opcode, mnemonic, count) for non-null opcodes\n",
    "opcode_info = [\n",
    "    (i, opcodes_results[\"mnemonics\"][i], opcodes_results[\"counts\"][i])\n",
    "    for i in range(256)\n",
    "    if opcodes_results[\"opcodes\"][i] is not None\n",
    "]\n",
    "# Sort by count in descending order\n",
    "sorted_opcodes = sorted(opcode_info, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "for opcode, mnemonic, count in sorted_opcodes[:10]:\n",
    "    percentage = (count / total_instructions) * 100\n",
    "    print(f\"  - Opcode {opcode} ({mnemonic}): {count} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78584946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ppdeep\n",
    "import androguard.misc\n",
    "import androguard.util\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import json\n",
    "import time\n",
    "import multiprocessing\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "\n",
    "def extract_api_calls(dx):\n",
    "    \"\"\"Extract unique API calls from the APK\"\"\"\n",
    "    api_calls = set()\n",
    "\n",
    "    # Iterate through all classes\n",
    "    for cls in dx.get_classes():\n",
    "        # Iterate through all methods in the class\n",
    "        for method in cls.get_methods():\n",
    "            # Get external method calls\n",
    "            for _, call, _ in method.get_xref_to():\n",
    "                if call.is_external():\n",
    "                    # Format: package_name.class_name.method_name\n",
    "                    api_call = f\"{call.get_class_name()[1:-1]}.{call.name}\"\n",
    "                    api_calls.add(api_call)\n",
    "\n",
    "    return sorted(list(api_calls))\n",
    "\n",
    "\n",
    "def extract_opcodes(dx):\n",
    "    \"\"\"Extract opcode statistics from the APK\"\"\"\n",
    "    opcodes_results = {\n",
    "        \"opcodes\": [None] * 768,  # Opcode values (0-255 + extended opcodes)\n",
    "        \"mnemonics\": [None] * 768,  # Mnemonic names\n",
    "        \"counts\": [0] * 768,  # Frequency counts\n",
    "    }\n",
    "\n",
    "    # Iterate through all classes\n",
    "    for cls in dx.get_classes():\n",
    "        # Iterate through all methods in the class\n",
    "        for method in cls.get_methods():\n",
    "            if method.is_external():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Get method implementation\n",
    "                m = method.get_method()\n",
    "                if m.get_code():\n",
    "                    # Extract opcodes from instructions\n",
    "                    for instruction in m.get_code().get_bc().get_instructions():\n",
    "                        opcode = instruction.get_op_value()\n",
    "                        mnemonic = instruction.get_name()\n",
    "\n",
    "                        # Store in the arrays at the correct position\n",
    "                        if 0 <= opcode < 256:  # Ensure opcode is in valid range\n",
    "                            opcodes_results[\"opcodes\"][opcode] = opcode\n",
    "                            opcodes_results[\"mnemonics\"][opcode] = mnemonic\n",
    "                            opcodes_results[\"counts\"][opcode] += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error in method {method.name}: {str(e)}\")\n",
    "\n",
    "    return opcodes_results\n",
    "\n",
    "\n",
    "def analyze_apk_wrapper(args):\n",
    "    \"\"\"Wrapper function for multiprocessing compatibility\"\"\"\n",
    "    apk_path, is_malware = args\n",
    "    try:\n",
    "        # Get sha256 from filename\n",
    "        apk_filename = os.path.basename(apk_path)\n",
    "\n",
    "        # Check if there is a previous handler\n",
    "        try:\n",
    "            androguard.util.set_log(\"CRITICAL\")\n",
    "        except Exception as e:\n",
    "            ...\n",
    "\n",
    "        # Load and analyze the APK\n",
    "        a, d, dx = androguard.misc.AnalyzeAPK(apk_path)\n",
    "\n",
    "        # Get basic file information\n",
    "        apk_size = os.path.getsize(apk_path)\n",
    "\n",
    "        # Get fuzzy hash\n",
    "        apk_fuzzy_hash = ppdeep.hash_from_file(apk_path)\n",
    "        fuzzy_hash_1 = (\n",
    "            apk_fuzzy_hash.split(\":\")[1] if \":\" in apk_fuzzy_hash else apk_fuzzy_hash\n",
    "        )\n",
    "\n",
    "        # Get app components\n",
    "        activities = a.get_activities()\n",
    "        services = a.get_services()\n",
    "        receivers = a.get_receivers()\n",
    "        permissions = a.get_permissions()\n",
    "\n",
    "        # Extract API calls\n",
    "        api_calls = extract_api_calls(dx)\n",
    "\n",
    "        # Extract opcodes\n",
    "        opcodes_results = extract_opcodes(dx)\n",
    "\n",
    "        # Build feature dictionary with both counts and full lists\n",
    "        features = {\n",
    "            \"file_size\": apk_size,\n",
    "            \"fuzzy_hash\": fuzzy_hash_1,\n",
    "            \"activities_list\": activities,\n",
    "            \"services_list\": services,\n",
    "            \"receivers_list\": receivers,\n",
    "            \"permissions_list\": permissions,\n",
    "            \"api_calls_list\": api_calls,\n",
    "            \"opcode_counts\": opcodes_results[\"counts\"],\n",
    "            \"is_malware\": 1 if is_malware else 0,\n",
    "        }\n",
    "\n",
    "        # Clean up to help with memory\n",
    "        del a, d, dx\n",
    "        gc.collect()\n",
    "\n",
    "        return apk_filename, features, None\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error analyzing {apk_path}: {str(e)}\"\n",
    "        return None, None, error_msg\n",
    "\n",
    "\n",
    "def analyze_apks_mp(benign_dir, malware_dir, max_workers=None, chunk_size=10):\n",
    "    \"\"\"\n",
    "    Analyze APK files using multiprocessing instead of concurrent.futures\n",
    "\n",
    "    Parameters:\n",
    "    - benign_dir: Directory containing benign APKs\n",
    "    - malware_dir: Directory containing malware APKs\n",
    "    - max_workers: Maximum number of parallel workers\n",
    "    - chunk_size: Number of APKs to process in each batch\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame with extracted features\n",
    "    \"\"\"\n",
    "    # Get list of APK files\n",
    "    benign_apks = [\n",
    "        os.path.join(benign_dir, f)\n",
    "        for f in os.listdir(benign_dir)\n",
    "        if os.path.isfile(os.path.join(benign_dir, f))\n",
    "    ]\n",
    "    malware_apks = [\n",
    "        os.path.join(malware_dir, f)\n",
    "        for f in os.listdir(malware_dir)\n",
    "        if os.path.isfile(os.path.join(malware_dir, f))\n",
    "    ]\n",
    "    benign_apks = benign_apks[9120:]\n",
    "\n",
    "    all_apks = [(path, False) for path in benign_apks] + [\n",
    "        (path, True) for path in malware_apks\n",
    "    ]\n",
    "    results = {}\n",
    "    failed_apks = []\n",
    "\n",
    "    # If max_workers is not specified, use half of available cores\n",
    "    if max_workers is None:\n",
    "        max_workers = max(1, multiprocessing.cpu_count() // 2)\n",
    "\n",
    "    print(\n",
    "        f\"Processing {len(all_apks)} APKs ({len(benign_apks)} benign, {len(malware_apks)} malware)\"\n",
    "    )\n",
    "    print(f\"Using {max_workers} worker processes\")\n",
    "\n",
    "    # Split APKs into chunks to avoid memory issues\n",
    "    chunks = [all_apks[i : i + chunk_size] for i in range(0, len(all_apks), chunk_size)]\n",
    "\n",
    "    total_processed = 0\n",
    "    with tqdm(total=len(all_apks), desc=\"Analyzing APKs\") as pbar:\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            # Process this chunk of APKs\n",
    "            try:\n",
    "                # Create a pool for this chunk only\n",
    "                with multiprocessing.Pool(processes=max_workers) as pool:\n",
    "                    # Process in parallel and collect results\n",
    "                    chunk_results = pool.map(analyze_apk_wrapper, chunk)\n",
    "\n",
    "                    # Update results and progress\n",
    "                    for apk_filename, features, error in chunk_results:\n",
    "                        if features:\n",
    "                            results[apk_filename] = features\n",
    "                        else:\n",
    "                            failed_apks.append((apk_filename, error))\n",
    "                            print(f\"Error with {apk_filename}: {error}\")\n",
    "\n",
    "                    total_processed += len(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "\n",
    "                # Explicit cleanup after each chunk\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "                del pool\n",
    "                gc.collect()\n",
    "\n",
    "                # Save intermediate results periodically\n",
    "                if (chunk_idx + 1) % 20 == 0 or chunk_idx == len(chunks) - 1:\n",
    "                    if results:\n",
    "                        temp_df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "                        temp_df.to_pickle(f\"apk_analysis_temp_{total_processed}.pkl\")\n",
    "                        print(\n",
    "                            f\"\\nSaved intermediate results ({len(results)} APKs processed so far)\"\n",
    "                        )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {chunk_idx + 1}/{len(chunks)}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "                # Mark all APKs in this chunk as failed\n",
    "                for apk_path, is_malware in chunk:\n",
    "                    apk_filename = os.path.basename(apk_path)\n",
    "                    failed_apks.append(\n",
    "                        (apk_filename, f\"Chunk processing error: {str(e)}\")\n",
    "                    )\n",
    "                pbar.update(len(chunk))\n",
    "\n",
    "    # Log failed APKs\n",
    "    if failed_apks:\n",
    "        with open(\"failed_apks.txt\", \"w\") as f:\n",
    "            for apk, error in failed_apks:\n",
    "                f.write(f\"{apk}: {error}\\n\")\n",
    "        print(\n",
    "            f\"\\n{len(failed_apks)} APKs failed to process. See failed_apks.txt for details.\"\n",
    "        )\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "\n",
    "    # Convert list columns to JSON strings for CSV storage\n",
    "    df_csv = df.copy()\n",
    "    list_columns = [\n",
    "        \"activities_list\",\n",
    "        \"services_list\",\n",
    "        \"receivers_list\",\n",
    "        \"permissions_list\",\n",
    "        \"api_calls_list\",\n",
    "    ]\n",
    "\n",
    "    for col in list_columns:\n",
    "        if col in df_csv.columns:\n",
    "            df_csv[col] = df_csv[col].apply(\n",
    "                lambda x: json.dumps(x) if isinstance(x, (list, dict)) else x\n",
    "            )\n",
    "\n",
    "    # Fill NaN values\n",
    "    df = df.fillna(0)\n",
    "    df_csv = df_csv.fillna(0)\n",
    "\n",
    "    return df, df_csv, failed_apks\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths to APK directories\n",
    "    BENIGN_DIR = PROJECT_ROOT / \"apks\" / \"20k\" / \"benign_apks\"\n",
    "    MALWARE_DIR = PROJECT_ROOT / \"apks\" / \"20k\" / \"malware_apks\"\n",
    "    # Set log level to suppress warnings\n",
    "\n",
    "    # Analyze APKs with multiprocessing\n",
    "    df, df_csv, failed_apks = analyze_apks_mp(\n",
    "        BENIGN_DIR,\n",
    "        MALWARE_DIR,\n",
    "        max_workers=16,  # Adjust based on your system\n",
    "        chunk_size=16,  # Process in smaller batches\n",
    "    )\n",
    "\n",
    "    # Save the dataframes\n",
    "    df.to_pickle(\"apk_analysis_results.pkl\")  # Full data including lists\n",
    "    df_csv.to_csv(\"apk_analysis_results.csv\")  # CSV with JSON strings for lists\n",
    "\n",
    "    # Print statistics\n",
    "    print(\n",
    "        f\"\\nAnalysis complete. Generated dataset with {df.shape[0]} samples and {df.shape[1]} features.\"\n",
    "    )\n",
    "    print(f\"Benign samples: {sum(df['is_malware'] == 0)}\")\n",
    "    print(f\"Malware samples: {sum(df['is_malware'] == 1)}\")\n",
    "    print(f\"Failed samples: {len(failed_apks)}\")\n",
    "\n",
    "    # Print sample of the dataframe\n",
    "    print(\"\\nSample of the dataframe:\")\n",
    "    print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
