import os
import random
import string
import sys
import tempfile
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import shap
import streamlit as st
import torch
import umap
from lime.lime_tabular import LimeTabularExplainer

# --- Path Setup ---
# This allows the script to find your custom modules
try:
    # Assumes the script is in src/app/
    project_root = Path(__file__).resolve().parents[2]
except NameError:
    # Fallback for interactive environments
    project_root = Path.cwd()

if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

# --- Project Imports ---
# These should now work correctly if you run streamlit from the project root
from src.prototypes.ml_model_io import load_ml_models_from_version
from src.prototypes.torch_apk_analysis_model import (
    extract_embeddings,
    get_best_available_device,
    predict,
)
from src.prototypes.torch_apk_analysis_model_io import (
    load_apk_analysis_model_from_version,
)
from src.utils.feature_extraction import analyze_apk
from src.utils.preprocessing_utils import (
    apply_scalers_to_dataframe,
    preprocess_data_for_nn,
)

# --- Helper Classes and Functions for Interpretability ---


class NNClassifierHeadWrapper:
    """
    Wraps the classifier head of the NN model to be compatible with SHAP/LIME,
    which expect a scikit-learn-like `predict_proba` method.
    """

    def __init__(self, model, device):
        self.model = model
        self.device = device
        self.model.to(self.device)
        self.model.eval()

    def predict_proba(self, embeddings_np):
        """Takes a numpy array of embeddings and returns class probabilities."""
        # Ensure embeddings are float32, not float64
        embeddings_tensor = torch.from_numpy(embeddings_np.astype(np.float32)).to(
            self.device
        )
        with torch.no_grad():
            if hasattr(self.model, "classifier") and self.model.classifier is not None:
                logits = self.model.classifier(embeddings_tensor)
                probabilities = torch.softmax(logits, dim=1).cpu().numpy()
                return probabilities
            else:
                st.error("The loaded NN model does not have a 'classifier' attribute.")
                return np.array([[0.5, 0.5]] * len(embeddings_np))


def get_embedding_feature_names(metadata):
    """Generates descriptive feature names for the embedding dimensions."""
    arch = metadata.get("model_architecture", {})
    feature_names = []

    # The order must match the concatenation order in APKFeatureEmbedder
    # This is typically seq -> char -> vector -> scalar
    seq_cols = arch.get("sequence_cols", [])
    char_cols = arch.get("char_cols", [])
    vector_cols = arch.get("vector_cols", [])
    scalar_cols = arch.get("scalar_features", [])
    embedding_dim = arch.get("embedding_dim", 128)

    for col in seq_cols:
        feature_names.extend([f"{col}_emb_{i}" for i in range(embedding_dim)])
    for col in char_cols:
        feature_names.extend([f"{col}_emb_{i}" for i in range(embedding_dim)])
    for col in vector_cols:
        # The linear layer in the embedder projects vector features to embedding_dim
        feature_names.extend([f"{col}_emb_{i}" for i in range(embedding_dim)])

    # The ML models are trained on embeddings that may also include raw scalar features
    if isinstance(scalar_cols, list):
        feature_names.extend(scalar_cols)

    return feature_names


# --- Model & Data Loading ---


@st.cache_resource
def load_nn_model_from_disk(version=None, base_dir="model_artifacts/nn_models"):
    with st.spinner("Loading Neural Network model and artifacts..."):
        device = get_best_available_device()
        model, vocab_dict, scalers, metadata = load_apk_analysis_model_from_version(
            version=version, base_dir=base_dir, device=device
        )
        model.to(device)
        model.eval()
        st.success("Neural Network model loaded.")
        return model, vocab_dict, scalers, metadata, device


@st.cache_resource
def load_ml_models_from_disk(version=None, base_dir="model_artifacts/ml_models"):
    with st.spinner("Loading classical ML models..."):
        ml_models, ml_metadata = load_ml_models_from_version(
            version=version, base_dir=base_dir
        )
        st.success("Classical ML models loaded.")
        return ml_models, ml_metadata


# --- Data Generation & Processing ---


def generate_mock_apk_data(metadata, vocab_dict):
    """Generates a single-row DataFrame with mock data."""
    arch = metadata.get("model_architecture", {})
    sequence_cols = arch.get("sequence_cols", [])
    char_cols = arch.get("char_cols", [])
    vector_cols = arch.get("vector_cols", [])
    scalar_cols = arch.get("scalar_features", [])
    vector_dims = arch.get("vector_dims", {})
    mock_row = {}
    for col in sequence_cols:
        vocab = vocab_dict.get(col)
        if vocab:
            all_tokens = vocab.get_itos()
            sample_size = random.randint(5, 15)
            mock_row[col] = filter(
                lambda x: not x.startswith("<"), random.sample(all_tokens, sample_size)
            )
    for col in char_cols:
        mock_row[col] = "".join(random.choice(string.hexdigits) for _ in range(32))
    for col in vector_cols:
        mock_row[col] = np.random.rand(vector_dims.get(col, 256)).tolist()
    for col in scalar_cols:
        mock_row[col] = random.uniform(0, 1000)
    df = pd.DataFrame([mock_row])
    for col in sequence_cols + vector_cols:
        if col in df.columns:
            df[col] = df[col].astype("object")
    return df


def full_preprocess_and_predict(
    df_raw, nn_model, vocab_dict, scalers, metadata, device
):
    """Full pipeline: Preprocesses raw data, gets NN prediction, and extracts embeddings."""
    arch = metadata.get("model_architecture", {})

    # Defensive checks to ensure feature lists are iterable, preventing crashes from malformed metadata
    sequence_cols = arch.get("sequence_cols", [])
    if not isinstance(sequence_cols, list):
        sequence_cols = []
        st.warning(
            "`sequence_cols` in model metadata was not a list; defaulting to empty."
        )

    char_cols = arch.get("char_cols", [])
    if not isinstance(char_cols, list):
        char_cols = []
        st.warning("`char_cols` in model metadata was not a list; defaulting to empty.")

    vector_cols = arch.get("vector_cols", [])
    if not isinstance(vector_cols, list):
        vector_cols = []
        st.warning(
            "`vector_cols` in model metadata was not a list; defaulting to empty."
        )

    scalar_cols = arch.get("scalar_features", [])
    if not isinstance(scalar_cols, list):
        scalar_cols = []
        st.warning(
            "`scalar_features` in model metadata was not a list; defaulting to empty."
        )

    vector_dims = arch.get("vector_dims", {})
    max_lengths = metadata.get("max_lengths")

    df_pre_processed = df_raw.copy()
    # The preprocessing function expects string representations of lists,
    # so we convert any list-like columns.
    for col in sequence_cols:
        if col in df_pre_processed.columns:
            df_pre_processed[col] = df_pre_processed[col].apply(
                lambda x: str(list(x)) if isinstance(x, (list, np.ndarray)) else str(x)
            )

    df_tokenized, _ = preprocess_data_for_nn(
        df_pre_processed,
        sequence_cols,
        char_cols,
        vector_cols,
        scalar_cols,
        vector_dims,
        vocab_dict=vocab_dict,
        max_lengths=max_lengths,
    )

    df_scaled, _ = apply_scalers_to_dataframe(
        df_tokenized,
        scalar_cols=scalar_cols,
        vector_cols=vector_cols,
        scalers=scalers,
        fit_scalers=False,
    )

    embeddings, _ = extract_embeddings(
        model=nn_model,
        df=df_tokenized,
        scalers=scalers,
        sequence_cols=sequence_cols,
        scalar_cols=scalar_cols,
        char_cols=char_cols,
        vector_cols=vector_cols,
        device=device,
        batch_size=df_tokenized.shape[0],
    )

    predictions_nn, probabilities_nn = predict(
        model=nn_model,
        df=df_tokenized,
        scalers=scalers,
        sequence_cols=sequence_cols,
        scalar_cols=scalar_cols,
        char_cols=char_cols,
        vector_cols=vector_cols,
        device=device,
        batch_size=df_tokenized.shape[0],
    )

    # Corrected return statement to pass results back to the main app
    return predictions_nn, probabilities_nn, embeddings, df_scaled


def get_ml_predictions(ml_models, embeddings):
    """Gets predictions from classical ML models."""
    predictions = {}
    for name, model in ml_models.items():
        try:
            pred = model.predict(embeddings)
            proba = model.predict_proba(embeddings)
            predictions[name] = (pred[0], proba[0])
        except Exception as e:
            st.warning(f"Could not get prediction for {name}: {e}")
    return predictions


# --- Interpretability & Visualization ---


@st.cache_data
def get_background_data_for_explainers(
    _nn_model, _vocab_dict, _scalers, _metadata, _device, n_samples=50
):
    """Generates and processes background data to get embeddings for context."""
    with st.spinner(
        f"Generating {n_samples} background samples for explainer context..."
    ):
        mock_dfs = [
            generate_mock_apk_data(_metadata, _vocab_dict) for _ in range(n_samples)
        ]
        df_background = pd.concat(mock_dfs, ignore_index=True)
        _, _, background_embeddings, df_background_scaled = full_preprocess_and_predict(
            df_background, _nn_model, _vocab_dict, _scalers, _metadata, _device
        )
        # Return both embeddings and the scaled feature dataframe for LIME
        return background_embeddings, df_background_scaled


@st.cache_data
def get_ml_explanations(
    _models_to_explain,
    _instance_embedding,
    _background_embeddings,
    _embedding_feature_names,  # Now expects descriptive names
):
    """Generates SHAP and LIME explanations for classical models based on embeddings."""
    explanations = {}

    # Ensure embeddings are dense numpy arrays for explainers
    instance_embedding_dense = (
        _instance_embedding.toarray()
        if hasattr(_instance_embedding, "toarray")
        else np.asarray(_instance_embedding)
    )
    background_embeddings_dense = (
        _background_embeddings.toarray()
        if hasattr(_background_embeddings, "toarray")
        else np.asarray(_background_embeddings)
    )

    for name, model in _models_to_explain.items():
        # SVMs trained with probability=False lack this method, so we skip them.
        if not hasattr(model, "predict_proba"):
            st.warning(
                f"Skipping explanations for {name}: model does not have `predict_proba` method."
            )
            continue
        try:
            # SHAP Explainer
            shap_explainer = shap.KernelExplainer(
                model.predict_proba, background_embeddings_dense
            )
            shap_values = shap_explainer.shap_values(instance_embedding_dense)
            shap_expected_value = shap_explainer.expected_value

            # LIME Explainer
            lime_explainer = LimeTabularExplainer(
                training_data=background_embeddings_dense,  # Use background embeddings
                mode="classification",
                feature_names=_embedding_feature_names,  # Use descriptive names
                class_names=["Benign", "Malware"],
                discretize_continuous=True,
            )
            lime_exp = lime_explainer.explain_instance(
                instance_embedding_dense[0], model.predict_proba, num_features=20
            )

            # Store only serializable results to avoid caching errors
            explanations[name] = {
                "shap_values": shap_values,
                "shap_expected_value": shap_expected_value,
                "lime_as_list": lime_exp.as_list(),
            }
        except Exception as e:
            st.warning(f"Could not generate explanation for {name}: {e}")

    # Return the dictionary with serializable data; @st.cache_data will handle it.
    return explanations


def plot_shap_summary(shap_values, class_names, feature_names):
    """Plots a SHAP summary plot, adapted for a single instance using a bar plot."""
    fig, ax = plt.subplots(figsize=(10, 8))  # Made plot smaller

    # Determine which SHAP values to plot. We want the "Malware" class (usually index 1).
    # If the model is single-output, shap_values might not be a list or be a list of length 1.
    plot_values = None
    if isinstance(shap_values, list):
        if len(shap_values) > 1:
            plot_values = shap_values[1]  # Malware class
        elif len(shap_values) == 1:
            plot_values = shap_values[0]
    else:
        plot_values = shap_values  # It's a numpy array

    if plot_values is not None:
        # We use summary_plot with plot_type='bar' for a single instance explanation
        shap.summary_plot(
            plot_values.reshape(1, -1),  # Reshape for summary_plot
            feature_names=feature_names,
            plot_type="bar",
            show=False,
            max_display=20,
        )
        ax.set_title(f"SHAP Feature Importance for '{class_names[1]}' Prediction")
        st.pyplot(fig)
    else:
        st.warning("Could not determine SHAP values to plot.")

    plt.close(fig)


def plot_lime_explanation(lime_exp_list):
    """Plots a LIME explanation as a bar chart from a list."""
    if not lime_exp_list:
        st.warning("LIME explanation could not be generated.")
        return

    exp_df = pd.DataFrame(lime_exp_list, columns=["feature", "weight"])
    exp_df["positive"] = exp_df["weight"] > 0
    # Take top 20 features for clarity by absolute weight
    exp_df = exp_df.reindex(exp_df.weight.abs().sort_values(ascending=False).index)
    exp_df = exp_df.head(20).sort_values(by="weight", ascending=True)

    fig, ax = plt.subplots(figsize=(10, 8))  # Made plot smaller
    colors = exp_df.positive.map({True: "g", False: "r"})
    ax.barh(exp_df["feature"], exp_df["weight"], color=colors)
    ax.set_title("LIME Explanation (Top Features)")
    ax.set_xlabel("Weight")
    st.pyplot(fig)
    plt.close(fig)


def plot_umap_embeddings(_current_embedding, _background_embeddings):
    """Visualizes embedding space with UMAP."""
    with st.spinner("Reducing dimensionality with UMAP..."):
        try:
            # Ensure embeddings are dense and float for UMAP
            current_dense = (
                _current_embedding.toarray()
                if hasattr(_current_embedding, "toarray")
                else np.asarray(_current_embedding)
            )
            background_dense = (
                _background_embeddings.toarray()
                if hasattr(_background_embeddings, "toarray")
                else np.asarray(_background_embeddings)
            )

            combined_embeddings = np.vstack([current_dense, background_dense]).astype(
                np.float32
            )

            reducer = umap.UMAP(
                n_neighbors=15, min_dist=0.1, n_components=2, random_state=42
            )
            reduced_embeddings = reducer.fit_transform(combined_embeddings)

            fig, ax = plt.subplots(figsize=(8, 6))  # Made plot smaller

            # Plot background points
            ax.scatter(
                reduced_embeddings[1:, 0],
                reduced_embeddings[1:, 1],
                c="gray",
                alpha=0.5,
                label="Background Samples",
            )

            # Plot current APK point
            ax.scatter(
                reduced_embeddings[0, 0],
                reduced_embeddings[0, 1],
                c="red",
                s=100,
                edgecolor="k",
                label="Current APK",
            )

            ax.set_title("UMAP Projection of APK Embeddings")
            ax.set_xlabel("UMAP Dimension 1")
            ax.set_ylabel("UMAP Dimension 2")
            ax.legend()
            st.pyplot(fig)
            plt.close(fig)
        except Exception as e:
            st.error(f"Failed to generate UMAP plot: {e}")


# --- UI Layout & Main Logic ---

st.set_page_config(page_title="APK Malware Interpreter", layout="wide")
st.title("🤖 APK Malware Analysis & Interpretation")

if "history" not in st.session_state:
    st.session_state.history = []
if "current_analysis" not in st.session_state:
    st.session_state.current_analysis = None

try:
    # Load all models and artifacts once
    nn_model, vocab_dict, scalers, nn_metadata, device = load_nn_model_from_disk()
    ml_models, ml_metadata = load_ml_models_from_disk()

    # --- Add NN model to ML models for consistent explanation ---
    nn_wrapper = NNClassifierHeadWrapper(nn_model, device)
    ml_models["Neural Network (Classifier Head)"] = nn_wrapper

    # --- Sidebar -- -
    with st.sidebar:
        st.header("Control Panel")
        uploaded_file = st.file_uploader(
            "Upload an APK file for analysis", type=["apk"]
        )

        if uploaded_file is not None:
            # To keep the app responsive, we process the file only when the button is clicked
            if st.button("Analyze Uploaded APK"):
                # Save uploaded file to a temporary directory
                with tempfile.NamedTemporaryFile(delete=False, suffix=".apk") as tmp:
                    tmp.write(uploaded_file.getvalue())
                    tmp_path = tmp.name

                with st.spinner(
                    f"Analyzing `{uploaded_file.name}`... This may take a moment."
                ):
                    # Assuming analyze_apk returns a dictionary of features and the filename
                    features, apk_filename = analyze_apk(tmp_path)
                    print(f"Extracted features: {features}")

                # Clean up the temporary file
                os.unlink(tmp_path)

                if features is not None:
                    # Convert the feature dictionary to a pandas DataFrame
                    df_raw = pd.DataFrame([features])

                    # Ensure list-like columns are correctly handled as objects
                    for col in df_raw.columns:
                        if isinstance(df_raw[col].iloc[0], list):
                            df_raw[col] = df_raw[col].astype("object")

                    st.success(
                        f"Successfully extracted features from `{apk_filename}`."
                    )
                    # Store the results in the session state to trigger the main view
                    st.session_state.current_analysis = {
                        "df_raw": df_raw,
                        "filename": uploaded_file.name,
                    }
                    st.rerun()  # Rerun to update the main panel
                else:
                    st.error(
                        f"Failed to analyze `{uploaded_file.name}`. The file might be corrupt, protected, or not a valid APK."
                    )
                    st.session_state.current_analysis = None  # Clear previous analysis

        st.header("Analysis History")
        if st.button("Clear History"):
            st.session_state.history = []
            st.session_state.current_analysis = None
            st.rerun()

        if not st.session_state.history:
            st.info("No analyses yet.")
        else:
            for i, record in enumerate(reversed(st.session_state.history)):
                # Use a button to reload a previous analysis
                verdict_emoji = "🔴" if record["verdict"] == "Malware" else "🟢"
                if st.button(
                    f"{verdict_emoji} {record['filename'][:25]}... ({record['verdict']})",
                    key=f"history_{i}",
                ):
                    # Load the selected analysis from history into the current view
                    st.session_state.current_analysis = record
                    st.rerun()

    # --- Main Analysis Area ---
    if st.session_state.current_analysis:
        # Retrieve the analysis data from the session state
        analysis_data = st.session_state.current_analysis
        df_raw = analysis_data["df_raw"]
        apk_filename = analysis_data["filename"]

        # --- Generate background data once for all explainers and UMAP ---
        # The function is cached, so it runs only once per session with same args
        background_embeddings, background_df_scaled = (
            get_background_data_for_explainers(
                nn_model, vocab_dict, scalers, nn_metadata, device, n_samples=100
            )
        )

        # Add to history if it's a new analysis (not reloaded from history)
        if "verdict" not in analysis_data:
            with st.spinner("Running full analysis pipeline..."):
                (
                    nn_pred,
                    nn_proba,
                    embeddings,
                    df_processed,
                ) = full_preprocess_and_predict(
                    df_raw, nn_model, vocab_dict, scalers, nn_metadata, device
                )

                ml_predictions = get_ml_predictions(ml_models, embeddings)

            verdict = "Malware" if nn_pred[0] == 1 else "Benign"
            # Update the current analysis with results
            analysis_data["verdict"] = verdict
            analysis_data["nn_pred"] = nn_pred[0]
            analysis_data["nn_proba"] = nn_proba[0]
            analysis_data["ml_predictions"] = ml_predictions
            analysis_data["embeddings"] = embeddings
            analysis_data["df_processed"] = df_processed

            # Add the completed analysis to the history
            st.session_state.history.append(analysis_data)
            st.rerun()  # Rerun to ensure the view updates with the new state
        else:
            # This is a reloaded analysis from history
            st.header(f"Displaying analysis for: `{apk_filename}`")
            nn_pred = analysis_data["nn_pred"]
            nn_proba = analysis_data["nn_proba"]
            ml_predictions = analysis_data["ml_predictions"]
            embeddings = analysis_data["embeddings"]
            df_processed = analysis_data["df_processed"]
            verdict = analysis_data["verdict"]

        st.subheader("Analysis Results")
        tab_summary, tab_preds, tab_exp, tab_umap, tab_input = st.tabs(
            [
                "📊 Summary",
                "📄 Detailed Predictions",
                "🤖 Model Explanations",
                "🗺️ Embedding Space",
                "⚙️ Processed Input",
            ]
        )

        with tab_summary:
            nn_col, ml_col = st.columns(2)
            with nn_col:
                st.metric(
                    "Neural Network Verdict",
                    verdict,
                    f"{nn_proba[1] * 100:.1f}% Malware"
                    if verdict == "Malware"
                    else f"{nn_proba[0] * 100:.1f}% Benign",
                    delta_color="inverse",
                )
            with ml_col:
                ml_verdicts = [
                    1 if pred == 1 else 0 for pred, _ in ml_predictions.values()
                ]
                malware_count = sum(ml_verdicts)
                benign_count = len(ml_verdicts) - malware_count
                st.metric(
                    "Classical Models Consensus",
                    "Malware" if malware_count > benign_count else "Benign",
                    f"{malware_count} Malware vs. {benign_count} Benign",
                    delta_color="off",
                )

        with tab_preds:
            st.subheader("Neural Network (APKAnalysisModel)")
            st.dataframe(
                pd.DataFrame(
                    {
                        "Model": ["Neural Network"],
                        "Prediction": ["Malware" if nn_pred == 1 else "Benign"],
                        "Benign Confidence": [f"{nn_proba[0] * 100:.2f}%"],
                        "Malware Confidence": [f"{nn_proba[1] * 100:.2f}%"],
                    }
                )
            )
            st.subheader("Classical ML Models (on NN Embeddings)")
            ml_results = [
                {
                    "Model": name,
                    "Prediction": "Malware" if pred == 1 else "Benign",
                    "Benign Confidence": f"{proba[0] * 100:.2f}%",
                    "Malware Confidence": f"{proba[1] * 100:.2f}%",
                }
                for name, (pred, proba) in ml_predictions.items()
            ]
            st.dataframe(pd.DataFrame(ml_results))

        with tab_exp:
            st.header("Model Explanations (SHAP & LIME)")
            st.info(
                "These models interpret the high-level features (embeddings) learned by the Neural Network."
            )

            # Get feature names for the embedding vector for better plot labels
            embedding_feature_names = get_embedding_feature_names(nn_metadata)

            # Get explanations for all models, including the NN wrapper
            all_explanations = get_ml_explanations(
                ml_models,  # This now includes the NN wrapper
                embeddings,
                background_embeddings,
                embedding_feature_names,
            )

            model_to_explain = st.selectbox(
                "Choose a model to inspect:", list(all_explanations.keys())
            )
            if model_to_explain and model_to_explain in all_explanations:
                exp = all_explanations[model_to_explain]

                st.subheader(f"SHAP Explanation for {model_to_explain}")
                with st.spinner("Generating SHAP plot..."):
                    try:
                        # The plot function is now robust to different SHAP value shapes
                        plot_shap_summary(
                            exp["shap_values"],
                            class_names=["Benign", "Malware"],
                            feature_names=embedding_feature_names,
                        )
                    except Exception as e:
                        st.error(f"Could not generate SHAP plot: {e}")

                st.subheader(f"LIME Explanation for {model_to_explain}")
                st.write(
                    "Shows feature contributions for the prediction on this specific APK."
                )
                with st.spinner("Generating LIME plot..."):
                    try:
                        # The plot function now takes the list of explanations directly
                        plot_lime_explanation(exp["lime_as_list"])

                        st.write("Feature importances (LIME):")
                        lime_df = pd.DataFrame(
                            exp["lime_as_list"], columns=["feature", "weight"]
                        )
                        st.dataframe(lime_df)
                    except Exception as e:
                        st.error(f"Could not generate LIME explanation: {e}")

        with tab_umap:
            st.header("Embedding Space Visualization (UMAP)")
            st.info(
                "This plot shows where the current APK's embedding (red dot) is located relative to a background of other samples (gray dots). Clusters can indicate similar behavior."
            )
            # Use the pre-calculated background embeddings
            plot_umap_embeddings(embeddings, background_embeddings)

        with tab_input:
            st.header("Processed Model Input")
            st.dataframe(df_processed)
            st.dataframe(
                pd.DataFrame(
                    embeddings, columns=[f"emb_{i}" for i in range(embeddings.shape[1])]
                )
            )

        with st.expander("Model Interpretation (Captum) - DISABLED"):
            st.warning(
                "Captum-based interpretability for the NN embedder is not yet implemented."
            )

    else:
        st.info("Upload an APK file and click 'Analyze' to begin.")

except FileNotFoundError as e:
    st.error(f"❌ Error loading model artifacts: {e}")
    st.warning(
        "Please ensure that trained models exist in the 'model_artifacts' directory and that you are running the app from the project root directory."
    )
except Exception as e:
    st.error(f"An unexpected error occurred: {e}")
    st.exception(e)
